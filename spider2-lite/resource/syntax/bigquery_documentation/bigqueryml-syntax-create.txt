[ ![Google Cloud](https://www.gstatic.com/devrel-
devsite/prod/vc851b65627ca98cc752c9ae13e5f506cd6dbb7ed1bb4c8df6090c5f9130ed83c/cloud/images/cloud-
logo.svg) ](/)

*

[ Documentation ](https://cloud.google.com/docs) [ Technology areas
](https://cloud.google.com/docs/tech-area-overviews)

close

* [ AI solutions, generative AI, and ML  ](https://cloud.google.com/docs/ai-ml)
* [ Application development  ](https://cloud.google.com/docs/application-development)
* [ Application hosting  ](https://cloud.google.com/docs/application-hosting)
* [ Compute  ](https://cloud.google.com/docs/compute-area)
* [ Data analytics and pipelines  ](https://cloud.google.com/docs/data)
* [ Databases  ](https://cloud.google.com/docs/databases)
* [ Distributed, hybrid, and multicloud  ](https://cloud.google.com/docs/dhm-cloud)
* [ Industry solutions  ](https://cloud.google.com/docs/industry)
* [ Networking  ](https://cloud.google.com/docs/networking)
* [ Observability and monitoring  ](https://cloud.google.com/docs/observability)
* [ Security  ](https://cloud.google.com/docs/security)
* [ Storage  ](https://cloud.google.com/docs/storage)

[ Cross-product tools ](https://cloud.google.com/docs/cross-product-overviews)

close

* [ Access and resources management  ](https://cloud.google.com/docs/access-resources)
* [ Cloud SDK, languages, frameworks, and tools  ](https://cloud.google.com/docs/devtools)
* [ Costs and usage management  ](https://cloud.google.com/docs/costs-usage)
* [ Infrastructure as code  ](https://cloud.google.com/docs/iac)
* [ Migration  ](https://cloud.google.com/docs/migration)

[ Related sites ](https://cloud.google.com/)

close

* [ Google Cloud Home  ](https://cloud.google.com/)
* [ Free Trial and Free Tier  ](https://cloud.google.com/free)
* [ Architecture Center  ](https://cloud.google.com/architecture)
* [ Blog  ](https://cloud.google.com/blog)
* [ Contact Sales  ](https://cloud.google.com/contact)
* [ Google Cloud Developer Center  ](https://cloud.google.com/developers)
* [ Google Developer Center  ](https://developers.google.com/)
* [ Google Cloud Marketplace (in console)  ](https://console.cloud.google.com/marketplace)
* [ Google Cloud Marketplace Documentation  ](https://cloud.google.com/marketplace/docs)
* [ Google Cloud Skills Boost  ](https://www.cloudskillsboost.google/paths)
* [ Google Cloud Solution Center  ](https://cloud.google.com/solutions)
* [ Google Cloud Support  ](https://cloud.google.com/support-hub)
* [ Google Cloud Tech Youtube Channel  ](https://www.youtube.com/@googlecloudtech)

* English
* Deutsch
* Español – América Latina
* Français
* Português – Brasil
* 中文 – 简体
* 日本語
* 한국어

Sign in

* [ BigQuery ](https://cloud.google.com/bigquery)

[ Guides ](https://cloud.google.com/bigquery/docs/introduction) [ Reference
](https://cloud.google.com/bigquery/quotas) [ Samples
](https://cloud.google.com/bigquery/docs/samples) [ Resources
](https://cloud.google.com/bigquery/docs/release-notes)

[ Contact Us ](https://cloud.google.com/contact) [ Start free
](//console.cloud.google.com/freetrial)

[ ![Google Cloud](https://www.gstatic.com/devrel-
devsite/prod/vc851b65627ca98cc752c9ae13e5f506cd6dbb7ed1bb4c8df6090c5f9130ed83c/cloud/images/cloud-
logo.svg) ](/)

*

* [ Documentation  ](/docs)
* [ Guides  ](/bigquery/docs/introduction)
* [ Reference  ](/bigquery/quotas)
* [ Samples  ](/bigquery/docs/samples)
* [ Resources  ](/bigquery/docs/release-notes)
* [ Technology areas  ](/docs/tech-area-overviews)
* More
* [ Cross-product tools  ](/docs/cross-product-overviews)
* More
* [ Related sites  ](/)
* More
* [ Console  ](//console.cloud.google.com/)
* [ Contact Us  ](/contact)
* [ Start free  ](//console.cloud.google.com/freetrial)

* Quotas and limits

* [ Quotas and limits reference  ](/bigquery/quotas)
* [ Troubleshoot quota errors  ](/bigquery/docs/troubleshoot-quotas)
* BigQuery command-line tool

* [ bq command-line tool reference  ](/bigquery/docs/reference/bq-cli-reference)
* SQL in BigQuery

* GoogleSQL reference

* [ Query syntax  ](/bigquery/docs/reference/standard-sql/query-syntax)
* General reference

* [ Data types  ](/bigquery/docs/reference/standard-sql/data-types)
* [ Lexical structure and syntax  ](/bigquery/docs/reference/standard-sql/lexical)
* [ Conversion rules  ](/bigquery/docs/reference/standard-sql/conversion_rules)
* [ Format elements  ](/bigquery/docs/reference/standard-sql/format-elements)
* [ Collation  ](/bigquery/docs/reference/standard-sql/collation-concepts)
* [ Text analysis  ](/bigquery/docs/reference/standard-sql/text-analysis)
* [ BI Engine optimized functions  ](/bigquery/docs/bi-engine-optimized-sql)

* Expressions

* [ Function calls  ](/bigquery/docs/reference/standard-sql/functions-reference)
* [ Aggregate function calls  ](/bigquery/docs/reference/standard-sql/aggregate-function-calls)
* [ Window function calls  ](/bigquery/docs/reference/standard-sql/window-function-calls)
* [ Operators  ](/bigquery/docs/reference/standard-sql/operators)
* [ Conditional expressions  ](/bigquery/docs/reference/standard-sql/conditional_expressions)
* [ Subqueries  ](/bigquery/docs/reference/standard-sql/subqueries)

* Functions

* [ All functions and operators  ](/bigquery/docs/reference/standard-sql/functions-and-operators)
* [ AEAD encryption functions  ](/bigquery/docs/reference/standard-sql/aead_encryption_functions)
* [ Aggregate functions  ](/bigquery/docs/reference/standard-sql/aggregate_functions)
* [ Approximate aggregate functions  ](/bigquery/docs/reference/standard-sql/approximate_aggregate_functions)
* [ Array functions  ](/bigquery/docs/reference/standard-sql/array_functions)
* [ Bit functions  ](/bigquery/docs/reference/standard-sql/bit_functions)
* [ Conversion functions  ](/bigquery/docs/reference/standard-sql/conversion_functions)
* [ Date functions  ](/bigquery/docs/reference/standard-sql/date_functions)
* [ Datetime functions  ](/bigquery/docs/reference/standard-sql/datetime_functions)
* [ Debugging functions  ](/bigquery/docs/reference/standard-sql/debugging_functions)
* [ Differentially private aggregate functions  ](/bigquery/docs/reference/standard-sql/aggregate-dp-functions)
* [ Federated query functions  ](/bigquery/docs/reference/standard-sql/federated_query_functions)
* [ DLP encryption functions  ](/bigquery/docs/reference/standard-sql/dlp_functions)
* [ Geography functions  ](/bigquery/docs/reference/standard-sql/geography_functions)
* [ Hash functions  ](/bigquery/docs/reference/standard-sql/hash_functions)
* [ HyperLogLog++ functions  ](/bigquery/docs/reference/standard-sql/hll_functions)
* [ Interval functions  ](/bigquery/docs/reference/standard-sql/interval_functions)
* [ JSON functions  ](/bigquery/docs/reference/standard-sql/json_functions)
* [ Mathematical functions  ](/bigquery/docs/reference/standard-sql/mathematical_functions)
* [ Navigation functions  ](/bigquery/docs/reference/standard-sql/navigation_functions)
* [ Net functions  ](/bigquery/docs/reference/standard-sql/net_functions)
* [ Numbering functions  ](/bigquery/docs/reference/standard-sql/numbering_functions)
* [ Range functions  ](/bigquery/docs/reference/standard-sql/range-functions)
* [ Search functions  ](/bigquery/docs/reference/standard-sql/search_functions)
* [ Security functions  ](/bigquery/docs/reference/standard-sql/security_functions)
* [ Statistical aggregate functions  ](/bigquery/docs/reference/standard-sql/statistical_aggregate_functions)
* [ String functions  ](/bigquery/docs/reference/standard-sql/string_functions)
* [ Table functions (built-in)  ](/bigquery/docs/reference/standard-sql/table-functions-built-in)
* [ Text analysis functions  ](/bigquery/docs/reference/standard-sql/text-analysis-functions)
* [ Time functions  ](/bigquery/docs/reference/standard-sql/time_functions)
* [ Time series functions  ](/bigquery/docs/reference/standard-sql/time-series-functions)
* [ Timestamp functions  ](/bigquery/docs/reference/standard-sql/timestamp_functions)
* [ Utility functions  ](/bigquery/docs/reference/standard-sql/utility-functions)

* Statements

* [ Data definition language (DDL)  ](/bigquery/docs/reference/standard-sql/data-definition-language)
* [ Data manipulation language (DML)  ](/bigquery/docs/reference/standard-sql/dml-syntax)
* [ Data control language (DCL)  ](/bigquery/docs/reference/standard-sql/data-control-language)
* [ Procedural language  ](/bigquery/docs/reference/standard-sql/procedural-language)
* [ Export and load statements  ](/bigquery/docs/reference/standard-sql/other-statements)
* [ Debugging statements  ](/bigquery/docs/reference/standard-sql/debugging-statements)

* BigQuery ML SQL reference

* Creating and training models

* [ CREATE MODEL statement overview  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create)
* Regression and classification

* [ Linear and logistic regression  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-glm)
* [ Boosted trees  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)
* [ Random forest  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-random-forest)
* [ Deep neural networks  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-models)
* [ Wide & Deep networks  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-wnd-models)
* [ AutoML models  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-automl)

* Clustering

* [ K-means  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-kmeans)

* Dimensionality reduction

* [ Principal component analysis  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-pca)
* [ Autoencoder  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-autoencoder)

* Collaborative filtering

* [ Matrix factorization  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-matrix-factorization)

* Time series forecasting

* [ Univariate forecasting with ARIMA_PLUS models  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-time-series)
* [ Multivariate forecasting with ARIMA_PLUS_XREG models  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-multivariate-time-series)

* Importing models

* [ Open Neural Network Exchange (ONNX)  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-onnx)
* [ TensorFlow  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tensorflow)
* [ TensorFlow Lite  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tflite)
* [ XGBoost  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-xgboost)

* Remote models

* [ LLMs  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model)
* [ Cloud AI services  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-service)
* [ Vertex AI hosted models  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-https)

* Feature engineering

* [ Feature transformation  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-transform)
* [ ML.TRANSFORM  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-transform)
* [ ML.FEATURE_INFO  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-feature)
* General functions

* [ ML.IMPUTER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-imputer)

* Numerical functions

* [ ML.BUCKETIZE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-bucketize)
* [ ML.MAX_ABS_SCALER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-max-abs-scaler)
* [ ML.MIN_MAX_SCALER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-min-max-scaler)
* [ ML.NORMALIZER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-normalizer)
* [ ML.POLYNOMIAL_EXPAND  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-polynomial-expand)
* [ ML.QUANTILE_BUCKETIZE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-quantile-bucketize)
* [ ML.ROBUST_SCALER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-robust-scaler)
* [ ML.STANDARD_SCALER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-standard-scaler)

* Categorical functions

* [ ML.FEATURE_CROSS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-feature-cross)
* [ ML.HASH_BUCKETIZE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-hash-bucketize)
* [ ML.LABEL_ENCODER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-label-encoder)
* [ ML.MULTI_HOT_ENCODER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-multi-hot-encoder)
* [ ML.ONE_HOT_ENCODER  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-one-hot-encoder)

* Text functions

* [ ML.NGRAMS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ngrams)
* [ ML.BAG_OF_WORDS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-bag-of-words)
* [ ML.TF_IDF  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-tf-idf)

* Image functions

* [ ML.CONVERT_COLOR_SPACE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-convert-color-space)
* [ ML.CONVERT_IMAGE_TYPE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-convert-image-type)
* [ ML.DECODE_IMAGE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-decode-image)
* [ ML.RESIZE_IMAGE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-resize-image)

* Point-in-time lookup functions

* [ ML.FEATURES_AT_TIME  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-feature-time)
* [ ML.ENTITY_FEATURES_AT_TIME  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-entity-feature-time)

* Hyperparameter tuning functions

* [ ML.TRIAL_INFO  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-trial-info)

* Evaluation functions

* [ ML.EVALUATE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-evaluate)
* [ ML.ROC_CURVE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-roc)
* [ ML.CONFUSION_MATRIX  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-confusion)
* [ ML.ARIMA_EVALUATE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-arima-evaluate)
* [ ML.TRAINING_INFO  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-train)
* [ ML.RECONSTRUCTION_LOSS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-reconstruction-loss)
* [ ML.HOLIDAY_INFO  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-holiday-info)

* Inference functions

* [ ML.PREDICT  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-predict)
* [ ML.FORECAST  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-forecast)
* [ ML.RECOMMEND  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-recommend)
* [ ML.DETECT_ANOMALIES  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-detect-anomalies)

* Generative AI functions

* [ ML.GENERATE_TEXT  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text)
* [ ML.GENERATE_EMBEDDING  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-embedding)

* AI functions

* [ ML.UNDERSTAND_TEXT  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-understand-text)
* [ ML.TRANSLATE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-translate)
* [ ML.PROCESS_DOCUMENT  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-process-document)
* [ ML.TRANSCRIBE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-transcribe)
* [ ML.ANNOTATE_IMAGE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-annotate-image)

* AI Explanation functions

* [ ML.EXPLAIN_PREDICT  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-explain-predict)
* [ ML.EXPLAIN_FORECAST  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-explain-forecast)
* [ ML.GLOBAL_EXPLAIN  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-global-explain)
* [ ML.FEATURE_IMPORTANCE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-importance)
* [ ML.ADVANCED_WEIGHTS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-advanced-weights)

* Model weights functions

* [ ML.WEIGHTS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-weights)
* [ ML.CENTROIDS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-centroids)
* [ ML.PRINCIPAL_COMPONENTS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-principal-components)
* [ ML.PRINCIPAL_COMPONENT_INFO  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-principal-component-info)
* [ ML.ARIMA_COEFFICIENTS  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-arima-coefficients)

* Model monitoring functions

* [ ML.DESCRIBE_DATA  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-describe-data)
* [ ML.VALIDATE_DATA_DRIFT  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-validate-data-drift)
* [ ML.VALIDATE_DATA_SKEW  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-validate-data-skew)
* [ ML.TFDV_DESCRIBE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-tfdv-describe)
* [ ML.TFDV_VALIDATE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-tfdv-validate)

* Math utility functions

* [ ML.DISTANCE  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-distance)
* [ ML.LP_NORM  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-lp-norm)

* Model management statements

* [ EXPORT MODEL statement  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-export-model)
* [ ALTER MODEL statement  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-alter-model)
* [ DROP MODEL statement  ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-drop-model)

* INFORMATION SCHEMA views

* [ Introduction  ](/bigquery/docs/information-schema-intro)
* Access control

* [ OBJECT_PRIVILEGES view  ](/bigquery/docs/information-schema-object-privileges)

* BI Engine

* [ BI_CAPACITIES  ](/bigquery/docs/information-schema-bi-capacities)
* [ BI_CAPACITY_CHANGES  ](/bigquery/docs/information-schema-bi-capacity-changes)

* Configurations

* [ EFFECTIVE_PROJECT_OPTIONS view  ](/bigquery/docs/information-schema-effective-project-options)
* [ ORGANIZATION_OPTIONS view  ](/bigquery/docs/information-schema-organization-options)
* [ ORGANIZATION_OPTIONS_CHANGES view  ](/bigquery/docs/information-schema-organization-options-changes)
* [ PROJECT_OPTIONS view  ](/bigquery/docs/information-schema-project-options)
* [ PROJECT_OPTIONS_CHANGES view  ](/bigquery/docs/information-schema-project-options-changes)

* Datasets

* [ SCHEMATA view  ](/bigquery/docs/information-schema-datasets-schemata)
* [ SCHEMATA_LINKS view  ](/bigquery/docs/information-schema-datasets-schemata-links)
* [ SCHEMATA_OPTIONS view  ](/bigquery/docs/information-schema-datasets-schemata-options)
* [ SHARED_DATASET_USAGE view  ](/bigquery/docs/information-schema-shared-dataset-usage)
* [ SCHEMATA_REPLICAS view  ](/bigquery/docs/information-schema-schemata-replicas)

* Jobs

* [ JOBS view  ](/bigquery/docs/information-schema-jobs)
* [ JOBS_BY_USER view  ](/bigquery/docs/information-schema-jobs-by-user)
* [ JOBS_BY_FOLDER view  ](/bigquery/docs/information-schema-jobs-by-folder)
* [ JOBS_BY_ORGANIZATION view  ](/bigquery/docs/information-schema-jobs-by-organization)

* Jobs by timeslice

* [ JOBS_TIMELINE view  ](/bigquery/docs/information-schema-jobs-timeline)
* [ JOBS_TIMELINE_BY_USER view  ](/bigquery/docs/information-schema-jobs-timeline-by-user)
* [ JOBS_TIMELINE_BY_FOLDER view  ](/bigquery/docs/information-schema-jobs-timeline-by-folder)
* [ JOBS_TIMELINE_BY_ORGANIZATION view  ](/bigquery/docs/information-schema-jobs-timeline-by-organization)

* Reservations

* [ ASSIGNMENTS view  ](/bigquery/docs/information-schema-assignments)
* [ ASSIGNMENT_CHANGES view  ](/bigquery/docs/information-schema-assignments-changes)
* [ CAPACITY_COMMITMENTS view  ](/bigquery/docs/information-schema-capacity-commitments)
* [ CAPACITY_COMMITMENT_CHANGES view  ](/bigquery/docs/information-schema-capacity-commitment-changes)
* [ RESERVATIONS view  ](/bigquery/docs/information-schema-reservations)
* [ RESERVATION_CHANGES view  ](/bigquery/docs/information-schema-reservation-changes)
* [ RESERVATIONS_TIMELINE view  ](/bigquery/docs/information-schema-reservation-timeline)

* Routines

* [ PARAMETERS view  ](/bigquery/docs/information-schema-parameters)
* [ ROUTINES view  ](/bigquery/docs/information-schema-routines)
* [ ROUTINE_OPTIONS view  ](/bigquery/docs/information-schema-routine-options)

* Search indexes

* [ SEARCH_INDEXES view  ](/bigquery/docs/information-schema-indexes)
* [ SEARCH_INDEX_COLUMNS view  ](/bigquery/docs/information-schema-index-columns)

* Sessions

* [ SESSIONS_BY_PROJECT view  ](/bigquery/docs/information-schema-sessions-by-project)
* [ SESSIONS_BY_USER view  ](/bigquery/docs/information-schema-sessions-by-user)

* Streaming

* [ STREAMING_TIMELINE view  ](/bigquery/docs/information-schema-streaming)
* [ STREAMING_TIMELINE_BY_FOLDER view  ](/bigquery/docs/information-schema-streaming-by-folder)
* [ STREAMING_TIMELINE_BY_ORGANIZATION view  ](/bigquery/docs/information-schema-streaming-by-organization)

* Tables

* [ COLUMNS view  ](/bigquery/docs/information-schema-columns)
* [ COLUMN_FIELD_PATHS view  ](/bigquery/docs/information-schema-column-field-paths)
* [ CONSTRAINT_COLUMN_USAGE view  ](/bigquery/docs/information-schema-constraint-column-usage)
* [ KEY_COLUMN_USAGE view  ](/bigquery/docs/information-schema-key-column-usage)
* [ PARTITIONS view  ](/bigquery/docs/information-schema-partitions)
* [ TABLES view  ](/bigquery/docs/information-schema-tables)
* [ TABLE_OPTIONS view  ](/bigquery/docs/information-schema-table-options)
* [ TABLE_CONSTRAINTS view  ](/bigquery/docs/information-schema-table-constraints)
* [ TABLE_SNAPSHOTS view  ](/bigquery/docs/information-schema-snapshots)
* [ TABLE_STORAGE view  ](/bigquery/docs/information-schema-table-storage)
* [ TABLE_STORAGE_BY_ORGANIZATION view  ](/bigquery/docs/information-schema-table-storage-by-organization)
* [ TABLE_STORAGE_USAGE_TIMELINE view  ](/bigquery/docs/information-schema-table-storage-usage)
* [ TABLE_STORAGE_USAGE_TIMELINE_BY_ORGANIZATION view  ](/bigquery/docs/information-schema-table-storage-usage-by-organization)

* Vector indexes

* [ VECTOR_INDEXES view  ](/bigquery/docs/information-schema-vector-indexes)
* [ VECTOR_INDEX_COLUMNS view  ](/bigquery/docs/information-schema-vector-index-columns)
* [ VECTOR_INDEX_OPTIONS view  ](/bigquery/docs/information-schema-vector-index-options)

* Views

* [ VIEWS view  ](/bigquery/docs/information-schema-views)
* [ MATERIALIZED_VIEWS view  ](/bigquery/docs/information-schema-materialized-views)

* Write API

* [ WRITE_API_TIMELINE view  ](/bigquery/docs/information-schema-write-api)
* [ WRITE_API_TIMELINE_BY_FOLDER view  ](/bigquery/docs/information-schema-write-api-by-folder)
* [ WRITE_API_TIMELINE_BY_ORGANIZATION view  ](/bigquery/docs/information-schema-write-api-by-organization)

* Legacy SQL reference

* [ Migrating to GoogleSQL  ](/bigquery/docs/reference/standard-sql/migrating-from-legacy-sql)
* [ Functions and operators  ](/bigquery/docs/reference/legacy-sql)
* [ Data types  ](/bigquery/docs/data-types)
* [ Querying nested and repeated fields  ](/bigquery/docs/legacy-nested-repeated)
* [ User-defined functions  ](/bigquery/docs/user-defined-functions-legacy)
* [ Table decorators  ](/bigquery/docs/table-decorators)

* BigQuery DataFrames Python API

* [ BigQuery DataFrames  ](/bigquery/docs/reference/bigquery-dataframes)
* BigQuery APIs

* BigQuery API reference

* [ BigQuery APIs and libraries overview  ](/bigquery/docs/reference/libraries-overview)
* BigQuery API reference

* [ BigQuery client libraries  ](/bigquery/docs/reference/libraries)
* [ BigQuery REST API  ](/bigquery/docs/reference/rest)
* REST reference (v2)

* REST Resources

* datasets

* [ Overview  ](/bigquery/docs/reference/rest/v2/datasets)
* [ delete  ](/bigquery/docs/reference/rest/v2/datasets/delete)
* [ get  ](/bigquery/docs/reference/rest/v2/datasets/get)
* [ insert  ](/bigquery/docs/reference/rest/v2/datasets/insert)
* [ list  ](/bigquery/docs/reference/rest/v2/datasets/list)
* [ patch  ](/bigquery/docs/reference/rest/v2/datasets/patch)
* [ undelete  ](/bigquery/docs/reference/rest/v2/datasets/undelete)
* [ update  ](/bigquery/docs/reference/rest/v2/datasets/update)

* jobs

* [ Overview  ](/bigquery/docs/reference/rest/v2/jobs)
* [ cancel  ](/bigquery/docs/reference/rest/v2/jobs/cancel)
* [ delete  ](/bigquery/docs/reference/rest/v2/jobs/delete)
* [ get  ](/bigquery/docs/reference/rest/v2/jobs/get)
* [ getQueryResults  ](/bigquery/docs/reference/rest/v2/jobs/getQueryResults)
* [ insert  ](/bigquery/docs/reference/rest/v2/jobs/insert)
* [ list  ](/bigquery/docs/reference/rest/v2/jobs/list)
* [ query  ](/bigquery/docs/reference/rest/v2/jobs/query)

* models

* [ Overview  ](/bigquery/docs/reference/rest/v2/models)
* [ delete  ](/bigquery/docs/reference/rest/v2/models/delete)
* [ get  ](/bigquery/docs/reference/rest/v2/models/get)
* [ list  ](/bigquery/docs/reference/rest/v2/models/list)
* [ patch  ](/bigquery/docs/reference/rest/v2/models/patch)

* projects

* [ Overview  ](/bigquery/docs/reference/rest/v2/projects)
* [ getServiceAccount  ](/bigquery/docs/reference/rest/v2/projects/getServiceAccount)
* [ list  ](/bigquery/docs/reference/rest/v2/projects/list)

* routines

* [ Overview  ](/bigquery/docs/reference/rest/v2/routines)
* [ delete  ](/bigquery/docs/reference/rest/v2/routines/delete)
* [ get  ](/bigquery/docs/reference/rest/v2/routines/get)
* [ insert  ](/bigquery/docs/reference/rest/v2/routines/insert)
* [ list  ](/bigquery/docs/reference/rest/v2/routines/list)
* [ update  ](/bigquery/docs/reference/rest/v2/routines/update)

* rowAccessPolicies

* [ Overview  ](/bigquery/docs/reference/rest/v2/rowAccessPolicies)
* [ getIamPolicy  ](/bigquery/docs/reference/rest/v2/rowAccessPolicies/getIamPolicy)
* [ list  ](/bigquery/docs/reference/rest/v2/rowAccessPolicies/list)
* [ testIamPermissions  ](/bigquery/docs/reference/rest/v2/rowAccessPolicies/testIamPermissions)

* tabledata

* [ Overview  ](/bigquery/docs/reference/rest/v2/tabledata)
* [ insertAll  ](/bigquery/docs/reference/rest/v2/tabledata/insertAll)
* [ list  ](/bigquery/docs/reference/rest/v2/tabledata/list)

* tables

* [ Overview  ](/bigquery/docs/reference/rest/v2/tables)
* [ delete  ](/bigquery/docs/reference/rest/v2/tables/delete)
* [ get  ](/bigquery/docs/reference/rest/v2/tables/get)
* [ getIamPolicy  ](/bigquery/docs/reference/rest/v2/tables/getIamPolicy)
* [ insert  ](/bigquery/docs/reference/rest/v2/tables/insert)
* [ list  ](/bigquery/docs/reference/rest/v2/tables/list)
* [ patch  ](/bigquery/docs/reference/rest/v2/tables/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/rest/v2/tables/setIamPolicy)
* [ testIamPermissions  ](/bigquery/docs/reference/rest/v2/tables/testIamPermissions)
* [ update  ](/bigquery/docs/reference/rest/v2/tables/update)

* Types

* [ ConnectionProperty  ](/bigquery/docs/reference/rest/v2/ConnectionProperty)
* [ DataFormatOptions  ](/bigquery/docs/reference/rest/v2/DataFormatOptions)
* [ DatasetAccessEntry  ](/bigquery/docs/reference/rest/v2/DatasetAccessEntry)
* [ DmlStats  ](/bigquery/docs/reference/rest/v2/DmlStats)
* [ EncryptionConfiguration  ](/bigquery/docs/reference/rest/v2/EncryptionConfiguration)
* [ GetPolicyOptions  ](/bigquery/docs/reference/rest/v2/GetPolicyOptions)
* [ Job  ](/bigquery/docs/reference/rest/v2/Job)
* [ JobReference  ](/bigquery/docs/reference/rest/v2/JobReference)
* [ Policy  ](/bigquery/docs/reference/rest/v2/Policy)
* [ ProjectReference  ](/bigquery/docs/reference/rest/v2/ProjectReference)
* [ QueryParameter  ](/bigquery/docs/reference/rest/v2/QueryParameter)
* [ RoundingMode  ](/bigquery/docs/reference/rest/v2/RoundingMode)
* [ RowAccessPolicyReference  ](/bigquery/docs/reference/rest/v2/RowAccessPolicyReference)
* [ SessionInfo  ](/bigquery/docs/reference/rest/v2/SessionInfo)
* [ StandardSqlDataType  ](/bigquery/docs/reference/rest/v2/StandardSqlDataType)
* [ StandardSqlField  ](/bigquery/docs/reference/rest/v2/StandardSqlField)
* [ TableReference  ](/bigquery/docs/reference/rest/v2/TableReference)
* [ TargetType  ](/bigquery/docs/reference/rest/v2/TargetType)
* [ TestIamPermissionsResponse  ](/bigquery/docs/reference/rest/v2/TestIamPermissionsResponse)

* [ API uploads  ](/bigquery/docs/reference/api-uploads)

* BigQuery Data Policy API reference

* [ Data Policy REST reference  ](/bigquery/docs/reference/bigquerydatapolicy/rest)
* v1

* REST Resources

* projects.locations.dataPolicies

* [ Overview  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies)
* [ create  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/create)
* [ delete  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/delete)
* [ get  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/get)
* [ getIamPolicy  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/getIamPolicy)
* [ list  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/list)
* [ patch  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/patch)
* [ rename  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/rename)
* [ setIamPolicy  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/setIamPolicy)
* [ testIamPermissions  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1/projects.locations.dataPolicies/testIamPermissions)

* v1beta1

* REST Resources

* projects.locations.dataPolicies

* [ Overview  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies)
* [ create  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/create)
* [ delete  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/delete)
* [ get  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/get)
* [ getIamPolicy  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/getIamPolicy)
* [ list  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/list)
* [ patch  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/setIamPolicy)
* [ testIamPermissions  ](/bigquery/docs/reference/bigquerydatapolicy/rest/v1beta1/projects.locations.dataPolicies/testIamPermissions)

* BigQuery Connections API reference

* [ BigQuery Connection client libraries  ](/bigquery/docs/reference/bigqueryconnection)
* [ BigQuery Connection REST API  ](/bigquery/docs/reference/bigqueryconnection/rest)
* RPC reference

* [ Overview  ](/bigquery/docs/reference/bigqueryconnection/rpc)
* [ google.cloud.bigquery.connection.v1  ](/bigquery/docs/reference/bigqueryconnection/rpc/google.cloud.bigquery.connection.v1)
* [ google.cloud.bigquery.connection.v1beta1  ](/bigquery/docs/reference/bigqueryconnection/rpc/google.cloud.bigquery.connection.v1beta1)
* [ google.iam.v1  ](/bigquery/docs/reference/bigqueryconnection/rpc/google.iam.v1)
* [ google.type  ](/bigquery/docs/reference/bigqueryconnection/rpc/google.type)

* REST reference (v1)

* REST Resources

* projects.locations.connections

* [ Overview  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections)
* [ create  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/create)
* [ delete  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/delete)
* [ get  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/get)
* [ getIamPolicy  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/getIamPolicy)
* [ list  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/list)
* [ patch  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/setIamPolicy)
* [ testIamPermissions  ](/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/testIamPermissions)

* REST reference (v1beta1)

* REST Resources

* projects.locations.connections

* [ Overview  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections)
* [ create  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/create)
* [ delete  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/delete)
* [ get  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/get)
* [ getIamPolicy  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/getIamPolicy)
* [ list  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/list)
* [ patch  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/setIamPolicy)
* [ testIamPermissions  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/testIamPermissions)
* [ updateCredential  ](/bigquery/docs/reference/bigqueryconnection/rest/v1beta1/projects.locations.connections/updateCredential)

* BigQuery Migration API reference

* [ BigQuery Migration client libraries  ](/bigquery/docs/reference/migration)
* [ BigQuery Migration REST API  ](/bigquery/docs/reference/migration/rest)
* REST reference (v2)

* REST Resources

* projects.locations.workflows

* [ Overview  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows)
* [ create  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows/create)
* [ delete  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows/delete)
* [ get  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows/get)
* [ list  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows/list)
* [ start  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows/start)

* projects.locations.workflows.subtasks

* [ Overview  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows.subtasks)
* [ get  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows.subtasks/get)
* [ list  ](/bigquery/docs/reference/migration/rest/v2/projects.locations.workflows.subtasks/list)

* Types

* [ Distribution  ](/bigquery/docs/reference/migration/rest/Shared.Types/Distribution)
* [ ErrorInfo  ](/bigquery/docs/reference/migration/rest/Shared.Types/ErrorInfo)
* [ MetricKind  ](/bigquery/docs/reference/migration/rest/Shared.Types/MetricKind)
* [ ResourceInfo  ](/bigquery/docs/reference/migration/rest/Shared.Types/ResourceInfo)
* [ ValueType  ](/bigquery/docs/reference/migration/rest/Shared.Types/ValueType)

* REST reference (v2alpha)

* REST Resources

* projects.locations.workflows

* [ Overview  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows)
* [ create  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows/create)
* [ delete  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows/delete)
* [ get  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows/get)
* [ list  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows/list)
* [ start  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows/start)

* projects.locations.workflows.subtasks

* [ Overview  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows.subtasks)
* [ get  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows.subtasks/get)
* [ list  ](/bigquery/docs/reference/migration/rest/v2alpha/projects.locations.workflows.subtasks/list)

* RPC reference

* [ Overview  ](/bigquery/docs/reference/migration/rpc)
* [ google.api  ](/bigquery/docs/reference/migration/rpc/google.api)
* [ google.cloud.bigquery.migration.tasks.assessment.v2alpha  ](/bigquery/docs/reference/migration/rpc/google.cloud.bigquery.migration.tasks.assessment.v2alpha)
* [ google.cloud.bigquery.migration.tasks.translation.v2alpha  ](/bigquery/docs/reference/migration/rpc/google.cloud.bigquery.migration.tasks.translation.v2alpha)
* [ google.cloud.bigquery.migration.v2  ](/bigquery/docs/reference/migration/rpc/google.cloud.bigquery.migration.v2)
* [ google.cloud.bigquery.migration.v2alpha  ](/bigquery/docs/reference/migration/rpc/google.cloud.bigquery.migration.v2alpha)
* [ google.rpc  ](/bigquery/docs/reference/migration/rpc/google.rpc)

* BigQuery Storage API reference

* [ Storage API client libraries  ](/bigquery/docs/reference/storage/libraries)
* RPC reference

* [ Overview  ](/bigquery/docs/reference/storage/rpc)
* [ google.cloud.bigquery.storage.v1  ](/bigquery/docs/reference/storage/rpc/google.cloud.bigquery.storage.v1)
* [ google.cloud.bigquery.storage.v1beta1  ](/bigquery/docs/reference/storage/rpc/google.cloud.bigquery.storage.v1beta1)
* [ google.cloud.bigquery.storage.v1beta2  ](/bigquery/docs/reference/storage/rpc/google.cloud.bigquery.storage.v1beta2)
* [ google.rpc  ](/bigquery/docs/reference/storage/rpc/google.rpc)

* BigQuery Reservation API reference

* [ BigQuery Reservation API client libraries  ](/bigquery/docs/reference/reservations)
* [ BigQuery Reservation REST API  ](/bigquery/docs/reference/reservations/rest)
* RPC reference

* [ Overview  ](/bigquery/docs/reference/reservations/rpc)
* [ google.cloud.bigquery.reservation.v1  ](/bigquery/docs/reference/reservations/rpc/google.cloud.bigquery.reservation.v1)
* [ google.rpc  ](/bigquery/docs/reference/reservations/rpc/google.rpc)

* REST reference (v1)

* REST Resources

* projects.locations

* [ Overview  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations)
* [ getBiReservation  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations/getBiReservation)
* [ searchAllAssignments  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations/searchAllAssignments)
* [ searchAssignments  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations/searchAssignments)
* [ updateBiReservation  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations/updateBiReservation)

* projects.locations.capacityCommitments

* [ Overview  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments)
* [ create  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments/create)
* [ delete  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments/delete)
* [ get  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments/get)
* [ list  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments/list)
* [ merge  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments/merge)
* [ patch  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments/patch)
* [ split  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.capacityCommitments/split)

* projects.locations.reservations

* [ Overview  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations)
* [ create  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations/create)
* [ delete  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations/delete)
* [ get  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations/get)
* [ list  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations/list)
* [ patch  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations/patch)

* projects.locations.reservations.assignments

* [ Overview  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations.assignments)
* [ create  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations.assignments/create)
* [ delete  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations.assignments/delete)
* [ list  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations.assignments/list)
* [ move  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations.assignments/move)
* [ patch  ](/bigquery/docs/reference/reservations/rest/v1/projects.locations.reservations.assignments/patch)

* Types

* [ BiReservation  ](/bigquery/docs/reference/reservations/rest/v1/BiReservation)
* [ Edition  ](/bigquery/docs/reference/reservations/rest/v1/Edition)

* BigQuery Analytics Hub API reference

* [ Analytics Hub client libraries  ](/bigquery/docs/reference/analytics-hub)
* [ Analytics Hub REST API  ](/bigquery/docs/reference/analytics-hub/rest)
* REST reference (v1)

* REST Resources

* organizations.locations.dataExchanges

* [ Overview  ](/bigquery/docs/reference/analytics-hub/rest/v1/organizations.locations.dataExchanges)
* [ list  ](/bigquery/docs/reference/analytics-hub/rest/v1/organizations.locations.dataExchanges/list)

* projects.locations.dataExchanges

* [ Overview  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges)
* [ create  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/create)
* [ delete  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/delete)
* [ get  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/get)
* [ getIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/getIamPolicy)
* [ list  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/list)
* [ listSubscriptions  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/listSubscriptions)
* [ patch  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/setIamPolicy)
* [ subscribe  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/subscribe)
* [ testIamPermissions  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges/testIamPermissions)

* projects.locations.dataExchanges.listings

* [ Overview  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings)
* [ create  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/create)
* [ delete  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/delete)
* [ get  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/get)
* [ getIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/getIamPolicy)
* [ list  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/list)
* [ listSubscriptions  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/listSubscriptions)
* [ patch  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/setIamPolicy)
* [ subscribe  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/subscribe)
* [ testIamPermissions  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.dataExchanges.listings/testIamPermissions)

* projects.locations.subscriptions

* [ Overview  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.subscriptions)
* [ delete  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.subscriptions/delete)
* [ get  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.subscriptions/get)
* [ list  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.subscriptions/list)
* [ refresh  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.subscriptions/refresh)
* [ revoke  ](/bigquery/docs/reference/analytics-hub/rest/v1/projects.locations.subscriptions/revoke)

* Types

* [ ListSharedResourceSubscriptionsResponse  ](/bigquery/docs/reference/analytics-hub/rest/v1/ListSharedResourceSubscriptionsResponse)
* [ Operation  ](/bigquery/docs/reference/analytics-hub/rest/v1/Operation)

* REST reference (v1beta1)

* REST Resources

* organizations.locations.dataExchanges

* [ Overview  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/organizations.locations.dataExchanges)
* [ list  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/organizations.locations.dataExchanges/list)

* projects.locations.dataExchanges

* [ Overview  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges)
* [ create  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/create)
* [ delete  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/delete)
* [ get  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/get)
* [ getIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/getIamPolicy)
* [ list  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/list)
* [ patch  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/setIamPolicy)
* [ testIamPermissions  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges/testIamPermissions)

* projects.locations.dataExchanges.listings

* [ Overview  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings)
* [ create  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/create)
* [ delete  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/delete)
* [ get  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/get)
* [ getIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/getIamPolicy)
* [ list  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/list)
* [ patch  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/patch)
* [ setIamPolicy  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/setIamPolicy)
* [ subscribe  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/subscribe)
* [ testIamPermissions  ](/bigquery/docs/reference/analytics-hub/rest/v1beta1/projects.locations.dataExchanges.listings/testIamPermissions)

* BigQuery Data Transfer Service API reference

* [ BigQuery Data Transfer Service client libraries  ](/bigquery/docs/reference/datatransfer/libraries)
* [ BigQuery Data Transfer Service REST API  ](/bigquery/docs/reference/datatransfer/rest)
* REST reference

* REST Resources

* projects

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects)
* [ enrollDataSources  ](/bigquery/docs/reference/datatransfer/rest/v1/projects/enrollDataSources)

* projects.dataSources

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.dataSources)
* [ checkValidCreds  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.dataSources/checkValidCreds)
* [ get  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.dataSources/get)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.dataSources/list)

* projects.locations

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations)
* [ enrollDataSources  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations/enrollDataSources)
* [ get  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations/get)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations/list)
* [ unenrollDataSources  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations/unenrollDataSources)

* projects.locations.dataSources

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.dataSources)
* [ checkValidCreds  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/checkValidCreds)
* [ get  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/get)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list)

* projects.locations.transferConfigs

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs)
* [ create  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/create)
* [ delete  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/delete)
* [ get  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/get)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/list)
* [ patch  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/patch)
* [ scheduleRuns  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/scheduleRuns)
* [ startManualRuns  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/startManualRuns)

* projects.locations.transferConfigs.runs

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs.runs)
* [ delete  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs.runs/delete)
* [ get  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs.runs/get)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs.runs/list)

* projects.locations.transferConfigs.runs.transferLogs

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs.runs.transferLogs)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs.runs.transferLogs/list)

* projects.transferConfigs

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs)
* [ create  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs/create)
* [ delete  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs/delete)
* [ get  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs/get)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs/list)
* [ patch  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs/patch)
* [ scheduleRuns  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs/scheduleRuns)
* [ startManualRuns  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs/startManualRuns)

* projects.transferConfigs.runs

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs.runs)
* [ delete  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs.runs/delete)
* [ get  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs.runs/get)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs.runs/list)

* projects.transferConfigs.runs.transferLogs

* [ Overview  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs.runs.transferLogs)
* [ list  ](/bigquery/docs/reference/datatransfer/rest/v1/projects.transferConfigs.runs.transferLogs/list)

* Types

* [ CheckValidCredsResponse  ](/bigquery/docs/reference/datatransfer/rest/v1/CheckValidCredsResponse)
* [ Code  ](/bigquery/docs/reference/datatransfer/rest/v1/Code)
* [ EmailPreferences  ](/bigquery/docs/reference/datatransfer/rest/v1/EmailPreferences)
* [ ListDataSourcesResponse  ](/bigquery/docs/reference/datatransfer/rest/v1/ListDataSourcesResponse)
* [ ListTransferConfigsResponse  ](/bigquery/docs/reference/datatransfer/rest/v1/ListTransferConfigsResponse)
* [ ListTransferLogsResponse  ](/bigquery/docs/reference/datatransfer/rest/v1/ListTransferLogsResponse)
* [ ListTransferRunsResponse  ](/bigquery/docs/reference/datatransfer/rest/v1/ListTransferRunsResponse)
* [ RunAttempt  ](/bigquery/docs/reference/datatransfer/rest/v1/RunAttempt)
* [ ScheduleTransferRunsResponse  ](/bigquery/docs/reference/datatransfer/rest/v1/ScheduleTransferRunsResponse)
* [ StartManualTransferRunsResponse  ](/bigquery/docs/reference/datatransfer/rest/v1/StartManualTransferRunsResponse)
* [ TimeRange  ](/bigquery/docs/reference/datatransfer/rest/v1/TimeRange)
* [ TransferState  ](/bigquery/docs/reference/datatransfer/rest/v1/TransferState)

* RPC reference

* [ Overview  ](/bigquery/docs/reference/datatransfer/rpc)
* [ google.cloud.bigquery.datatransfer.v1  ](/bigquery/docs/reference/datatransfer/rpc/google.cloud.bigquery.datatransfer.v1)
* [ google.cloud.location  ](/bigquery/docs/reference/datatransfer/rpc/google.cloud.location)
* [ google.rpc  ](/bigquery/docs/reference/datatransfer/rpc/google.rpc)

* BigQuery BigLake API reference

* [ BigLake REST API  ](/bigquery/docs/reference/biglake/rest)
* REST reference (v1)

* REST Resources

* projects.locations.catalogs

* [ Overview  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs)
* [ create  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs/create)
* [ delete  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs/delete)
* [ get  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs/get)
* [ list  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs/list)

* projects.locations.catalogs.databases

* [ Overview  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases)
* [ create  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases/create)
* [ delete  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases/delete)
* [ get  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases/get)
* [ list  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases/list)
* [ patch  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases/patch)

* projects.locations.catalogs.databases.tables

* [ Overview  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases.tables)
* [ create  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases.tables/create)
* [ delete  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases.tables/delete)
* [ get  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases.tables/get)
* [ list  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases.tables/list)
* [ patch  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases.tables/patch)
* [ rename  ](/bigquery/docs/reference/biglake/rest/v1/projects.locations.catalogs.databases.tables/rename)

* REST reference (v1alpha1)

* REST Resources

* projects.locations.catalogs

* [ Overview  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs)
* [ create  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs/create)
* [ delete  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs/delete)
* [ get  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs/get)
* [ list  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs/list)

* projects.locations.catalogs.databases

* [ Overview  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases)
* [ create  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases/create)
* [ delete  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases/delete)
* [ get  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases/get)
* [ list  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases/list)
* [ patch  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases/patch)

* projects.locations.catalogs.databases.locks

* [ Overview  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.locks)
* [ check  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.locks/check)
* [ create  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.locks/create)
* [ delete  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.locks/delete)
* [ list  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.locks/list)

* projects.locations.catalogs.databases.tables

* [ Overview  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.tables)
* [ create  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.tables/create)
* [ delete  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.tables/delete)
* [ get  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.tables/get)
* [ list  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.tables/list)
* [ patch  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.tables/patch)
* [ rename  ](/bigquery/docs/reference/biglake/rest/v1alpha1/projects.locations.catalogs.databases.tables/rename)

* BigQuery routines

* [ System procedures reference  ](/bigquery/docs/reference/system-procedures)
* [ System variables reference  ](/bigquery/docs/reference/system-variables)
* BigQuery audit logging

* BigQuery audit logging reference

* [ Overview  ](/bigquery/docs/reference/auditlogs)
* Types

* [ AuditData  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/AuditData)
* [ AuditLogConfig.LogType  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/AuditLogConfig.LogType)
* [ BigQueryAuditMetadata  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata)
* [ BigQueryAuditMetadata.AccessChange.Action  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.AccessChange.Action)
* [ BigQueryAuditMetadata.ConnectionChange.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.ConnectionChange.Reason)
* [ BigQueryAuditMetadata.CreateDisposition  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.CreateDisposition)
* [ BigQueryAuditMetadata.DatasetChange.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.DatasetChange.Reason)
* [ BigQueryAuditMetadata.DatasetCreation.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.DatasetCreation.Reason)
* [ BigQueryAuditMetadata.DatasetDeletion.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.DatasetDeletion.Reason)
* [ BigQueryAuditMetadata.JobConfig.Query.Priority  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.JobConfig.Query.Priority)
* [ BigQueryAuditMetadata.JobConfig.Type  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.JobConfig.Type)
* [ BigQueryAuditMetadata.JobDeletion.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.JobDeletion.Reason)
* [ BigQueryAuditMetadata.JobInsertion.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.JobInsertion.Reason)
* [ BigQueryAuditMetadata.JobState  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.JobState)
* [ BigQueryAuditMetadata.ModelCreation.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.ModelCreation.Reason)
* [ BigQueryAuditMetadata.ModelDataChange.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.ModelDataChange.Reason)
* [ BigQueryAuditMetadata.ModelDataRead.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.ModelDataRead.Reason)
* [ BigQueryAuditMetadata.ModelDeletion.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.ModelDeletion.Reason)
* [ BigQueryAuditMetadata.ModelMetadataChange.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.ModelMetadataChange.Reason)
* [ BigQueryAuditMetadata.OperationType  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.OperationType)
* [ BigQueryAuditMetadata.QueryStatementType  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.QueryStatementType)
* [ BigQueryAuditMetadata.RoutineChange.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.RoutineChange.Reason)
* [ BigQueryAuditMetadata.RoutineCreation.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.RoutineCreation.Reason)
* [ BigQueryAuditMetadata.RoutineDeletion.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.RoutineDeletion.Reason)
* [ BigQueryAuditMetadata.SearchIndexCreation.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.SearchIndexCreation.Reason)
* [ BigQueryAuditMetadata.SearchIndexDeletion.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.SearchIndexDeletion.Reason)
* [ BigQueryAuditMetadata.TableChange.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.TableChange.Reason)
* [ BigQueryAuditMetadata.TableCreation.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.TableCreation.Reason)
* [ BigQueryAuditMetadata.TableDataChange.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.TableDataChange.Reason)
* [ BigQueryAuditMetadata.TableDataRead.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.TableDataRead.Reason)
* [ BigQueryAuditMetadata.TableDeletion.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.TableDeletion.Reason)
* [ BigQueryAuditMetadata.UnlinkDataset.Reason  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.UnlinkDataset.Reason)
* [ BigQueryAuditMetadata.WriteDisposition  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BigQueryAuditMetadata.WriteDisposition)
* [ BindingDelta.Action  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/BindingDelta.Action)
* [ DatasetAccessEntry  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/DatasetAccessEntry)
* [ DatasetAccessEntry.TargetType  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/DatasetAccessEntry.TargetType)
* [ Expr  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/Expr)
* [ JoinRestrictionPolicy.JoinCondition  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/JoinRestrictionPolicy.JoinCondition)
* [ Policy  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/Policy)
* [ RoutineReference  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/RoutineReference)
* [ Status  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/Status)
* [ TableReference  ](/bigquery/docs/reference/auditlogs/rest/Shared.Types/TableReference)

* [ AI solutions, generative AI, and ML  ](/docs/ai-ml)
* [ Application development  ](/docs/application-development)
* [ Application hosting  ](/docs/application-hosting)
* [ Compute  ](/docs/compute-area)
* [ Data analytics and pipelines  ](/docs/data)
* [ Databases  ](/docs/databases)
* [ Distributed, hybrid, and multicloud  ](/docs/dhm-cloud)
* [ Industry solutions  ](/docs/industry)
* [ Networking  ](/docs/networking)
* [ Observability and monitoring  ](/docs/observability)
* [ Security  ](/docs/security)
* [ Storage  ](/docs/storage)

* [ Access and resources management  ](/docs/access-resources)
* [ Cloud SDK, languages, frameworks, and tools  ](/docs/devtools)
* [ Costs and usage management  ](/docs/costs-usage)
* [ Infrastructure as code  ](/docs/iac)
* [ Migration  ](/docs/migration)

* [ Google Cloud Home  ](/)
* [ Free Trial and Free Tier  ](/free)
* [ Architecture Center  ](/architecture)
* [ Blog  ](https://cloud.google.com/blog)
* [ Contact Sales  ](/contact)
* [ Google Cloud Developer Center  ](/developers)
* [ Google Developer Center  ](https://developers.google.com/)
* [ Google Cloud Marketplace (in console)  ](https://console.cloud.google.com/marketplace)
* [ Google Cloud Marketplace Documentation  ](/marketplace/docs)
* [ Google Cloud Skills Boost  ](https://www.cloudskillsboost.google/paths)
* [ Google Cloud Solution Center  ](/solutions)
* [ Google Cloud Support  ](/support-hub)
* [ Google Cloud Tech Youtube Channel  ](https://www.youtube.com/@googlecloudtech)

* [ Home ](https://cloud.google.com/)
* [ BigQuery ](https://cloud.google.com/bigquery)
* [ Documentation ](https://cloud.google.com/bigquery/docs)
* [ Reference ](https://cloud.google.com/bigquery/quotas)

Send feedback  Stay organized with collections  Save and categorize content
based on your preferences.

#  The CREATE MODEL statement

To create a model in BigQuery, use the BigQuery ML ` CREATE MODEL ` statement.
This statement is similar to the [ ` CREATE TABLE ` ](/bigquery/docs/data-
definition-language#create_table_statement) DDL statement. When you run a
query that contains a ` CREATE MODEL ` statement, a [ query job
](/bigquery/docs/jobs-overview) is generated for you that processes the query.

For information about supported model types of each SQL statement and
function, and all supported SQL statements and functions for each model type,
read [ End-to-end user journey for each model
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-e2e-journey) .

**Note:** This syntax statement provides a comprehensive list of model types
with their model options. When creating a model, use that model specific `
CREATE MODEL ` statement for convenience. You can view specific ` CREATE MODEL
` statements by clicking the ` MODEL_TYPE ` name in list below, in the table
of contents in the left panel, or in the _create model_ link in the [ End-to-
end user journey for each model ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-e2e-journey) .

##  ` CREATE MODEL ` syntax



{CREATE MODEL | CREATE MODEL IF NOT EXISTS | CREATE OR REPLACE MODEL}
model_name
[TRANSFORM (select_list)]
[INPUT (field_name field_type)
OUTPUT (field_name field_type)]
[REMOTE WITH CONNECTION `connection_name`]
[OPTIONS(model_option_list)]
[AS {query_statement |
(
training_data AS (query_statement),
custom_holiday AS (holiday_statement)
)}]

model_option_list:
MODEL_TYPE = { ['LINEAR_REG'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-glm) |
['LOGISTIC_REG'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-glm) |
['KMEANS'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-kmeans) |
['MATRIX_FACTORIZATION'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-matrix-factorization) |
['PCA'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-pca) |
['AUTOENCODER'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-autoencoder) |
['AUTOML_CLASSIFIER'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-automl) |
['AUTOML_REGRESSOR'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-automl) |
['BOOSTED_TREE_CLASSIFIER'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree) |
['BOOSTED_TREE_REGRESSOR'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree) |
['RANDOM_FOREST_CLASSIFIER'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-random-forest) |
['RANDOM_FOREST_REGRESSOR'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-random-forest) |
['DNN_CLASSIFIER'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-models) |
['DNN_REGRESSOR'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-models) |
['DNN_LINEAR_COMBINED_CLASSIFIER'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-wnd-models) |
['DNN_LINEAR_COMBINED_REGRESSOR'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-wnd-models) |
['ARIMA_PLUS'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-time-series) |
['ARIMA_PLUS_XREG'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-multivariate-time-series) |
['TENSORFLOW'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tensorflow) |
['TENSORFLOW_LITE'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tflite) |
['ONNX'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-onnx) |
['XGBOOST'](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-xgboost)}
[, MODEL_REGISTRY = { 'VERTEX_AI' } ]
[, VERTEX_AI_MODEL_ID = string_value ]
[, VERTEX_AI_MODEL_VERSION_ALIASES = string_array ]
[, INPUT_LABEL_COLS = string_array ]
[, MAX_ITERATIONS = int64_value ]
[, EARLY_STOP = { TRUE | FALSE } ]
[, MIN_REL_PROGRESS = float64_value ]
[, DATA_SPLIT_METHOD = { 'AUTO_SPLIT' | 'RANDOM' | 'CUSTOM' | 'SEQ' | 'NO_SPLIT' } ]
[, DATA_SPLIT_EVAL_FRACTION = float64_value ]
[, DATA_SPLIT_TEST_FRACTION = float64_value ]
[, DATA_SPLIT_COL = string_value ]
[, OPTIMIZE_STRATEGY = { 'AUTO_STRATEGY' | 'BATCH_GRADIENT_DESCENT' | 'NORMAL_EQUATION' } ]
[, L1_REG = float64_value ]
[, L2_REG = float64_value ]
[, LEARN_RATE_STRATEGY = { 'LINE_SEARCH' | 'CONSTANT' } ]
[, LEARN_RATE = float64_value ]
[, LS_INIT_LEARN_RATE = float64_value ]
[, WARM_START = { TRUE | FALSE } ]
[, AUTO_CLASS_WEIGHTS = { TRUE | FALSE } ]
[, CLASS_WEIGHTS = struct_array ]
[, INSTANCE_WEIGHT_COL = string_value ]
[, NUM_CLUSTERS = int64_value ]
[, KMEANS_INIT_METHOD = { 'RANDOM' | 'KMEANS++' | 'CUSTOM' } ]
[, KMEANS_INIT_COL = string_value ]
[, DISTANCE_TYPE = { 'EUCLIDEAN' | 'COSINE' } ]
[, STANDARDIZE_FEATURES = { TRUE | FALSE } ]
[, MODEL_PATH = string_value ]
[, BUDGET_HOURS = float64_value ]
[, FEEDBACK_TYPE = {'EXPLICIT' | 'IMPLICIT'} ]
[, NUM_FACTORS = int64_value ]
[, USER_COL = string_value ]
[, ITEM_COL = string_value ]
[, RATING_COL = string_value ]
[, WALS_ALPHA = float64_value ]
[, BOOSTER_TYPE = { 'gbtree' | 'dart'} ]
[, NUM_PARALLEL_TREE = int64_value ]
[, DART_NORMALIZE_TYPE = { 'tree' | 'forest'} ]
[, TREE_METHOD = { 'auto' | 'exact' | 'approx' | 'hist'} ]
[, MIN_TREE_CHILD_WEIGHT = float64_value ]
[, COLSAMPLE_BYTREE = float64_value ]
[, COLSAMPLE_BYLEVEL = float64_value ]
[, COLSAMPLE_BYNODE = float64_value ]
[, MIN_SPLIT_LOSS = float64_value ]
[, MAX_TREE_DEPTH = int64_value ]
[, SUBSAMPLE = float64_value ]
[, ACTIVATION_FN = { 'RELU' | 'RELU6' | 'CRELU' | 'ELU' | 'SELU' | 'SIGMOID' | 'TANH' } ]
[, BATCH_SIZE = int64_value ]
[, DROPOUT = float64_value ]
[, HIDDEN_UNITS = int_array ]
[, OPTIMIZER = { 'ADAGRAD' | 'ADAM' | 'FTRL' | 'RMSPROP' | 'SGD' } ]
[, TIME_SERIES_TIMESTAMP_COL = string_value ]
[, TIME_SERIES_DATA_COL = string_value ]
[, TIME_SERIES_ID_COL = { string_value | string_array } ]
[, HORIZON = int64_value ]
[, AUTO_ARIMA = { TRUE | FALSE } ]
[, AUTO_ARIMA_MAX_ORDER = int64_value ]
[, AUTO_ARIMA_MIN_ORDER = int64_value ]
[, NON_SEASONAL_ORDER = (int64_value, int64_value, int64_value) ]
[, DATA_FREQUENCY = { 'AUTO_FREQUENCY' | 'PER_MINUTE' | 'HOURLY' | 'DAILY' | 'WEEKLY' | ... } ]
[, FORECAST_LIMIT_LOWER_BOUND = float64_value  ]
[, FORECAST_LIMIT_UPPER_BOUND = float64_value  ]
[, INCLUDE_DRIFT = { TRUE | FALSE } ]
[, HOLIDAY_REGION = { 'GLOBAL' | 'NA' | 'JAPAC' | 'EMEA' | 'LAC' | 'AE' | ... } ]
[, CLEAN_SPIKES_AND_DIPS = { TRUE | FALSE } ]
[, ADJUST_STEP_CHANGES = { TRUE | FALSE } ]
[, DECOMPOSE_TIME_SERIES = { TRUE | FALSE } ]
[, HIERARCHICAL_TIME_SERIES_COLS = { string_array } ]
[, ENABLE_GLOBAL_EXPLAIN = { TRUE | FALSE } ]
[, APPROX_GLOBAL_FEATURE_CONTRIB = { TRUE | FALSE }]
[, INTEGRATED_GRADIENTS_NUM_STEPS = int64_value ]
[, CALCULATE_P_VALUES = { TRUE | FALSE } ]
[, FIT_INTERCEPT = { TRUE | FALSE } ]
[, CATEGORY_ENCODING_METHOD = { 'ONE_HOT_ENCODING' | 'DUMMY_ENCODING' | 'LABEL_ENCODING' | 'TARGET_ENCODING' } ]
[, ENDPOINT = string_value ]
[, REMOTE_SERVICE_TYPE = { 'CLOUD_AI_VISION_V1' | 'CLOUD_AI_NATURAL_LANGUAGE_V1' | 'CLOUD_AI_TRANSLATE_V3' } ]
[, XGBOOST_VERSION = { '0.9' | '1.1' } ]
[, TF_VERSION = { '1.15' | '2.8.0' } ]
[, NUM_TRIALS = int64_value, ]
[, MAX_PARALLEL_TRIALS = int64_value ]
[, HPARAM_TUNING_ALGORITHM = { 'VIZIER_DEFAULT' | 'RANDOM_SEARCH' | 'GRID_SEARCH' } ]
[, HPARAM_TUNING_OBJECTIVES = { 'R2_SCORE' | 'ROC_AUC' | ... } ]


###  ` CREATE MODEL `

Creates and trains a new model in the specified dataset. If the model name
exists, ` CREATE MODEL ` returns an error.

###  ` CREATE MODEL IF NOT EXISTS `

Creates and trains a new model only if the model does not exist in the
specified dataset.

###  ` CREATE OR REPLACE MODEL `

Creates and trains a model and replaces an existing model with the same name
in the specified dataset.

###  ` model_name `

` model_name ` is the name of the model you're creating or replacing. The
model name must be unique per dataset: no other model or table can have the
same name. The model name must follow the same naming rules as a BigQuery
table. A model name can:

* Contain up to 1,024 characters
* Contain letters (upper or lower case), numbers, and underscores

` model_name ` is not case-sensitive.

If you don't have a default project configured, prepend the project ID to the
model name in following format, including backticks: `
`[PROJECT_ID].[DATASET].[MODEL]` ` ; for example, `
`myproject.mydataset.mymodel` ` .

###  ` TRANSFORM `

TRANSFORM lets you specify all preprocessing during model creation and have it
automatically applied during prediction and evaluation.

For example, you can create the following model:



CREATE OR REPLACE MODEL `myproject.mydataset.mymodel`
TRANSFORM(ML.FEATURE_CROSS(STRUCT(f1, f2)) as cross_f,
ML.QUANTILE_BUCKETIZE(f3) OVER() as buckets,
label_col)
OPTIONS(model_type='linear_reg', input_label_cols=['label_col'])
AS SELECT * FROM t


During prediction, you don't need to preprocess the input again, and the same
transformations are automatically restored:



SELECT * FROM ML.PREDICT(MODEL `myproject.mydataset.mymodel`, (SELECT f1, f2, f3 FROM table))


When the ` TRANSFORM ` clause is present, only output columns from the `
TRANSFORM ` clause are used in training. Any results from ` query_statement `
that don't appear in the ` TRANSFORM ` clause are ignored.

The input columns of the ` TRANSFORM ` clause are the result of `
query_statement ` . So, the final input used in training is the set of columns
generated by the following query:



SELECT (select_list) FROM (query_statement);


Input columns of the ` TRANSFORM ` clause can be of any SIMPLE type or ARRAY
of SIMPLE type. SIMPLE types are non-STRUCT and non-ARRAY data types.

In prediction ( ` ML.PREDICT ` ), users only need to pass in the original
columns from the ` query_statement ` that are used inside the ` TRANSFORM `
clause. The columns dropped in ` TRANSFORM ` don't need to be provided during
prediction. ` TRANSFORM ` is automatically applied to the input data during
prediction, including the statistics used in ML analytic functions (for
example, ` ML.QUANTILE_BUCKETIZE ` ).

To learn more about feature preprocessing, see [ Feature preprocessing
overview ](/bigquery/docs/preprocess-overview) , or try the [ Feature
Engineering Functions ](https://github.com/GoogleCloudPlatform/bigquery-ml-
utils/blob/master/notebooks/bqml-preprocessing-functions.ipynb) notebook.

To try using the ` TRANSFORM ` clause, try the [ Use the BigQuery ML `
TRANSFORM ` clause for feature engineering ](/bigquery/docs/bigqueryml-
transform) tutorial or the [ Create Model With Inline Transpose
](https://github.com/GoogleCloudPlatform/bigquery-ml-
utils/blob/master/notebooks/bqml-feature-engineering.ipynb) notebook.

###  ` select_list `

You can pass columns from ` query_statement ` through to model training
without transformation by either using ` * ` , ` * EXCEPT() ` , or by listing
the column names directly.

Not all columns from ` query_statement ` are required to appear in the `
TRANSFORM ` clause, so you can drop columns appearing in ` query_statement `
by omitting them from the ` TRANSFORM ` clause.

You can transform inputs from ` query_statement ` by using expressions in `
select_list ` . ` select_list ` is similar to a normal ` SELECT ` statement. `
select_list ` supports the following syntax:

* ` * `
* ` * EXCEPT() `
* ` * REPLACE() `
* ` expression `
* ` expression.* `

The following cannot appear inside ` select_list ` :

* Aggregation functions.
* Non-BigQuery ML analytic functions. For more information about supported functions, see [ Manual feature preprocessing ](/bigquery/docs/manual-preprocessing) .
* UDFs.
* Subqueries.
* Anonymous columns. For example, ` a + b as c ` is allowed, while ` a + b ` isn't.

The output columns of ` select_list ` can be of any BigQuery supported data
type.

If present, the following columns must appear in ` select_list ` without
transformation:

* ` label `
* ` data_split_col `
* ` kmeans_init_col `
* ` instance_weight_col `

If these columns are returned by ` query_statement ` , you must reference them
in ` select_list ` by column name outside of any expression, or by using ` * `
. You can't use aliases with these columns.

###  ` INPUT ` and ` OUTPUT `

` INPUT ` and ` OUTPUT ` clauses are used to specify input and output format
for [ remote models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-remote-model) or [ XGBoost models ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-xgboost) .

####  ` field_name `

For remote models, ` INPUT ` and ` OUTPUT ` field names must be identical as
the field names of the Vertex AI endpoint request and response. See examples
in [ remote model ` INPUT ` and ` OUTPUT ` clause
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-
model#in-out-state) .

For XGBoost models, ` INPUT ` field names must be identical to the names in
the ` feature_names ` field if ` feature_names ` field is populated in the
XGBoost model file. See [ XGBoost INPUT OUTPUT clause
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
xgboost#input_output_clause) for more details.

####  ` field_type `

[ Remote models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-remote-model) support the following BigQuery data types for ` INPUT `
and ` OUTPUT ` clauses:

* Simple type: [ BOOL ](/bigquery/docs/reference/standard-sql/data-types#boolean_type) , [ INT64 ](/bigquery/docs/reference/standard-sql/data-types#integer_type) , [ FLOAT64 ](/bigquery/docs/reference/standard-sql/data-types#floating_point_types) , [ NUMERIC ](/bigquery/docs/reference/standard-sql/data-types#decimal_types) , [ BIGNUMERIC ](/bigquery/docs/reference/standard-sql/data-types#decimal_types) , [ STRING ](/bigquery/docs/reference/standard-sql/data-types#string_type)
* [ ARRAY ](/bigquery/docs/reference/standard-sql/data-types#array_type) <Simple type>

[ XGBoost models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-xgboost) support the following BigQuery data types for ` INPUT ` field
type:

* [ Numeric type ](/bigquery/docs/reference/standard-sql/data-types#numeric_types)
* [ ARRAY ](/bigquery/docs/reference/standard-sql/data-types#array_type) <Numeric type>

[ XGBoost models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-xgboost) only support [ FLOAT64 ](/bigquery/docs/reference/standard-
sql/data-types#floating_point_types) for ` OUTPUT ` field type.

###  ` connection_name `

BigQuery uses a ` CLOUD_RESOURCE ` [ connection ](/bigquery/docs/create-cloud-
resource-connection) to interact with your Vertex AI endpoint. You need to
grant [ Vertex AI User role ](/vertex-ai/docs/general/access-
control#aiplatform.user) to connection's service account on your Vertex AI
endpoint project.

See examples in [ remote model ` CONNECTION ` statement
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-
model#connection)

###  ` model_option_list `

` CREATE MODEL ` supports the following options:

####  ` MODEL_TYPE `

**Syntax**



MODEL_TYPE = { 'LINEAR_REG' | 'LOGISTIC_REG' | 'KMEANS' | 'PCA' |
'MATRIX_FACTORIZATION' | 'AUTOENCODER' | 'AUTOML_REGRESSOR' |
'AUTOML_CLASSIFIER' | 'BOOSTED_TREE_CLASSIFIER' | 'BOOSTED_TREE_REGRESSOR' |
'RANDOM_FOREST_CLASSIFIER' | 'RANDOM_FOREST_REGRESSOR' |
'DNN_CLASSIFIER' | 'DNN_REGRESSOR' | 'DNN_LINEAR_COMBINED_CLASSIFIER' |
'DNN_LINEAR_COMBINED_REGRESSOR' | 'ARIMA_PLUS' | 'ARIMA_PLUS_XREG' |
'TENSORFLOW' | 'TENSORFLOW_LITE' | 'ONNX' | 'XGBOOST'}


**Description**

Specify the model type. This argument is required.

**Arguments**

The argument is in the model type column.  Model category  |  Model type  |
Description  |  Model specific CREATE MODEL statement
---|---|---|---
Regression  |  ` 'LINEAR_REG' ` |  Linear regression for real-valued label
prediction; for example, the sales of an item on a given day.  |  [ CREATE
MODEL statement for generalized linear models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-glm)
` 'BOOSTED_TREE_REGRESSOR' ` |  Create a boosted tree regressor model using
the XGBoost library.  |  [ CREATE MODEL statement for boosted tree models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)
` 'RANDOM_FOREST_REGRESSOR' ` |  Create a random forest regressor model using
the XGBoost library.  |  [ CREATE MODEL statement for random forest models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-random-
forest)
` 'DNN_REGRESSOR' ` |  Create a Deep Neural Network Regressor model.  |  [
CREATE MODEL statement for DNN models ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-dnn-models)
` 'DNN_LINEAR_COMBINED_REGRESSOR' ` |  Create a Wide-and-Deep Regressor model.
|  [ CREATE MODEL statement for Wide-and-Deep models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-wnd-models)
` 'AUTOML_REGRESSOR' ` |  Create a regression model using AutoML.  |  [ CREATE
MODEL statement for AutoML models ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-automl)
Classification  |  ` 'LOGISTIC_REG' ` |  Logistic regression for binary-class
or multi-class classification; for example, determining whether a customer
will make a purchase.  |  [ CREATE MODEL statement for generalized linear
models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-glm)
` 'BOOSTED_TREE_CLASSIFIER' ` |  Create a boosted tree classifier model using
the XGBoost library.  |  [ CREATE MODEL statement for boosted tree models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)
` 'RANDOM_FOREST_CLASSIFIER' ` |  Create a random forest classifier model
using the XGBoost library.  |  [ CREATE MODEL statement for random forest
models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
random-forest)
` 'DNN_CLASSIFIER' ` |  Create a Deep Neural Network Classifier model.  |  [
CREATE MODEL statement for DNN models ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-dnn-models)
` 'DNN_LINEAR_COMBINED_CLASSIFIER' ` |  Create a Wide-and-Deep Classifier
model.  |  [ CREATE MODEL statement for Wide-and-Deep models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-wnd-models)
` 'AUTOML_CLASSIFIER' ` |  Create a classification model using AutoML.  |  [
CREATE MODEL statement for AutoML models ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-automl)
Clustering  |  ` 'KMEANS' ` |  K-means clustering for data segmentation; for
example, identifying customer segments.  |  [ CREATE MODEL statement for
K-means models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-kmeans)
Collaborative Filtering  |  ` 'MATRIX_FACTORIZATION' ` |  Matrix factorization
for recommendation systems. For example, given a set of users, items, and some
ratings for a subset of the items, creates a model to predict a user's rating
for items they have not rated.  |  [ CREATE MODEL statement for matrix
factorization models ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization)
Dimensionality Reduction  |  ` 'PCA' ` |  Principal component analysis for
dimensionality reduction.  |  [ CREATE MODEL statement for PCA models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-pca)
` 'AUTOENCODER' ` |  Create an Autoencoder model for anomaly detection,
dimensionality reduction, and embedding purposes.  |  [ CREATE MODEL statement
for Autoencoder model ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-autoencoder)
Time series forecasting  |  ` 'ARIMA_PLUS' ` (previously ` 'ARIMA' ` )  |
Univariate time-series forecasting with many modeling components under the
hood such as ARIMA model for the trend, STL and ETS for seasonality, holiday
effects, and so on.  |  [ CREATE MODEL statement for time series models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-time-series)
` 'ARIMA_PLUS_XREG' ` |  Multivariate time-series forecasting using linear
regression and ARIMA_PLUS as the underlying techniques.  |  [ CREATE MODEL
statement for time series models ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-multivariate-time-series)
Importing models  |  ` 'TENSORFLOW' ` |  Create a model by importing a
TensorFlow model into BigQuery.  |  [ CREATE MODEL statement for TensorFlow
models ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
tensorflow)
` 'TENSORFLOW_LITE' ` |  Create a model by importing a TensorFlow Lite model
into BigQuery.  |  [ CREATE MODEL statement for TensorFlow Lite models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tflite)
` 'ONNX' ` |  Create a model by importing an ONNX model into BigQuery.  |  [
CREATE MODEL statement for ONNX models ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-onnx)
` 'XGBOOST' ` |  Create a model by importing a XGBoost model into BigQuery.  |
[ CREATE MODEL statement for XGBoost models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-xgboost)
Remote models  |  NA  |  Create a model by specifying a Vertex AI endpoint.  |
[ CREATE MODEL statement for remote models
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model)

**Note:** We are deprecating ` ARIMA ` as the model type. While the model
training pipelines of ` ARIMA ` and ` ARIMA_PLUS ` are the same, ` ARIMA_PLUS
` supports more functionality, including support for a new training option, [
` DECOMPOSE_TIME_SERIES ` ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create#decompose_time_series) , and table-valued functions including [
` ML.ARIMA_EVALUATE ` ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-arima-evaluate) and [ ` ML.EXPLAIN_FORECAST `
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-explain-forecast) .

####  Other model options

The table below provides a comprehensive list of model options, with a brief
description and their applicable model types. You can find detailed
description in the model specific ` CREATE MODEL ` statement by clicking the
model type in the "Applied model types" column.

When the applied model types are supervised learning models, unless
"regressor" or "classifier" is explicitly listed, it means that model options
apply to both the regressor and the classifier. For example, the "boosted
tree" means that model option applies to both boosted tree regressor and
boosted tree classifier, while the "boosted tree classifier" only applies to
the classifier.

Name  |  Description  |  Applied model types
---|---|---
MODEL_REGISTRY  |  The MODEL_REGISTRY option specifies the model registry
destination. For now, 'VERTEX_AI' is the only supported model registry
destination. To learn more, see [ MLOps with BigQuery ML and Vertex AI.
](/bigquery/docs/create_vertex#register_a_model_to_the) |  All model types are
supported.
VERTEX_AI_MODEL_ID  |  The Vertex AI model ID to register the model with.
**Note:** VERTEX_AI_MODEL_ID can only be set when MODEL_REGISTRY is set to
'VERTEX_AI'. To learn more, see [ Add a Vertex AI model ID.
](/bigquery/docs/create_vertex#add_a_model_id)
|  All model types are supported.
VERTEX_AI_MODEL_VERSION_ALIASES  |  The Vertex AI model alias to register the
model with.
**Note:** VERTEX_AI_MODEL_VERSION_ALIASES can only be set when MODEL_REGISTRY
is set to 'VERTEX_AI'. To learn more, see [ Add a Vertex AI model alias.
](/bigquery/docs/create_vertex#add_a_model_alias)
|  All model types are supported.
INPUT_LABEL_COLS  |  The label column names in the training data.  |  [ Linear
& logistic regression ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-glm#input_label_cols) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#input_label_cols) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#input_label_cols) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#input_label_cols) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#input_label_cols) ,
[ AutoML ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
automl#input_label_cols)
MAX_ITERATIONS  |  The maximum number of training iterations or steps.  |  [
Linear & logistic regression ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-glm#max_iterations) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#max_iterations) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#max_iterations) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#max_iterations) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#max_iterations) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#max_iterations) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#max_iterations)
EARLY_STOP  |  Whether training should stop after the first iteration in which
the relative loss improvement is less than the value specified for
`MIN_REL_PROGRESS`.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#early_stop) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#early_stop) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#early_stop) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#early_stop) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#early_stop) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#early_stop) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#early_stop) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#early_stop)
MIN_REL_PROGRESS  |  The minimum relative loss improvement that is necessary
to continue training when `EARLY_STOP` is set to true.  |  [ Linear & logistic
regression ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#min_rel_progress) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#min_rel_progress) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#min_rel_progress) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#min_rel_progress) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#min_rel_progress) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#min_rel_progress) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#min_rel_progress) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#min_rel_progress)
DATA_SPLIT_METHOD  |  The method to split input data into training and
evaluation sets when not running hyperparameter tuning, or into training,
evaluation, and test sets when running hyperparameter tuning.  |  [ Linear &
logistic regression ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-glm#data_split_method) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#data_split_method) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#data_split_method) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#data_split_method) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#data_split_method)
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#data_split_method)
DATA_SPLIT_EVAL_FRACTION  |  Specifies the fraction of the data used for
evaluation. Accurate to two decimal places.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#data_split_eval_fraction) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#data_split_eval_fraction) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#data_split_eval_fraction) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#data_split_eval_fraction) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#data_split_eval_fraction)
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#data_split_eval_fraction)
DATA_SPLIT_TEST_FRACTION  |  Specifies the fraction of the data used for
testing when you are running hyperparameter tuning. Accurate to two decimal
places.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#data_split_test_fraction) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#data_split_test_fraction) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#data_split_test_fraction) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#data_split_test_fraction) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#data_split_test_fraction)
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#data_split_test_fraction)
DATA_SPLIT_COL  |  Identifies the column used to split the data.  |  [ Linear
& logistic regression ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-glm#data_split_col) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#data_split_col) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#data_split_col) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#data_split_col) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#data_split_col)
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#data_split_col)
OPTIMIZE_STRATEGY  |  The strategy to train linear regression models.  |  [
Linear regression ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-glm#optimize_strategy)
L1_REG  |  The amount of [ L1 regularization
](https://developers.google.com/machine-learning/glossary/#L1_regularization)
applied.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-glm#l1_reg) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#l1_reg)
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#l1_reg)
L2_REG  |  The amount of [ L2 regularization
](https://developers.google.com/machine-learning/glossary/#L2_regularization)
applied.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-glm#l2_reg) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#l2_reg) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#l2_reg) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#l2_reg) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#l2_reg)
LEARN_RATE_STRATEGY  |  The strategy for specifying the [ learning rate
](https://developers.google.com/machine-learning/glossary/#learning_rate)
during training.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#learn_rate_strategy)
LEARN_RATE  |  The learn rate for [ gradient descent
](https://developers.google.com/machine-learning/glossary/#gradient_descent)
when LEARN_RATE_STRATEGY is set to CONSTANT.  |  [ Linear & logistic
regression ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#learn_rate)
LS_INIT_LEARN_RATE  |  Sets the initial learning rate that
LEARN_RATE_STRATEGY=LINE_SEARCH uses.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#ls_init_learn_rate)
WARM_START  |  Retrain a model with new training data, new model options, or
both.  |  [ Linear & logistic regression ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-glm#warm_start) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#warm_start) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#warm_start) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#warm_start) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#warm_start)
AUTO_CLASS_WEIGHTS  |  Whether to balance class labels using weights for each
class in inverse proportion to the frequency of that class.  |  [ Logistic
regression ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#auto_class_weights) ,
[ Boosted tree classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-boosted-tree#auto_class_weights) ,
[ Random forest classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-random-forest#auto_class_weights) ,
[ DNN classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-dnn-models#auto_class_weights) ,
[ Wide & Deep classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-wnd-models#auto_class_weights)
CLASS_WEIGHTS  |  The weights to use for each class label. This option cannot
be specified if AUTO_CLASS_WEIGHTS is specified.

It takes an ARRAY of STRUCTs; each STRUCT is a (STRING, FLOAT64) pair
representing a class label and the corresponding weight.

A weight must be present for every class label. The weights are not required
to add up to one. For example: CLASS_WEIGHTS = [STRUCT('example_label', .2)].
|  [ Logistic regression ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-glm#class_weights) ,
[ Boosted tree classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-boosted-tree#class_weights) ,
[ Random forest classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-random-forest#class_weights) ,
[ DNN classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-dnn-models#class_weights) ,
[ Wide & Deep classifier ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-wnd-models#class_weights)
INSTANCE_WEIGHT_COL  |  Identifies the column used to specify the weights for
each data point in the training dataset.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#instance_weight_col) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#instance_weight_col)
NUM_CLUSTERS  |  The number of clusters to identify in the input data.  |  [
Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#num_clusters)
KMEANS_INIT_METHOD  |  The method of initializing the clusters.  |  [ Kmeans
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#kmeans_init_method)
KMEANS_INIT_COL  |  Identifies the column used to initialize the centroids.  |
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#kmeans_init_col)
DISTANCE_TYPE  |  The type of metric to compute the distance between two
points.  |  [ K-means ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-kmeans#distance_type)
STANDARDIZE_FEATURES  |  Whether to [ standardize numerical features
](https://en.wikipedia.org/wiki/Feature_scaling) .  |  [ Kmeans
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#standardize_features)
BUDGET_HOURS  |  Sets the training budget hours.  |  [ AutoML
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
automl#budget_hours) |  MODEL_PATH  |  Specifies the location of the imported
model to import.  |  [ Imported TensorFlow model
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
tensorflow#model_path) ,
[ Imported TensorFlow lite model ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-tflite#model_path) ,
[ Imported ONNX model ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-onnx#model_path) ,
[ Imported XGBoost model ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-xgboost#model_path)
FEEDBACK_TYPE  |  Specifies feedback type for matrix factorization models
which changes the algorithm that is used during training.  |  [ Matrix
factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-matrix-factorization#feedback_type)
NUM_FACTORS  |  Specifies the number of latent factors.  |  [ Matrix
factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-matrix-factorization#num_factors)
USER_COL  |  The user column name.  |  [ Matrix factorization
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-matrix-
factorization#user_col)
ITEM_COL  |  The item column name.  |  [ Matrix factorization
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-matrix-
factorization#item_col)
RATING_COL  |  The rating column name.  |  [ Matrix factorization
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-matrix-
factorization#rating_col)
WALS_ALPHA  |  A hyperparameter for matrix factorization models with IMPLICIT
feedback.  |  [ Matrix factorization ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-matrix-factorization#wals_alpha)
BOOSTER_TYPE  |  For boosted tree models, specify the booster type to use,
with default value GBTREE.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#booster_type)
NUM_PARALLEL_TREE  |  Number of parallel trees constructed during each
iteration.  |  [ Boosted trees ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-boosted-tree#num_parallel_tree) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#num_parallel_tree)
DART_NORMALIZE_TYPE  |  Type of normalization algorithm for DART booster.  |
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#dart_normalize_type)
TREE_METHOD  |  Type of tree construction algorithm.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#tree_method) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#tree_method)
MIN_TREE_CHILD_WEIGHT  |  Minimum sum of instance weight needed in a child for
further partitioning.  |  [ Boosted trees ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-boosted-tree#min_tree_child_weight) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#min_tree_child_weight)
COLSAMPLE_BYTREE  |  Subsample ratio of columns when constructing each tree.
Subsampling occurs once for every tree constructed.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#colsample_bytree) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#colsample_bytree)
COLSAMPLE_BYLEVEL  |  Subsample ratio of columns for each level. Subsampling
occurs once for every new depth level reached in a tree.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#colsample_bylevel) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#colsample_bylevel)
COLSAMPLE_BYNODE  |  Subsample ratio of columns for each node (split).
Subsampling occurs once every time a new split is evaluated.  |  [ Boosted
trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
boosted-tree#colsample_bynode) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#colsample_bynode)
MIN_SPLIT_LOSS  |  Minimum loss reduction required to make a further partition
on a leaf node of the tree.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#min_split_loss) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#min_split_loss)
MAX_TREE_DEPTH  |  Maximum depth of a tree.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#max_tree_depth) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#max_tree_depth)
SUBSAMPLE  |  Subsample ratio of the training instances.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#subsample) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#subsample)
ACTIVATION_FN  |  Specifies the activation function of the neural network.  |
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#activation_fn) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#activation_fn) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#activation_fn)
BATCH_SIZE  |  Specifies the mini batch size of samples that are fed to the
neural network.  |  [ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-dnn-models#batch_size) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#batch_size) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#batch_size)
DROPOUT  |  Specifies the dropout rate of units in the neural network.  |  [
DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#dropout) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#dropout) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#dropout)
HIDDEN_UNITS  |  Specifies the hidden layers of the neural network.  |  [ DNN
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#hidden_units) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#hidden_units) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#hidden_units)
OPTIMIZER  |  Specifies the optimizer for training the model.  |  [ DNN
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#optimizer) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#optimizer) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#optimizer)
TIME_SERIES_TIMESTAMP_COL  |  The timestamp column name for time series
models.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-time-series#time_series_timestamp_col) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#time_series_timestamp_col)
TIME_SERIES_DATA_COL  |  The data column name for time series models.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#time_series_data_col) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#time_series_data_col)
TIME_SERIES_ID_COL  |  The ID column names for time-series models.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#time_series_id_col)
HORIZON  |  The number of time points to forecast. When forecasting multiple
time series at once, this parameter applies to each time series.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#horizon) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#horizon)
AUTO_ARIMA  |  Whether the training process should use auto.ARIMA or not.  |
[ ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#auto_arima) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#auto_arima)
AUTO_ARIMA_MAX_ORDER  |  The maximum value for the sum of non-sesonal p and q.
It controls the parameter search space in the auto.ARIMA algorithm.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#auto_arima_max_order) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#auto_arima_max_order)
AUTO_ARIMA_MIN_ORDER  |  The minimum value for the sum of non-sesonal p and q.
It controls the parameter search space in the auto.ARIMA algorithm.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#auto_arima_min_order) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#auto_arima_min_order)
NON_SEASONAL_ORDER  |  The tuple of non-seasonal p, d, and q for the
ARIMA_PLUS model.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-time-series#non_seasonal_order) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#non_seasonal_order)
DATA_FREQUENCY  |  The data frequency of the input time series.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#data_frequency) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#data_frequency)
FORECAST_LIMIT_LOWER_BOUND  |  The lower bound of the time series forecasting
values.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-time-series#forecast_limit_lower_bound)
FORECAST_LIMIT_UPPER_BOUND  |  The upper bound of the time series forecasting
values.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-time-series#forecast_limit_upper_bound)
INCLUDE_DRIFT  |  Should the ARIMA_PLUS model include a linear drift term or
not.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-time-series#include_drift) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#include_drift)
HOLIDAY_REGION  |  The geographical region based on which the holiday effect
is applied in modeling.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-time-series#holiday_region) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#holiday_region)
CLEAN_SPIKES_AND_DIPS  |  Whether the spikes and dips should be cleaned.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#clean_spikes_and_dips) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#clean_spikes_and_dips)
ADJUST_STEP_CHANGES  |  Whether the step changes should be adjusted.  |  [
ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
time-series#adjust_step_changes) ,
[ ARIMA_PLUS_XREG ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-multivariate-time-series#adjust_step_changes)
DECOMPOSE_TIME_SERIES  |  Whether the separate components of both the history
and the forecast parts of the time series (such as seasonal components) should
be saved.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-time-series#decompose_time_series)
HIERARCHICAL_TIME_SERIES_COLS  |  The column names used to generate
hierarchical time series forecasts. The column order represents the hierarchy
structure.  |  [ ARIMA_PLUS ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-time-series#hierarchical_time_series_cols)
ENABLE_GLOBAL_EXPLAIN  |  Specifies whether to compute global explanations
using explainable AI to evaluate global feature importance to the model.  |  [
Linear & logistic regression ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-create-glm#enable_global_explain) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#enable_global_explain) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#enable_global_explain) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#enable_global_explain) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#enable_global_explain)
APPROX_GLOBAL_FEATURE_CONTRIB  |  Specifies whether to use fast approximation
for feature contribution computation.  |  [ Boosted trees
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-
tree#approx_global_feature_contrib) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#approx_global_feature_contrib)
INTEGRATED_GRADIENTS_NUM_STEPS  |  Specifies the number of steps to sample
between the example being explained and its baseline for approximating the
integral in integrated gradients attribution methods.  |  [ DNN
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#integrated_gradients_num_steps) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#integrated_gradients_num_steps)
CALCULATE_P_VALUES  |  Specifies whether to compute p-values for the model
during training.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#calculate_p_values)
FIT_INTERCEPT  |  Specifies whether to fit an intercept for the model during
training.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#fit_intercept)
CATEGORY_ENCODING_METHOD  |  Specifies the default encoding method for
categorical features.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#category_encoding_method) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#category_encoding_method)
ENDPOINT  |  Specifies the Vertex AI https endpoint to create the remote
model. For example, the ` text-bison ` and ` gemini-pro ` LLMS and user
deployed models.  |  [ Remote model with Vertex AI endpoint
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-
model#endpoint)
REMOTE_SERVICE_TYPE  |  Specifies the cloud AI service type used for Cloud AI
service TVFs.  |  [ Cloud AI service TVFs ](/bigquery/docs/reference/standard-
sql/bigqueryml-syntax-cloud-ai-service-tvfs-overview)
XGBOOST_VERSION  |  Specifies the Xgboost version for model training.  |  [
Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#xgboost_version) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#xgboost_version)
TF_VERSION  |  Specifies the Tensorflow (TF) version for model training.  |  [
DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#tf_version) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#tf_version) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#tf_version)
NUM_TRIALS  |  Specifies the maximum number of submodels to train when you are
running hyperparameter tuning.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#num_trials) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#num_trials) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#num_trials) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#num_trials) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#num_trials) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#num_trials) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#num_trials) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#num_trials)
MAX_PARALLEL_TRIALS  |  Specifies the maximum number of trials to run at the
same time when you are running hyperparameter tuning.  |  [ Linear & logistic
regression ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#max_parallel_trials) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#max_parallel_trials) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#max_parallel_trials) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#max_parallel_trials) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#max_parallel_trials) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#max_parallel_trials) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#max_parallel_trials) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#max_parallel_trials)
HPARAM_TUNING_ALGORITHM  |  Specifies the algorithm used to tune the
hyperparameters when you are running hyperparameter tuning.  |  [ Linear &
logistic regression ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-glm#hparam_tuning_algorithm) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#hparam_tuning_algorithm) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#hparam_tuning_algorithm) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#hparam_tuning_algorithm) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#hparam_tuning_algorithm) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#hparam_tuning_algorithm) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#hparam_tuning_algorithm) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#hparam_tuning_algorithm)
HPARAM_TUNING_OBJECTIVES  |  Specifies the hyperparameter tuning objective for
the model.  |  [ Linear & logistic regression
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
glm#hparam_tuning_objectives) ,
[ Boosted trees ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-boosted-tree#hparam_tuning_objectives) ,
[ Random forest ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-random-forest#hparam_tuning_objectives) ,
[ DNN ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-
models#hparam_tuning_objectives) ,
[ Wide & Deep ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-wnd-models#hparam_tuning_objectives) ,
[ Kmeans ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-
kmeans#hparam_tuning_objectives) ,
[ Matrix factorization ](/bigquery/docs/reference/standard-sql/bigqueryml-
syntax-create-matrix-factorization#hparam_tuning_objectives) ,
[ Autoencoder ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-
create-autoencoder#hparam_tuning_objectives)

###  ` AS `

All model types support the following ` AS ` clause syntax for specifying the
training data:



AS query_statement


For time series forecasting models that have a ` DATA_FREQUENCY ` value of
either ` DAILY ` or ` AUTO_FREQUENCY ` , you can optionally use the following
` AS ` clause syntax to perform [ custom holiday modeling
](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-time-
series#custom_holidays) in addition to specifying the training data:



AS (
training_data AS (query_statement),
custom_holiday AS (holiday_statement)
)


####  ` query_statement `

The ` query_statement ` argument specifies the query that is used to generate
the training data. For information about the supported SQL syntax of the `
query_statement ` clause, see [ GoogleSQL query syntax
](/bigquery/docs/reference/standard-sql/query-syntax#sql-syntax) .

####  ` holiday_statement `

The ` holiday_statement ` argument specifies the query that provides custom
holiday modeling information for time series forecast models. This query must
return 50,000 rows or less and must contain the following columns:

* ` region ` : Required. A ` STRING ` value that identifies the region to target for holiday modeling. Use one of the following options:

* An upper-case [ holiday region code ](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-time-series#holiday_region) . Use this option to overwrite or supplement the holidays for the specified region. You can see the holidays for a region by running ` SELECT * FROM bigquery-public-data.ml_datasets.holidays_and_events_for_forecasting WHERE region =  region  ` .
* An arbitrary string. Use this option to specify a custom region that you want to model holidays for. For example, you could specify ` London ` if you are only modeling holidays for that city.

Be sure not to use an existing holiday region code when you are trying to
model for a custom region. For example, if you want to model a holiday in
California, and specify ` CA ` as the ` region ` value, the service recognizes
that as the holiday region code for Canada and targets that region. Because
the argument is case-sensitive, you could specify ` ca ` , ` California ` , or
some other value that isn't a holiday region code.

* ` holiday_name ` : Required. A ` STRING ` value that identifies the holiday to target for holiday modeling. Use one of the following options:

* The holiday name as it is represented in the ` bigquery-public-data.ml_datasets.holidays_and_events_for_forecasting ` public table, including case. Use this option to  overwrite  or  supplement  the specified holiday.
* A string that represents a custom holiday. The string must be a valid column name so that it can be used in ` ML.EXPLAIN_FORECAST ` output. For example, it cannot contain space. For more information on column naming, see [ Column names ](/bigquery/docs/schemas#column_names) .
* ` primary_date ` : Required. A ` DATE ` value that specifies the date the holiday falls on.

* ` preholiday_days ` : Optional. An ` INT64 ` value that specifies the start of the holiday window around the holiday that is taken into account when modeling. Must be greater than or equal to ` 1 ` . Defaults to ` 1 ` .

* ` postholiday_days ` : Optional. An ` INT64 ` value that specifies the end of the holiday window around the holiday that is taken into account when modeling. Must be greater than or equal to ` 1 ` . Defaults to ` 1 ` .

The ` preholiday_days ` and ` postholiday_days ` arguments together describe
the holiday window around the holiday that is taken into account when
modeling. The holiday window is defined as ` [primary_date - preholiday_days,
primary_date + postholiday_days] ` and is inclusive of the pre- and post-
holiday days. The sum of the values for these arguments must be less than `
365 ` and must be the same across the given holiday. For example, if you are
modeling Arbor Day for several different years, you must specify the same
holiday window for all of those years.

To achieve the best holiday modeling result, provide as much historical and
forecast information about the occurrences of each included holiday as
possible. For example, if you have time series data from 2018 to 2022 and
would like to forecast for 2023, you get the best result by providing the
custom holiday information for all of those years, similar to the following:



CREATE OR REPLACE MODEL `mydataset.arima_model`
OPTIONS (
model_type = 'ARIMA_PLUS',
holiday_region = 'US',...) AS (
training_data AS (SELECT * FROM `mydataset.timeseries_data`),
custom_holiday AS (
SELECT
'US' AS region,
'Halloween' AS holiday_name,
primary_date,
5 AS preholiday_days,
1 AS postholiday_days
FROM
UNNEST(
[
DATE('2018-10-31'),
DATE('2019-10-31'),
DATE('2020-10-31'),
DATE('2021-10-31'),
DATE('2022-10-31'),
DATE('2023-10-31')])
AS primary_date
)
)


##  Supported inputs

The ` CREATE MODEL ` statement supports the following data types for input
label, data split columns and input feature columns.

###  Supported input feature types

See [ Supported input feature types ](/bigquery/docs/reference/standard-
sql/bigqueryml-input-feature-types) for BigQuery ML supported input feature
types.

###  Supported data types for input label columns

BigQuery ML supports different GoogleSQL data types depending on the model
type. Supported data types for ` input_label_cols ` include:

` Model type ` |  ` Supported label types `
---|---
` regression models ` |  [ ` INT64 ` ](/bigquery/docs/reference/standard-
sql/data-types#integer-type)
[ ` NUMERIC ` ](/bigquery/docs/reference/standard-sql/data-types#numeric_type)
[ ` BIGNUMERIC ` ](/bigquery/docs/reference/standard-sql/data-
types#bignumeric_type)
[ ` FLOAT64 ` ](/bigquery/docs/reference/standard-sql/data-types#floating-
point-type)
` classification models ` |  Any [ groupable
](/bigquery/docs/reference/standard-sql/data-types#data-type-properties) data
type

###  Supported data types for data split columns

BigQuery ML supports different GoogleSQL data types depending on the data
split method. Supported data types for ` data_split_col ` include:

` Data split method ` |  ` Supported column types `
---|---
` CUSTOM ` |  [ ` BOOL ` ](/bigquery/docs/reference/standard-sql/data-
types#boolean-type)
` SEQ ` |  [ ` INT64 ` ](/bigquery/docs/reference/standard-sql/data-
types#integer-type)
[ ` NUMERIC ` ](/bigquery/docs/reference/standard-sql/data-types#numeric_type)
[ ` BIGNUMERIC ` ](/bigquery/docs/reference/standard-sql/data-
types#bignumeric_type)
[ ` FLOAT64 ` ](/bigquery/docs/reference/standard-sql/data-types#floating-
point-type)
[ ` TIMESTAMP ` ](/bigquery/docs/reference/standard-sql/data-types#timestamp-
type)

##  Limitations

` CREATE MODEL ` statements must comply with the following rules:

* Only one ` CREATE ` statement is allowed.
* When you use a ` CREATE MODEL ` statement, the size of the model must be 90 MB or less or the query fails. Generally, if all categorical variables are short strings, a total feature cardinality (model dimension) of 5-10 million is supported. The dimensionality is dependent on the cardinality and length of the string variables.
* The label column cannot contain ` NULL ` values. If the label column contains ` NULL ` values, then the query fails.
* The ` CREATE MODEL IF NOT EXISTS ` clause always updates the last modified timestamp of a model.
* Query statements used in the ` CREATE MODEL ` statement cannot contain ` EXTERNAL_QUERY ` . If you want to use ` EXTERNAL_QUERY ` , then [ materialize the query result ](/bigquery/docs/reference/standard-sql/data-definition-language#create_table_statement) and then use the ` CREATE MODEL ` statement with the newly created table.

Send feedback

Except as otherwise noted, the content of this page is licensed under the [
Creative Commons Attribution 4.0 License
](https://creativecommons.org/licenses/by/4.0/) , and code samples are
licensed under the [ Apache 2.0 License
](https://www.apache.org/licenses/LICENSE-2.0) . For details, see the [ Google
Developers Site Policies ](https://developers.google.com/site-policies) . Java
is a registered trademark of Oracle and/or its affiliates.

Last updated 2024-04-29 UTC.

[{ "type": "thumb-down", "id": "hardToUnderstand", "label":"Hard to
understand" },{ "type": "thumb-down", "id":
"incorrectInformationOrSampleCode", "label":"Incorrect information or sample
code" },{ "type": "thumb-down", "id": "missingTheInformationSamplesINeed",
"label":"Missing the information/samples I need" },{ "type": "thumb-down",
"id": "otherDown", "label":"Other" }]  [{ "type": "thumb-up", "id":
"easyToUnderstand", "label":"Easy to understand" },{ "type": "thumb-up", "id":
"solvedMyProblem", "label":"Solved my problem" },{ "type": "thumb-up", "id":
"otherUp", "label":"Other" }]  Need to tell us more?

* ###  Why Google

* [ Choosing Google Cloud ](/why-google-cloud/)
* [ Trust and security ](/trust-center/)
* [ Open cloud ](/open-cloud/)
* [ Multicloud ](/multicloud/)
* [ Global infrastructure ](/infrastructure/)
* [ Customers and case studies ](/customers/)
* [ Analyst reports ](/analyst-reports/)
* [ Whitepapers ](/whitepapers/)
* [ Blog ](//cloud.google.com/blog/)
* ###  Products and pricing

* [ Google Cloud pricing ](/pricing/)
* [ Google Workspace pricing ](//workspace.google.com/pricing.html)
* [ See all products ](/products/)
* ###  Solutions

* [ Infrastructure modernization ](/solutions/infrastructure-modernization/)
* [ Databases ](/solutions/databases/)
* [ Application modernization ](/solutions/application-modernization/)
* [ Smart analytics ](/solutions/smart-analytics/)
* [ Artificial Intelligence ](/solutions/ai/)
* [ Security ](/solutions/security/)
* [ Productivity & work transformation ](https://workspace.google.com/enterprise/)
* [ Industry solutions ](/solutions/#industry-solutions)
* [ DevOps solutions ](/solutions/devops/)
* [ Small business solutions ](/solutions/#section-14)
* [ See all solutions ](/solutions/)
* ###  Resources

* [ Google Cloud documentation ](/docs/)
* [ Google Cloud quickstarts ](/docs/get-started/)
* [ Google Cloud Marketplace ](/marketplace/)
* [ Learn about cloud computing ](/discover/)
* [ Support ](/support-hub/)
* [ Code samples ](/docs/samples)
* [ Cloud Architecture Center ](/architecture/)
* [ Training ](/learn/training/)
* [ Certifications ](/learn/certification/)
* [ Google for Developers ](//developers.google.com)
* [ Google Cloud for Startups ](/startup/)
* [ System status ](//status.cloud.google.com)
* [ Release Notes ](/release-notes)
* ###  Engage

* [ Contact sales ](/contact/)
* [ Find a Partner ](//cloud.google.com/find-a-partner)
* [ Become a Partner ](/partners/become-a-partner/)
* [ Events ](/events/)
* [ Podcasts ](/podcasts/)
* [ Developer Center ](/developers/)
* [ Press Corner ](https://www.googlecloudpresscorner.com/)
* [ Google Cloud on YouTube ](//www.youtube.com/googlecloud)
* [ Google Cloud Tech on YouTube ](//www.youtube.com/googlecloudplatform)
* [ Follow on X ](//x.com/googlecloud)
* [ Join User Research ](//userresearch.google.com/?reserved=1&utm_source=website&Q_Language=en&utm_medium=own_srch&utm_campaign=CloudWebFooter&utm_term=0&utm_content=0&productTag=clou&campaignDate=jul19&pType=devel&referral_code=jk212693)
* [ We're hiring. Join Google Cloud! ](//careers.google.com/cloud)
* [ Google Cloud Community ](https://www.googlecloudcommunity.com/)

* [ About Google ](//about.google/)
* [ Privacy ](//policies.google.com/privacy)
* [ Site terms ](//www.google.com/intl/en/policies/terms/regional.html)
* [ Google Cloud terms ](/product-terms/)
* Manage cookies
* [ Our third decade of climate action: join us ](/sustainability)
* Sign up for the Google Cloud newsletter  [ Subscribe ](/newsletter/)

* English
* Deutsch
* Español – América Latina
* Français
* Português – Brasil
* 中文 – 简体
* 日本語
* 한국어

