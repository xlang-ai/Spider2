[
    {
        "instance_id": "sf001",
        "score": 1,
        "pred_sql": "WITH timestamps AS\n(   \n    SELECT\n        DATE_TRUNC(year,DATEADD(year,-1,DATE '2024-08-29')) AS ref_timestamp,\n        LAST_DAY(DATEADD(week,2 + CAST(WEEKISO(ref_timestamp) != 1 AS INTEGER),ref_timestamp),week) AS end_week,\n        DATEADD(day, day_num - 7, end_week) AS date_valid_std\n    FROM\n    (   \n        SELECT\n            ROW_NUMBER() OVER (ORDER BY SEQ1()) AS day_num\n        FROM\n            TABLE(GENERATOR(rowcount => 7))\n    ) \n)\nSELECT\n    country,\n    postal_code,\n    date_valid_std,\n    tot_snowfall_in \nFROM \n    GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI.standard_tile.history_day\nNATURAL INNER JOIN\n    timestamps\nWHERE\n    country='US' AND\n    tot_snowfall_in > 6.0 \nORDER BY \n    postal_code,date_valid_std\n;",
        "error_info": null
    },
    {
        "instance_id": "sf002",
        "score": 1,
        "pred_sql": "WITH big_banks AS (\n    SELECT id_rssd\n    FROM FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries\n    WHERE variable = 'ASSET'\n      AND date = '2022-12-31'\n      AND value > 1E10\n)\nSELECT name\nFROM FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries AS ts\nINNER JOIN FINANCE__ECONOMICS.CYBERSYN.financial_institution_attributes AS att ON (ts.variable = att.variable)\nINNER JOIN FINANCE__ECONOMICS.CYBERSYN.financial_institution_entities AS ent ON (ts.id_rssd = ent.id_rssd)\nINNER JOIN big_banks ON (big_banks.id_rssd = ts.id_rssd)\nWHERE ts.date = '2022-12-31'\n  AND att.variable_name = '% Insured (Estimated)'\n  AND att.frequency = 'Quarterly'\n  AND ent.is_active = True\nORDER BY (1 - value) DESC\nLIMIT 10;",
        "error_info": null
    },
    {
        "instance_id": "sf011",
        "score": 1,
        "pred_sql": " WITH TractPop AS (\n    SELECT\n        CG.\"BlockGroupID\",\n        FCV.\"CensusValue\",\n        CG.\"StateCountyTractID\",\n        CG.\"BlockGroupPolygon\"\n    FROM\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Dim_CensusGeography\" CG\n    JOIN\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Fact_CensusValues_ACS2021\" FCV\n        ON CG.\"BlockGroupID\" = FCV.\"BlockGroupID\"\n    WHERE\n        CG.\"StateAbbrev\" = 'NY'\n        AND FCV.\"MetricID\" = 'B01003_001E'\n),\n\nTractGroup AS (\n    SELECT\n        CG.\"StateCountyTractID\",\n        SUM(FCV.\"CensusValue\") AS \"TotalTractPop\"\n    FROM\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Dim_CensusGeography\" CG\n    JOIN\n        CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE.PUBLIC.\"Fact_CensusValues_ACS2021\" FCV\n        ON CG.\"BlockGroupID\" = FCV.\"BlockGroupID\"\n    WHERE\n        CG.\"StateAbbrev\" = 'NY'\n        AND FCV.\"MetricID\" = 'B01003_001E'\n    GROUP BY\n        CG.\"StateCountyTractID\"\n)\n\nSELECT\n    TP.\"BlockGroupID\",\n    TP.\"CensusValue\",\n    TP.\"StateCountyTractID\",\n    TG.\"TotalTractPop\",\n    CASE WHEN TG.\"TotalTractPop\" <> 0 THEN TP.\"CensusValue\" / TG.\"TotalTractPop\" ELSE 0 END AS \"BlockGroupRatio\"\nFROM\n    TractPop TP\nJOIN\n    TractGroup TG\n    ON TP.\"StateCountyTractID\" = TG.\"StateCountyTractID\";",
        "error_info": null
    },
    {
        "instance_id": "sf012",
        "score": 0,
        "pred_sql": "SELECT \n    YEAR(claims.date_of_loss)               AS year_of_loss,\n    claims.nfip_community_name,\n    SUM(claims.building_damage_amount) AS total_building_damage_amount,\n    SUM(claims.contents_damage_amount) AS total_contents_damage_amount\nFROM WEATHER__ENVIRONMENT.CYBERSYN.fema_national_flood_insurance_program_claim_index claims\nWHERE \n    claims.nfip_community_name = 'City Of New York' \n    AND year_of_loss >=2010 AND year_of_loss <=2019\nGROUP BY year_of_loss, claims.nfip_community_name\nORDER BY year_of_loss, claims.nfip_community_name;",
        "error_info": "Result Error"
    },
    {
        "instance_id": "sf014",
        "score": 1,
        "pred_sql": "WITH Commuters AS (\n    SELECT\n        GE.\"ZipCode\",\n        SUM(CASE WHEN M.\"MetricID\" = 'B08303_013E' THEN F.\"CensusValueByZip\" ELSE 0 END +\n            CASE WHEN M.\"MetricID\" = 'B08303_012E' THEN F.\"CensusValueByZip\" ELSE 0 END) AS \"Num_Commuters_1Hr_Travel_Time\"\n    FROM\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"LU_GeographyExpanded\" GE\n    JOIN\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"Fact_CensusValues_ACS2021_ByZip\" F\n        ON GE.\"ZipCode\" = F.\"ZipCode\"\n    JOIN\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"Dim_CensusMetrics\" M\n        ON F.\"MetricID\" = M.\"MetricID\"\n    WHERE\n        GE.\"PreferredStateAbbrev\" = 'NY'\n        AND (M.\"MetricID\" = 'B08303_013E' OR M.\"MetricID\" = 'B08303_012E') -- Metric IDs for commuters with 1+ hour travel time\n    GROUP BY\n        GE.\"ZipCode\"\n),\n\nStateBenchmark AS (\n    SELECT\n        SB.\"StateAbbrev\",\n        SUM(SB.\"StateBenchmarkValue\") AS \"StateBenchmark_Over1HrTravelTime\",\n        SB.\"TotalStatePopulation\"\n    FROM\n        CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE.PUBLIC.\"Fact_StateBenchmark_ACS2021\" SB\n    WHERE\n        SB.\"MetricID\" IN ('B08303_013E', 'B08303_012E')\n        AND SB.\"StateAbbrev\" = 'NY'\n    GROUP BY\n        SB.\"StateAbbrev\", SB.\"TotalStatePopulation\"\n)\n\nSELECT\n    C.\"ZipCode\",\n    SUM(C.\"Num_Commuters_1Hr_Travel_Time\") AS \"Total_Commuters_1Hr_Travel_Time\",\n    SB.\"StateBenchmark_Over1HrTravelTime\",\n    SB.\"TotalStatePopulation\",\nFROM\n    Commuters C\nCROSS JOIN\n    StateBenchmark SB\nGROUP BY\n    C.\"ZipCode\", SB.\"StateBenchmark_Over1HrTravelTime\", SB.\"TotalStatePopulation\"\nORDER BY\n    \"Total_Commuters_1Hr_Travel_Time\" DESC\nLIMIT 1;\n\n\n",
        "error_info": null
    },
    {
        "instance_id": "sf018",
        "score": 1,
        "pred_sql": "WITH push_send AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Send' AS \"EVENT_TYPE\"\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_SEND_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_bounce AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Bounce' AS \"EVENT_TYPE\"\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_BOUNCE_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_open AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Open' AS \"EVENT_TYPE\",\n        carrier,\n        browser,\n        device_model\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_OPEN_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_open_influence AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Influenced Open' AS \"EVENT_TYPE\",\n        carrier,\n        browser,\n        device_model\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_INFLUENCEDOPEN_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n)\nSELECT\n    ps.app_group_id,\n    ps.campaign_id,\n    ps.user_id,\n    ps.time,\n    po.time push_open_time,\n    ps.message_variation_id,\n    ps.platform,\n    ps.ad_tracking_enabled,\n    po.carrier,\n    po.browser,\n    po.device_model,\n    COUNT(\n        DISTINCT ps.id\n    ) push_notification_sends,\n    COUNT(\n        DISTINCT ps.user_id\n    ) unique_push_notification_sends,\n    COUNT(\n        DISTINCT pb.id\n    ) push_notification_bounced,\n    COUNT(\n        DISTINCT pb.user_id\n    ) unique_push_notification_bounced,\n    COUNT(\n        DISTINCT po.id\n    ) push_notification_open,\n    COUNT(\n        DISTINCT po.user_id\n    ) unique_push_notification_opened,\n    COUNT(\n        DISTINCT poi.id\n    ) push_notification_influenced_open,\n    COUNT(\n        DISTINCT poi.user_id\n    ) unique_push_notification_influenced_open\nFROM\n    push_send ps\n    LEFT JOIN push_bounce pb\n    ON ps.message_variation_id = pb.message_variation_id\n    AND ps.user_id = pb.user_id\n    AND ps.app_group_id = pb.app_group_id\n    LEFT JOIN push_open po\n    ON ps.message_variation_id = po.message_variation_id\n    AND ps.user_id = po.user_id\n    AND ps.app_group_id = po.app_group_id\n    LEFT JOIN push_open_influence poi\n    ON ps.message_variation_id = poi.message_variation_id\n    AND ps.user_id = poi.user_id\n    AND ps.app_group_id = poi.app_group_id\nGROUP BY\n    1,2,3,4,5,6,7,8,9,10,11;\n",
        "error_info": null
    },
    {
        "instance_id": "sf040",
        "score": 1,
        "pred_sql": "WITH zip_areas AS (\n    SELECT\n        geo.geo_id,\n        geo.geo_name AS zip,\n        states.related_geo_name AS state,\n        countries.related_geo_name AS country,\n        ST_AREA(TRY_TO_GEOGRAPHY(value)) AS area\n    FROM US_ADDRESSES__POI.CYBERSYN.geography_index AS geo\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_relationships AS states\n        ON (geo.geo_id = states.geo_id AND states.related_level = 'State')\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_relationships AS countries\n        ON (geo.geo_id = countries.geo_id AND countries.related_level = 'Country')\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_characteristics AS chars\n        ON (geo.geo_id = chars.geo_id AND chars.relationship_type = 'coordinates_geojson')\n    WHERE geo.level = 'CensusZipCodeTabulationArea'\n),\n\nzip_area_ranks AS (\n    SELECT\n        *,\n        ROW_NUMBER() OVER (PARTITION BY country, state ORDER BY area DESC, geo_id) AS zip_area_rank\n    FROM zip_areas\n)\n\nSELECT addr.number, addr.street, addr.street_type\nFROM US_ADDRESSES__POI.CYBERSYN.us_addresses AS addr\nJOIN zip_area_ranks AS areas\n    ON (addr.id_zip = areas.geo_id)\nWHERE addr.state = 'FL' AND areas.country = 'United States' AND areas.zip_area_rank = 1\nORDER BY LATITUDE DESC\nLIMIT 10;",
        "error_info": null
    },
    {
        "instance_id": "sf044",
        "score": 1,
        "pred_sql": "WITH ytd_performance AS (\n  SELECT\n    ticker,\n    MIN(date) OVER (PARTITION BY ticker) AS start_of_year_date,\n    FIRST_VALUE(value) OVER (PARTITION BY ticker ORDER BY date ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS start_of_year_price,\n    MAX(date) OVER (PARTITION BY ticker) AS latest_date,\n    LAST_VALUE(value) OVER (PARTITION BY ticker ORDER BY date ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS latest_price\n  FROM FINANCE__ECONOMICS.CYBERSYN.stock_price_timeseries\n  WHERE\n    ticker IN ('AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'NVDA')\n    AND date BETWEEN DATE '2024-01-01' AND DATE '2024-06-30'  -- Adjusted to cover only from the start of 2024 to the end of June 2024\n    AND variable_name = 'Post-Market Close'\n)\nSELECT\n  ticker,\n  (latest_price - start_of_year_price) / start_of_year_price * 100 AS percentage_change_ytd\nFROM\n  ytd_performance\nGROUP BY\n  ticker, start_of_year_date, start_of_year_price, latest_date, latest_price\nORDER BY percentage_change_ytd DESC;",
        "error_info": null
    },
    {
        "instance_id": "sf_bq012",
        "score": 1,
        "pred_sql": "WITH double_entry_book AS (\n  -- Debits\n  SELECT \n    \"to_address\" AS \"address\",\n    \"value\" AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRACES\"\n  WHERE \"to_address\" IS NOT NULL\n    AND \"status\" = 1\n    AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n  \n  UNION ALL\n  \n  -- Credits\n  SELECT \n    \"from_address\" AS \"address\",\n    - \"value\" AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRACES\"\n  WHERE \"from_address\" IS NOT NULL\n    AND \"status\" = 1\n    AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n  \n  UNION ALL\n  \n  -- Transaction fees debits\n  SELECT \n    \"miner\" AS \"address\",\n    SUM(CAST(\"receipt_gas_used\" AS NUMBER) * CAST(\"gas_price\" AS NUMBER)) AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRANSACTIONS\" AS \"transactions\"\n  JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"BLOCKS\" AS \"blocks\"\n    ON \"blocks\".\"number\" = \"transactions\".\"block_number\"\n  GROUP BY \"blocks\".\"miner\"\n  \n  UNION ALL\n  \n  -- Transaction fees credits\n  SELECT \n    \"from_address\" AS \"address\",\n    -(CAST(\"receipt_gas_used\" AS NUMBER) * CAST(\"gas_price\" AS NUMBER)) AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRANSACTIONS\"\n),\ntop_10_balances AS (\n  SELECT\n    \"address\",\n    SUM(\"value\") AS \"balance\"\n  FROM double_entry_book\n  GROUP BY \"address\"\n  ORDER BY \"balance\" DESC\n  LIMIT 10\n)\nSELECT \n    ROUND(AVG(\"balance\") / 1e15, 2) AS \"average_balance_trillion\"\nFROM top_10_balances;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq017",
        "score": 1,
        "pred_sql": "WITH bounding_area AS (\n    SELECT \"geometry\" AS geometry\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => planet_features.\"all_tags\") AS \"tag\"\n    WHERE \"feature_type\" = 'multipolygons'\n      AND \"tag\".value:\"key\" = 'wikidata'\n      AND \"tag\".value:\"value\" = 'Q35'\n),\n\nhighway_info AS (\n    SELECT \n        SUM(ST_LENGTH(\n                ST_GEOGRAPHYFROMWKB(planet_features.\"geometry\")\n            )\n        ) AS highway_length,\n        \"tag\".value:\"value\" AS highway_type\n    FROM \n        GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES AS planet_features,\n        bounding_area\n    CROSS JOIN LATERAL FLATTEN(INPUT => planet_features.\"all_tags\") AS \"tag\"\n    WHERE \"tag\".value:\"key\" = 'highway'\n    AND \"feature_type\" = 'lines'\n    AND ST_DWITHIN(\n        ST_GEOGFROMWKB(planet_features.\"geometry\"), \n        ST_GEOGFROMWKB(bounding_area.geometry),\n        0.0\n    ) \n    GROUP BY highway_type\n)\n\nSELECT \n  REPLACE(highway_type, '\"', '') AS highway_type\nFROM\n  highway_info\nORDER BY \n  highway_length DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq028",
        "score": 1,
        "pred_sql": "WITH HighestReleases AS (\n    SELECT\n        HR.\"Name\",\n        HR.\"Version\"\n    FROM (\n        SELECT\n            \"Name\",\n            \"Version\",\n            ROW_NUMBER() OVER (\n                PARTITION BY \"Name\"\n                ORDER BY \n                    TO_NUMBER(PARSE_JSON(\"VersionInfo\"):\"Ordinal\") DESC\n            ) AS RowNumber\n        FROM\n            DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONS\n        WHERE\n            \"System\" = 'NPM'\n            AND TO_BOOLEAN(PARSE_JSON(\"VersionInfo\"):\"IsRelease\") = TRUE\n    ) AS HR\n    WHERE HR.RowNumber = 1\n),\nPVP AS (\n    SELECT\n        PVP.\"Name\", \n        PVP.\"Version\", \n        PVP.\"ProjectType\", \n        PVP.\"ProjectName\"\n    FROM\n        DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT AS PVP\n    JOIN\n        HighestReleases AS HR\n    ON\n        PVP.\"Name\" = HR.\"Name\"\n        AND PVP.\"Version\" = HR.\"Version\"\n    WHERE\n        PVP.\"System\" = 'NPM'\n        AND PVP.\"ProjectType\" = 'GITHUB'\n)\nSELECT\n    PVP.\"Name\", \n    PVP.\"Version\"\nFROM\n    PVP\nJOIN\n    DEPS_DEV_V1.DEPS_DEV_V1.PROJECTS AS P\nON\n    PVP.\"ProjectType\" = P.\"Type\" \n    AND PVP.\"ProjectName\" = P.\"Name\"\nORDER BY \n    P.\"StarsCount\" DESC\nLIMIT 8;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq033",
        "score": 1,
        "pred_sql": "WITH Patent_Matches AS (\n    SELECT\n      TO_DATE(CAST(ANY_VALUE(patentsdb.\"filing_date\") AS STRING), 'YYYYMMDD') AS Patent_Filing_Date,\n      patentsdb.\"application_number\" AS Patent_Application_Number,\n      MAX(abstract_info.value:\"text\") AS Patent_Title,\n      MAX(abstract_info.value:\"language\") AS Patent_Title_Language\n    FROM\n      PATENTS.PATENTS.PUBLICATIONS AS patentsdb,\n      LATERAL FLATTEN(input => patentsdb.\"abstract_localized\") AS abstract_info\n    WHERE\n      LOWER(abstract_info.value:\"text\") LIKE '%internet of things%'\n      AND patentsdb.\"country_code\" = 'US'\n    GROUP BY\n      Patent_Application_Number\n),\n\nDate_Series_Table AS (\n    SELECT\n        DATEADD(day, seq4(), DATE '2008-01-01') AS day,\n        0 AS Number_of_Patents\n    FROM\n        TABLE(\n            GENERATOR(\n                ROWCOUNT => 5479\n            )\n        )\n    ORDER BY\n        day\n)\n\nSELECT\n  TO_CHAR(Date_Series_Table.day, 'YYYY-MM') AS Patent_Date_YearMonth,\n  COUNT(Patent_Matches.Patent_Application_Number) AS Number_of_Patent_Applications\nFROM\n  Date_Series_Table\n  LEFT JOIN Patent_Matches\n    ON Date_Series_Table.day = Patent_Matches.Patent_Filing_Date\nWHERE\n    Date_Series_Table.day < DATE '2023-01-01'\nGROUP BY\n  TO_CHAR(Date_Series_Table.day, 'YYYY-MM')\nORDER BY\n  Patent_Date_YearMonth;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq037",
        "score": 1,
        "pred_sql": "WITH A AS (\n    SELECT\n        \"reference_bases\",\n        \"start_position\"\n    FROM\n        \"HUMAN_GENOME_VARIANTS\".\"HUMAN_GENOME_VARIANTS\".\"_1000_GENOMES_PHASE_3_OPTIMIZED_SCHEMA_VARIANTS_20150220\"\n    WHERE\n        \"reference_bases\" IN ('AT', 'TA')\n),\nB AS (\n    SELECT\n        \"reference_bases\",\n        MIN(\"start_position\") AS \"min_start_position\",\n        MAX(\"start_position\") AS \"max_start_position\",\n        COUNT(1) AS \"total_count\"\n    FROM\n        A\n    GROUP BY\n        \"reference_bases\"\n),\nmin_counts AS (\n    SELECT\n        A.\"reference_bases\",  -- Explicitly referencing the column from table A\n        A.\"start_position\" AS \"min_start_position\",\n        COUNT(1) AS \"min_count\"\n    FROM\n        A\n    INNER JOIN B \n        ON A.\"reference_bases\" = B.\"reference_bases\"\n    WHERE\n        A.\"start_position\" = B.\"min_start_position\"\n    GROUP BY\n        A.\"reference_bases\", A.\"start_position\"\n),\nmax_counts AS (\n    SELECT\n        A.\"reference_bases\",  -- Explicitly referencing the column from table A\n        A.\"start_position\" AS \"max_start_position\",\n        COUNT(1) AS \"max_count\"\n    FROM\n        A\n    INNER JOIN B\n        ON A.\"reference_bases\" = B.\"reference_bases\"\n    WHERE\n        A.\"start_position\" = B.\"max_start_position\"\n    GROUP BY\n        A.\"reference_bases\", A.\"start_position\"\n)\nSELECT\n    B.\"reference_bases\",  -- Explicitly referencing the column from table B\n    B.\"min_start_position\",\n    CAST(min_counts.\"min_count\" AS FLOAT) / B.\"total_count\" AS \"min_position_ratio\",\n    B.\"max_start_position\",\n    CAST(max_counts.\"max_count\" AS FLOAT) / B.\"total_count\" AS \"max_position_ratio\"\nFROM\n    B\nLEFT JOIN\n    min_counts ON B.\"reference_bases\" = min_counts.\"reference_bases\" AND B.\"min_start_position\" = min_counts.\"min_start_position\"\nLEFT JOIN\n    max_counts ON B.\"reference_bases\" = max_counts.\"reference_bases\" AND B.\"max_start_position\" = max_counts.\"max_start_position\"\nORDER BY\n    B.\"reference_bases\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq043",
        "score": 1,
        "pred_sql": "SELECT\n  genex.\"case_barcode\" AS \"case_barcode\",\n  genex.\"sample_barcode\" AS \"sample_barcode\",\n  genex.\"aliquot_barcode\" AS \"aliquot_barcode\",\n  genex.\"HGNC_gene_symbol\" AS \"HGNC_gene_symbol\",\n  clinical_info.\"Variant_Type\" AS \"Variant_Type\",\n  genex.\"gene_id\" AS \"gene_id\",\n  genex.\"normalized_count\" AS \"normalized_count\",\n  genex.\"project_short_name\" AS \"project_short_name\",\n  clinical_info.\"demo__gender\" AS \"gender\",\n  clinical_info.\"demo__vital_status\" AS \"vital_status\",\n  clinical_info.\"demo__days_to_death\" AS \"days_to_death\"\nFROM ( \n  SELECT\n    case_list.\"Variant_Type\" AS \"Variant_Type\",\n    case_list.\"case_barcode\" AS \"case_barcode\",\n    clinical.\"demo__gender\",\n    clinical.\"demo__vital_status\",\n    clinical.\"demo__days_to_death\"\n  FROM\n    (SELECT\n      mutation.\"case_barcode\",\n      mutation.\"Variant_Type\"\n    FROM\n      \"TCGA\".\"TCGA_VERSIONED\".\"SOMATIC_MUTATION_HG19_DCC_2017_02\" AS mutation\n    WHERE\n      mutation.\"Hugo_Symbol\" = 'CDKN2A'\n      AND mutation.\"project_short_name\" = 'TCGA-BLCA'\n    GROUP BY\n      mutation.\"case_barcode\",\n      mutation.\"Variant_Type\"\n    ORDER BY\n      mutation.\"case_barcode\"\n    ) AS case_list /* end case_list */\n  INNER JOIN\n    \"TCGA\".\"TCGA_VERSIONED\".\"CLINICAL_GDC_R39\" AS clinical\n  ON\n    case_list.\"case_barcode\" = clinical.\"submitter_id\" /* end clinical annotation */ ) AS clinical_info\nINNER JOIN\n  \"TCGA\".\"TCGA_VERSIONED\".\"RNASEQ_HG19_GDC_2017_02\" AS genex\nON\n  genex.\"case_barcode\" = clinical_info.\"case_barcode\"\nWHERE\n  genex.\"HGNC_gene_symbol\" IN ('MDM2', 'TP53', 'CDKN1A','CCNE1')\nORDER BY\n  \"case_barcode\",\n  \"HGNC_gene_symbol\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq050",
        "score": 1,
        "pred_sql": "WITH data AS (\n    SELECT\n        \"ZIPSTARTNAME\".\"borough\" AS \"borough_start\",\n        \"ZIPSTARTNAME\".\"neighborhood\" AS \"neighborhood_start\",\n        \"ZIPENDNAME\".\"borough\" AS \"borough_end\",\n        \"ZIPENDNAME\".\"neighborhood\" AS \"neighborhood_end\",\n        CAST(\"TRI\".\"tripduration\" / 60 AS NUMERIC) AS \"trip_minutes\",\n        \"WEA\".\"temp\" AS \"temperature\",\n        CAST(\"WEA\".\"wdsp\" AS NUMERIC) AS \"wind_speed\",\n        \"WEA\".\"prcp\" AS \"precipitation\",\n        EXTRACT(MONTH FROM DATE(\"TRI\".\"starttime\")) AS \"start_month\"\n    FROM\n        \"NEW_YORK_CITIBIKE_1\".\"NEW_YORK_CITIBIKE\".\"CITIBIKE_TRIPS\" AS \"TRI\"\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPSTART\"\n        ON ST_WITHIN(\n            ST_POINT(\"TRI\".\"start_station_longitude\", \"TRI\".\"start_station_latitude\"),\n            ST_GEOGFROMWKB(\"ZIPSTART\".\"zip_code_geom\")\n        )\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPEND\"\n        ON ST_WITHIN(\n            ST_POINT(\"TRI\".\"end_station_longitude\", \"TRI\".\"end_station_latitude\"),\n            ST_GEOGFROMWKB(\"ZIPEND\".\"zip_code_geom\")\n        )\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"GSOD2014\" AS \"WEA\"\n        ON TO_DATE(CONCAT(\"WEA\".\"year\", LPAD(\"WEA\".\"mo\", 2, '0'), LPAD(\"WEA\".\"da\", 2, '0')), 'YYYYMMDD') = DATE(\"TRI\".\"starttime\")\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"CYCLISTIC\".\"ZIP_CODES\" AS \"ZIPSTARTNAME\"\n        ON \"ZIPSTART\".\"zip_code\" = CAST(\"ZIPSTARTNAME\".\"zip\" AS STRING)\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"CYCLISTIC\".\"ZIP_CODES\" AS \"ZIPENDNAME\"\n        ON \"ZIPEND\".\"zip_code\" = CAST(\"ZIPENDNAME\".\"zip\" AS STRING)\n    WHERE\n        \"WEA\".\"wban\" = (\n            SELECT \"wban\" \n            FROM \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"STATIONS\"\n            WHERE\n                \"state\" = 'NY'\n                AND LOWER(\"name\") LIKE LOWER('%New York Central Park%')\n            LIMIT 1\n        )\n        AND EXTRACT(YEAR FROM DATE(\"TRI\".\"starttime\")) = 2014\n),\nagg_data AS (\n    SELECT\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        COUNT(*) AS \"num_trips\",\n        ROUND(AVG(\"trip_minutes\"), 1) AS \"avg_trip_minutes\",\n        ROUND(AVG(\"temperature\"), 1) AS \"avg_temperature\",\n        ROUND(AVG(\"wind_speed\"), 1) AS \"avg_wind_speed\",\n        ROUND(AVG(\"precipitation\"), 1) AS \"avg_precipitation\"\n    FROM data\n    GROUP BY\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\"\n),\nmost_common_months AS (\n    SELECT\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        \"start_month\",\n        ROW_NUMBER() OVER (\n            PARTITION BY \"borough_start\", \"neighborhood_start\", \"borough_end\", \"neighborhood_end\" \n            ORDER BY COUNT(*) DESC\n        ) AS \"row_num\"\n    FROM data\n    GROUP BY\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        \"start_month\"\n)\n\nSELECT\n    a.*,\n    m.\"start_month\" AS \"most_common_month\"\nFROM\n    agg_data a\nJOIN\n    most_common_months m\n    ON a.\"borough_start\" = m.\"borough_start\" \n    AND a.\"neighborhood_start\" = m.\"neighborhood_start\" \n    AND a.\"borough_end\" = m.\"borough_end\" \n    AND a.\"neighborhood_end\" = m.\"neighborhood_end\" \n    AND m.\"row_num\" = 1\nORDER BY \n    a.\"neighborhood_start\", \n    a.\"neighborhood_end\";",
        "error_info": null
    },
    {
        "instance_id": "sf_bq052",
        "score": 1,
        "pred_sql": "SELECT\n    app.\"patent_id\" AS \"patent_id\",\n    patent.\"title\",\n    app.\"date\" AS \"application_date\",\n    filterData.\"bkwdCitations_1\",\n    filterData.\"fwrdCitations_1\",\n    summary.\"text\" AS \"summary_text\"\nFROM\n    PATENTSVIEW.PATENTSVIEW.BRF_SUM_TEXT AS summary\nJOIN\n    PATENTSVIEW.PATENTSVIEW.PATENT AS patent\n    ON summary.\"patent_id\" = patent.\"id\"\nJOIN\n    PATENTSVIEW.PATENTSVIEW.APPLICATION AS app\n    ON app.\"patent_id\" = summary.\"patent_id\"\nJOIN (\n    SELECT DISTINCT\n        cpc.\"patent_id\",\n        IFNULL(citation_1.\"bkwdCitations_1\", 0) AS \"bkwdCitations_1\",\n        IFNULL(citation_1.\"fwrdCitations_1\", 0) AS \"fwrdCitations_1\"\n    FROM\n        PATENTSVIEW.PATENTSVIEW.CPC_CURRENT AS cpc\n    JOIN (\n        SELECT\n            b.\"patent_id\",\n            b.\"bkwdCitations_1\",\n            f.\"fwrdCitations_1\"\n        FROM (\n            SELECT\n                cited.\"patent_id\",\n                COUNT(*) AS \"fwrdCitations_1\"\n            FROM\n                PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n            JOIN\n                PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" >= apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(MONTH, 1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 month\n            GROUP BY\n                cited.\"patent_id\"\n        ) AS f\n        JOIN (\n            SELECT\n                cited.\"patent_id\",\n                COUNT(*) AS \"bkwdCitations_1\"\n            FROM\n                PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n            JOIN\n                PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" < apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) >= DATEADD(MONTH, -1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 month before\n            GROUP BY\n                cited.\"patent_id\"\n        ) AS b\n        ON b.\"patent_id\" = f.\"patent_id\"\n        WHERE\n            b.\"bkwdCitations_1\" IS NOT NULL\n            AND f.\"fwrdCitations_1\" IS NOT NULL\n            AND (b.\"bkwdCitations_1\" > 0 OR f.\"fwrdCitations_1\" > 0)\n    ) AS citation_1\n    ON cpc.\"patent_id\" = citation_1.\"patent_id\"\n    WHERE\n        cpc.\"subsection_id\" = 'C05'\n        OR cpc.\"group_id\" = 'A01G'\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nORDER BY app.\"date\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq057",
        "score": 1,
        "pred_sql": "WITH totals AS (\n    -- Aggregate monthly totals for Bitcoin txs, input/output UTXOs,\n    -- and input/output values (UTXO stands for Unspent Transaction Output)\n    SELECT\n        \"txs_tot\".\"block_timestamp_month\" AS tx_month,\n        COUNT(\"txs_tot\".\"hash\") AS tx_count,\n        SUM(\"txs_tot\".\"input_count\") AS tx_inputs,\n        SUM(\"txs_tot\".\"output_count\") AS tx_outputs,\n        SUM(\"txs_tot\".\"input_value\") / 100000000 AS tx_input_val,\n        SUM(\"txs_tot\".\"output_value\") / 100000000 AS tx_output_val\n    FROM CRYPTO.CRYPTO_BITCOIN.TRANSACTIONS AS \"txs_tot\"\n    WHERE \"txs_tot\".\"block_timestamp_month\" BETWEEN CAST('2021-01-01' AS DATE) AND CAST('2021-12-31' AS DATE)\n    GROUP BY \"txs_tot\".\"block_timestamp_month\"\n    ORDER BY \"txs_tot\".\"block_timestamp_month\" DESC\n),\ncoinjoinOuts AS (\n    -- Builds a table where each row represents an output of a \n    -- potential CoinJoin tx, defined as a tx that had more \n    -- than two outputs and had a total output value less than its\n    -- input value, per Adam Fiscor's description in this article: \n    SELECT \n        \"txs\".\"hash\",\n        \"txs\".\"block_number\",\n        \"txs\".\"block_timestamp_month\",\n        \"txs\".\"input_count\",\n        \"txs\".\"output_count\",\n        \"txs\".\"input_value\",\n        \"txs\".\"output_value\",\n        \"o\".value:\"value\" AS \"outputs_val\"\n    FROM CRYPTO.CRYPTO_BITCOIN.TRANSACTIONS AS \"txs\", \n         LATERAL FLATTEN(INPUT => \"txs\".\"outputs\") AS \"o\"\n    WHERE \"txs\".\"output_count\" > 2 \n      AND \"txs\".\"output_value\" <= \"txs\".\"input_value\"\n      AND \"txs\".\"block_timestamp_month\" BETWEEN CAST('2021-01-01' AS DATE) AND CAST('2021-12-31' AS DATE)\n    ORDER BY \"txs\".\"block_number\", \"txs\".\"hash\" DESC\n),\ncoinjoinTxs AS (\n    -- Builds a table of just the distinct CoinJoin tx hashes\n    -- which had more than one equal-value output.\n    SELECT \n        \"coinjoinouts\".\"hash\" AS \"cjhash\",\n        \"coinjoinouts\".\"outputs_val\" AS outputVal,\n        COUNT(*) AS cjOuts\n    FROM coinjoinOuts AS \"coinjoinouts\"\n    GROUP BY \"coinjoinouts\".\"hash\", \"coinjoinouts\".\"outputs_val\"\n    HAVING COUNT(*) > 1\n),\ncoinjoinsD AS (\n    -- Filter out all potential CoinJoin txs that did not have\n    -- more than one equal-value output. Do not list the\n    -- outputs themselves, only the distinct tx hashes and\n    -- their input/output counts and values.\n    SELECT DISTINCT \n        \"coinjoinouts\".\"hash\", \n        \"coinjoinouts\".\"block_number\", \n        \"coinjoinouts\".\"block_timestamp_month\",\n        \"coinjoinouts\".\"input_count\",\n        \"coinjoinouts\".\"output_count\",\n        \"coinjoinouts\".\"input_value\",\n        \"coinjoinouts\".\"output_value\"\n    FROM coinjoinOuts AS \"coinjoinouts\"\n    INNER JOIN coinjoinTxs AS \"coinjointxs\" \n        ON \"coinjoinouts\".\"hash\" = \"coinjointxs\".\"cjhash\"\n),\ncoinjoins AS (\n    -- Aggregate monthly totals for CoinJoin txs, input/output UTXOs,\n    -- and input/output values\n    SELECT \n        \"cjs\".\"block_timestamp_month\" AS cjs_month,\n        COUNT(\"cjs\".\"hash\") AS cjs_count,\n        SUM(\"cjs\".\"input_count\") AS cjs_inputs,\n        SUM(\"cjs\".\"output_count\") AS cjs_outputs,\n        SUM(\"cjs\".\"input_value\") / 100000000 AS cjs_input_val,\n        SUM(\"cjs\".\"output_value\") / 100000000 AS cjs_output_val\n    FROM coinjoinsD AS \"cjs\"\n    GROUP BY \"cjs\".\"block_timestamp_month\"\n    ORDER BY \"cjs\".\"block_timestamp_month\" DESC\n)\nSELECT EXTRACT(MONTH FROM tx_month) AS month,\n    -- Calculate resulting CoinJoin percentages:\n    -- tx_percent = percent of monthly Bitcoin txs that were CoinJoins\n    ROUND(coinjoins.cjs_count / totals.tx_count * 100, 1) AS tx_percent,\n    \n    -- utxos_percent = percent of monthly Bitcoin utxos that were CoinJoins\n    ROUND((coinjoins.cjs_inputs / totals.tx_inputs + coinjoins.cjs_outputs / totals.tx_outputs) / 2 * 100, 1) AS utxos_percent,\n    \n    -- value_percent = percent of monthly Bitcoin volume that took place\n    -- in CoinJoined transactions\n    ROUND(coinjoins.cjs_input_val / totals.tx_input_val * 100, 1) AS value_percent\nFROM totals\nINNER JOIN coinjoins\n    ON totals.tx_month = coinjoins.cjs_month\nORDER BY value_percent DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq068",
        "score": 1,
        "pred_sql": "WITH double_entry_book AS (\n    -- debits\n    SELECT\n        ARRAY_TO_STRING(\"inputs\".value:addresses, ',') AS \"address\",  -- Use the correct JSON path notation\n        \"inputs\".value:type AS \"type\",\n        - \"inputs\".value:value AS \"value\"\n    FROM CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS,\n         LATERAL FLATTEN(INPUT => \"inputs\") AS \"inputs\"\n    WHERE TO_TIMESTAMP(\"block_timestamp\" / 1000000) >= '2014-03-01' \n      AND TO_TIMESTAMP(\"block_timestamp\" / 1000000) < '2014-04-01'\n\n    UNION ALL\n \n    -- credits\n    SELECT\n        ARRAY_TO_STRING(\"outputs\".value:addresses, ',') AS \"address\",  -- Use the correct JSON path notation\n        \"outputs\".value:type AS \"type\",\n        \"outputs\".value:value AS \"value\"\n    FROM CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS, \n         LATERAL FLATTEN(INPUT => \"outputs\") AS \"outputs\"\n    WHERE TO_TIMESTAMP(\"block_timestamp\" / 1000000) >= '2014-03-01' \n      AND TO_TIMESTAMP(\"block_timestamp\" / 1000000) < '2014-04-01'\n),\naddress_balances AS (\n    SELECT \n        \"address\",\n        \"type\",\n        SUM(\"value\") AS \"balance\"\n    FROM double_entry_book\n    GROUP BY \"address\", \"type\"\n),\nmax_min_balances AS (\n    SELECT\n        \"type\",\n        MAX(\"balance\") AS max_balance,\n        MIN(\"balance\") AS min_balance\n    FROM address_balances\n    GROUP BY \"type\"\n)\nSELECT\n    REPLACE(\"type\", '\"', '') AS \"type\",  -- Replace double quotes with nothing\n    max_balance,\n    min_balance\nFROM max_min_balances\nORDER BY \"type\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq070",
        "score": 1,
        "pred_sql": "WITH\n  sm_images AS (\n    SELECT\n      \"SeriesInstanceUID\" AS \"digital_slide_id\", \n      \"StudyInstanceUID\" AS \"case_id\",\n      \"ContainerIdentifier\" AS \"physical_slide_id\",\n      \"PatientID\" AS \"patient_id\",\n      \"TotalPixelMatrixColumns\" AS \"width\", \n      \"TotalPixelMatrixRows\" AS \"height\",\n      \"collection_id\",\n      \"crdc_instance_uuid\",\n      \"gcs_url\", \n      CAST(\n        \"SharedFunctionalGroupsSequence\"[0].\"PixelMeasuresSequence\"[0].\"PixelSpacing\"[0] AS FLOAT\n      ) AS \"pixel_spacing\", \n      CASE \"TransferSyntaxUID\"\n          WHEN '1.2.840.10008.1.2.4.50' THEN 'jpeg'\n          WHEN '1.2.840.10008.1.2.4.91' THEN 'jpeg2000'\n          ELSE 'other'\n      END AS \"compression\"\n    FROM\n      IDC.IDC_V17.DICOM_ALL\n    WHERE\n      \"Modality\" = 'SM' \n      AND \"ImageType\"[2] = 'VOLUME'\n  ),\n\n  tissue_types AS (\n    SELECT DISTINCT *\n    FROM (\n      SELECT\n        \"SeriesInstanceUID\" AS \"digital_slide_id\",\n        CASE \"steps_unnested2\".value:\"CodeValue\"::STRING\n            WHEN '17621005' THEN 'normal' -- meaning: 'Normal' (i.e., non-neoplastic)\n            WHEN '86049000' THEN 'tumor'  -- meaning: 'Neoplasm, Primary'\n            ELSE 'other'                 -- meaning: 'Neoplasm, Metastatic'\n        END AS \"tissue_type\"\n      FROM\n        IDC.IDC_V17.DICOM_ALL\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"SpecimenDescriptionSequence\"[0].\"PrimaryAnatomicStructureSequence\") AS \"steps_unnested1\"\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"steps_unnested1\".value:\"PrimaryAnatomicStructureModifierSequence\") AS \"steps_unnested2\"\n    )\n  ),\n\n  specimen_preparation_sequence_items AS (\n    SELECT DISTINCT *\n    FROM (\n      SELECT\n        \"SeriesInstanceUID\" AS \"digital_slide_id\",\n        \"steps_unnested2\".value:\"ConceptNameCodeSequence\"[0].\"CodeMeaning\"::STRING AS \"item_name\",\n        \"steps_unnested2\".value:\"ConceptCodeSequence\"[0].\"CodeMeaning\"::STRING AS \"item_value\"\n      FROM\n        IDC.IDC_V17.DICOM_ALL\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"SpecimenDescriptionSequence\"[0].\"SpecimenPreparationSequence\") AS \"steps_unnested1\"\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"steps_unnested1\".value:\"SpecimenPreparationStepContentItemSequence\") AS \"steps_unnested2\"\n    )\n  )\n\nSELECT\n  a.*,\n  b.\"tissue_type\",\n  REPLACE(REPLACE(a.\"collection_id\", 'tcga_luad', 'luad'), 'tcga_lusc', 'lscc') AS \"cancer_subtype\"\nFROM \n  sm_images AS a\n  JOIN tissue_types AS b \n    ON b.\"digital_slide_id\" = a.\"digital_slide_id\"\n  JOIN specimen_preparation_sequence_items AS c \n    ON c.\"digital_slide_id\" = a.\"digital_slide_id\"\nWHERE\n  (a.\"collection_id\" = 'tcga_luad' OR a.\"collection_id\" = 'tcga_lusc')\n  AND a.\"compression\" != 'other'\n  AND (b.\"tissue_type\" = 'normal' OR b.\"tissue_type\" = 'tumor')\n  AND (c.\"item_name\" = 'Embedding medium' AND c.\"item_value\" = 'Tissue freezing medium')\nORDER BY \n  a.\"crdc_instance_uuid\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq072",
        "score": 1,
        "pred_sql": "WITH BlackRace AS (\n    SELECT CAST(\"Code\" AS INT) AS CODE\n    FROM DEATH.DEATH.RACE\n    WHERE LOWER(\"Description\") LIKE '%black%'\n)\nSELECT \n    v.\"Age\", \n    v.\"Total\" AS \"Vehicle_Total\", \n    v.\"Black\" AS \"Vehicle_Black\",\n    g.\"Total\" AS \"Gun_Total\", \n    g.\"Black\" AS \"Gun_Black\"\nFROM (\n    SELECT \n        \"Age\", \n        COUNT(*) AS \"Total\", \n        COUNT_IF(\"Race\" IN (SELECT CODE FROM BlackRace)) AS \"Black\"\n    FROM DEATH.DEATH.DEATHRECORDS d\n    JOIN (\n        SELECT \n            DISTINCT e.\"DeathRecordId\" AS \"id\"\n        FROM DEATH.DEATH.ENTITYAXISCONDITIONS e\n        JOIN (\n            SELECT * \n            FROM DEATH.DEATH.ICD10CODE \n            WHERE LOWER(\"Description\") LIKE '%vehicle%'\n        ) c \n        ON e.\"Icd10Code\" = c.\"Code\"\n    ) f\n    ON d.\"Id\" = f.\"id\"\n    WHERE \"Age\" BETWEEN 12 AND 18\n    GROUP BY \"Age\"\n) v  -- Vehicle\n\nJOIN (\n    SELECT \n        \"Age\", \n        COUNT(*) AS \"Total\", \n        COUNT_IF(\"Race\" IN (SELECT CODE FROM BlackRace)) AS \"Black\"\n    FROM DEATH.DEATH.DEATHRECORDS d\n    JOIN (\n        SELECT \n            DISTINCT e.\"DeathRecordId\" AS \"id\"\n        FROM DEATH.DEATH.ENTITYAXISCONDITIONS e\n        JOIN (\n            SELECT \n                \"Code\", \"Description\" \n            FROM DEATH.DEATH.ICD10CODE\n            WHERE \"Description\" LIKE '%firearm%'\n        ) c \n        ON e.\"Icd10Code\" = c.\"Code\"\n    ) f\n    ON d.\"Id\" = f.\"id\"\n    WHERE \"Age\" BETWEEN 12 AND 18\n    GROUP BY \"Age\"\n) g\nON g.\"Age\" = v.\"Age\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq083",
        "score": 1,
        "pred_sql": "SELECT \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) AS \"Date\",  -- \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u65e5\u671f\u683c\u5f0f\uff0c\u9664\u4ee51000000\n  TO_CHAR(SUM(\n      CASE\n          WHEN \"input\" LIKE '0x40c10f19%' THEN 1\n          ELSE -1\n      END * \n      CAST(CONCAT('0x', LTRIM(SUBSTRING(\"input\", \n                                       CASE \n                                           WHEN \"input\" LIKE '0x40c10f19%' THEN 75\n                                           ELSE 11\n                                       END, 64), '0')) AS FLOAT) / 1000000)\n  , '$999,999,999,999') AS \"\u0394 Total Market Value\"\nFROM \n  \"CRYPTO\".\"CRYPTO_ETHEREUM\".\"TRANSACTIONS\"\nWHERE \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) BETWEEN '2023-01-01' AND '2023-12-31'\n  AND \"to_address\" = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'  -- USDC Token\n  AND (\"input\" LIKE '0x42966c68%' -- Burn\n       OR \"input\" LIKE '0x40c10f19%' -- Mint\n  )\nGROUP BY \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000))\nORDER BY \n  \"Date\" DESC;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq091",
        "score": 1,
        "pred_sql": "WITH AA AS (\n    SELECT \n        FIRST_VALUE(\"assignee_harmonized\") OVER (PARTITION BY \"application_number\" ORDER BY \"application_number\") AS assignee_harmonized,\n        FIRST_VALUE(\"filing_date\") OVER (PARTITION BY \"application_number\" ORDER BY \"application_number\") AS filing_date,\n        \"application_number\"\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs\n        , LATERAL FLATTEN(input => pubs.\"cpc\") AS c\n    WHERE \n        c.value:\"code\" LIKE 'A61%'\n),\n\nPatentApplications AS (\n    SELECT \n        ANY_VALUE(assignee_harmonized) as assignee_harmonized,\n        ANY_VALUE(filing_date) as filing_date\n    FROM AA\n    GROUP BY \"application_number\"\n),\n\nAssigneeApplications AS (\nSELECT \n    COUNT(*) AS total_applications,\n    a.value::STRING AS assignee_name,\n    CAST(FLOOR(filing_date / 10000) AS INT) AS filing_year\nFROM \n    PatentApplications\n    , LATERAL FLATTEN(input => assignee_harmonized) AS a\nGROUP BY \n    a.value::STRING, filing_year\n),\n\nTotalApplicationsPerAssignee AS (\n    SELECT\n        assignee_name,\n        SUM(total_applications) AS total_applications\n    FROM \n        AssigneeApplications\n    GROUP BY \n        assignee_name\n    ORDER BY \n        total_applications DESC\n    LIMIT 1\n),\n\nMaxYearForTopAssignee AS (\n    SELECT\n        aa.assignee_name,\n        aa.filing_year,\n        aa.total_applications\n    FROM \n        AssigneeApplications aa\n    INNER JOIN\n        TotalApplicationsPerAssignee tapa ON aa.assignee_name = tapa.assignee_name\n    ORDER BY \n        aa.total_applications DESC\n    LIMIT 1\n)\n\nSELECT filing_year\nFROM \n    MaxYearForTopAssignee\n    \n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq093",
        "score": 1,
        "pred_sql": "WITH double_entry_book AS (\n    -- Debits\n    SELECT \n        \"to_address\" AS \"address\", \n        \"value\" AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRACES\n    WHERE \n        \"to_address\" IS NOT NULL\n        AND \"status\" = 1\n        AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n        AND TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n\n    UNION ALL\n    \n    -- Credits\n    SELECT \n        \"from_address\" AS \"address\", \n        - \"value\" AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRACES\n    WHERE \n        \"from_address\" IS NOT NULL\n        AND \"status\" = 1\n        AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n        AND TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n\n    UNION ALL\n\n    -- Transaction Fees Debits\n    SELECT \n        \"miner\" AS \"address\", \n        SUM(CAST(\"receipt_gas_used\" AS NUMERIC) * CAST(\"gas_price\" AS NUMERIC)) AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRANSACTIONS AS \"transactions\"\n    JOIN \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.BLOCKS AS \"blocks\" \n        ON \"blocks\".\"number\" = \"transactions\".\"block_number\"\n    WHERE \n        TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n    GROUP BY \n        \"blocks\".\"miner\"\n\n    UNION ALL\n    \n    -- Transaction Fees Credits\n    SELECT \n        \"from_address\" AS \"address\", \n        -(CAST(\"receipt_gas_used\" AS NUMERIC) * CAST(\"gas_price\" AS NUMERIC)) AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRANSACTIONS\n    WHERE \n        TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n),\nnet_changes AS (\n    SELECT \n        \"address\",\n        SUM(\"value\") AS \"net_change\"\n    FROM \n        double_entry_book\n    GROUP BY \n        \"address\"\n)\nSELECT \n    MAX(\"net_change\") AS \"max_net_change\",\n    MIN(\"net_change\") AS \"min_net_change\"\nFROM\n    net_changes;",
        "error_info": null
    },
    {
        "instance_id": "sf_bq099",
        "score": 1,
        "pred_sql": "WITH PatentApplications AS (\n   SELECT \n        \"assignee_harmonized\" AS assignee_harmonized,\n        \"filing_date\" AS filing_date,\n        \"country_code\" AS country_code,\n        \"application_number\" AS application_number\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs,\n        LATERAL FLATTEN(input => pubs.\"cpc\") AS c\n    WHERE c.value:\"code\" LIKE 'A01B3%'\n\n),\n\nAssigneeApplications AS (\n    SELECT \n        COUNT(*) AS year_country_cnt,\n        a.value:\"name\" AS assignee_name,\n        CAST(FLOOR(filing_date / 10000) AS INT) AS filing_year,\n        apps.country_code as country_code\n    FROM \n        PatentApplications as apps,\n        LATERAL FLATTEN(input => assignee_harmonized) AS a\n    GROUP BY \n        assignee_name, filing_year, country_code\n),\n\nRankedApplications AS (\n    SELECT\n        assignee_name,\n        filing_year,\n        country_code,\n        year_country_cnt,\n        SUM(year_country_cnt) OVER (PARTITION BY assignee_name, filing_year) AS total_cnt,\n        ROW_NUMBER() OVER (PARTITION BY assignee_name, filing_year ORDER BY year_country_cnt DESC) AS rn\n    FROM\n        AssigneeApplications\n),\n\nAggregatedData AS (\n    SELECT\n        total_cnt AS year_cnt,\n        assignee_name,\n        filing_year,\n        country_code\n    FROM\n        RankedApplications\n    WHERE\n        rn = 1\n)\n\n\nSELECT \n    total_count,\n    REPLACE(assignee_name, '\"', '') AS assignee_name,\n    year_cnt,\n    filing_year,\n    country_code\nFROM (\n    SELECT \n        year_cnt,\n        assignee_name,\n        filing_year,\n        country_code,\n        SUM(year_cnt) OVER (PARTITION BY assignee_name) AS total_count,\n        ROW_NUMBER() OVER (PARTITION BY assignee_name ORDER BY year_cnt DESC) AS rn\n    FROM\n        AggregatedData\n    ORDER BY assignee_name\n) sub\nWHERE rn = 1\nORDER BY total_count\nDESC\nLIMIT 3",
        "error_info": null
    },
    {
        "instance_id": "sf_bq104",
        "score": 1,
        "pred_sql": "WITH LatestWeek AS (\n    SELECT\n        DATEADD(WEEK, -52, MAX(\"week\")) AS \"last_year_week\"\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n),\nLatestRefreshDate AS (\n    SELECT\n        MAX(\"refresh_date\") AS \"latest_refresh_date\"\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n),\nRankedTerms AS (\n    SELECT\n        \"term\",\n        \"week\",\n        CASE WHEN \"score\" IS NULL THEN NULL ELSE \"dma_name\" END AS \"dma_name\",\n        \"rank\",\n        \"score\",\n        ROW_NUMBER() OVER (\n            PARTITION BY \"term\", \"week\"\n            ORDER BY \"score\" DESC\n        ) AS rn\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n    WHERE\n        \"week\" = (SELECT \"last_year_week\" FROM LatestWeek)\n        AND \"refresh_date\" = (SELECT \"latest_refresh_date\" FROM LatestRefreshDate)\n)\n\nSELECT\n    \"term\"\nFROM\n    RankedTerms\nWHERE\n    rn = 1\nORDER BY\n    \"rank\"\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq121",
        "score": 1,
        "pred_sql": "WITH sub AS (\n  SELECT \n    \"users\".\"id\",\n    CAST(TO_TIMESTAMP(MAX(\"users\".\"creation_date\") / 1000000.0) AS DATE) AS \"user_creation_date\",  -- \u4f7f\u7528 MAX \u805a\u5408 creation_date \u5e76\u8f6c\u6362\u4e3a DATE\n    MAX(\"users\".\"reputation\") AS \"reputation\",  \n    SUM(CASE WHEN badges.\"user_id\" IS NULL THEN 0 ELSE 1 END) AS \"num_badges\"\n  FROM \"STACKOVERFLOW\".\"STACKOVERFLOW\".\"USERS\" \"users\"\n  LEFT JOIN \"STACKOVERFLOW\".\"STACKOVERFLOW\".\"BADGES\" badges\n    ON \"users\".\"id\" = badges.\"user_id\"\n  WHERE CAST(TO_TIMESTAMP(\"users\".\"creation_date\" / 1000000.0) AS DATE) <= DATE '2021-10-01'\n  GROUP BY \"users\".\"id\"\n)\n\nSELECT \n  DATEDIFF(YEAR, \"user_creation_date\", DATE '2021-10-01') AS \"user_tenure\",\n  COUNT(1) AS \"Num_Users\",\n  AVG(\"reputation\") AS \"Avg_Reputation\",\n  AVG(\"num_badges\") AS \"Avg_Num_Badges\"\nFROM sub\nGROUP BY \"user_tenure\"\nORDER BY \"user_tenure\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq127",
        "score": 1,
        "pred_sql": "WITH fam AS (\n  SELECT DISTINCT\n    \"family_id\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\"\n),\n\ncrossover AS (\n  SELECT\n    \"publication_number\",\n    \"family_id\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\"\n),\n\npub AS (\n  SELECT\n    \"family_id\",\n    MIN(\"publication_date\") AS \"publication_date\",\n    LISTAGG(\"publication_number\", ',') WITHIN GROUP (ORDER BY \"publication_number\") AS \"publication_number\",\n    LISTAGG(\"country_code\", ',') WITHIN GROUP (ORDER BY \"country_code\") AS \"country_code\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n  GROUP BY\n    \"family_id\"\n),\n\ntech_class AS (\n  SELECT\n    p.\"family_id\",\n    LISTAGG(DISTINCT cpc.value:\"code\"::STRING, ',') WITHIN GROUP (ORDER BY cpc.value:\"code\"::STRING) AS \"cpc\",\n    LISTAGG(DISTINCT ipc.value:\"code\"::STRING, ',') WITHIN GROUP (ORDER BY ipc.value:\"code\"::STRING) AS \"ipc\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"cpc\") AS cpc\n    CROSS JOIN LATERAL FLATTEN(input => p.\"ipc\") AS ipc\n  GROUP BY\n    p.\"family_id\"\n),\n\ncit AS (\n  SELECT\n    p.\"family_id\",\n    LISTAGG(crossover.\"family_id\", ',') WITHIN GROUP (ORDER BY crossover.\"family_id\" ASC) AS \"citation\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"citation\") AS citation\n    LEFT JOIN\n      crossover\n    ON\n      citation.value:\"publication_number\"::STRING = crossover.\"publication_number\"\n  GROUP BY\n    p.\"family_id\"\n),\n\ntmp_gpr AS (\n  SELECT\n    \"family_id\",\n    LISTAGG(crossover.\"publication_number\", ',') AS \"cited_by_publication_number\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"ABS_AND_EMB\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"cited_by\") AS cited_by\n    LEFT JOIN\n      crossover\n    ON\n      cited_by.value:\"publication_number\"::STRING = crossover.\"publication_number\"\n  GROUP BY\n    \"family_id\"\n),\n\ngpr AS (\n  SELECT\n    tmp_gpr.\"family_id\",\n    LISTAGG(crossover.\"family_id\", ',') WITHIN GROUP (ORDER BY crossover.\"family_id\" ASC) AS \"cited_by\"\n  FROM\n    tmp_gpr\n    CROSS JOIN LATERAL FLATTEN(input => SPLIT(tmp_gpr.\"cited_by_publication_number\", ',')) AS cited_by_publication_number\n    LEFT JOIN\n      crossover\n    ON\n      cited_by_publication_number.value::STRING = crossover.\"publication_number\"\n  GROUP BY\n    tmp_gpr.\"family_id\"\n)\n\nSELECT\n  fam.\"family_id\",\n  pub.\"publication_date\",\n  pub.\"publication_number\",\n  pub.\"country_code\",\n  tech_class.\"cpc\",\n  tech_class.\"ipc\",\n  cit.\"citation\",\n  gpr.\"cited_by\"\nFROM\n  fam\n  LEFT JOIN pub ON fam.\"family_id\" = pub.\"family_id\"\n  LEFT JOIN tech_class ON fam.\"family_id\" = tech_class.\"family_id\"\n  LEFT JOIN cit ON fam.\"family_id\" = cit.\"family_id\"\n  LEFT JOIN gpr ON fam.\"family_id\" = gpr.\"family_id\"\nWHERE\n  pub.\"publication_date\" BETWEEN 20150101 AND 20150131;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq128",
        "score": 1,
        "pred_sql": "SELECT\n    patent.\"title\",\n    patent.\"abstract\",\n    app.\"date\" AS publication_date,\n    filterData.\"bkwdCitations\",\n    filterData.\"fwrdCitations_5\"\nFROM\n    \"PATENTSVIEW\".\"PATENTSVIEW\".\"PATENT\" AS patent\nJOIN\n    \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS app\n    ON app.\"patent_id\" = patent.\"id\"\nJOIN (\n    SELECT\n        DISTINCT cpc.\"patent_id\",\n        IFNULL(citation_5.\"bkwdCitations\", 0) AS \"bkwdCitations\",\n        IFNULL(citation_5.\"fwrdCitations_5\", 0) AS \"fwrdCitations_5\"\n    FROM\n        \"PATENTSVIEW\".\"PATENTSVIEW\".\"CPC_CURRENT\" AS cpc\n    LEFT JOIN (\n        SELECT\n            b.\"patent_id\",\n            b.\"bkwdCitations\",\n            f.\"fwrdCitations_5\"\n        FROM (\n            SELECT \n                cited.\"citation_id\" AS \"patent_id\",\n                IFNULL(COUNT(*), 0) AS \"fwrdCitations_5\"\n            FROM \n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"USPATENTCITATION\" AS cited\n            JOIN\n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS apps\n                ON cited.\"citation_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" >= apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(YEAR, 5, TRY_CAST(apps.\"date\" AS DATE)) -- 5-year citation window\n            GROUP BY \n                cited.\"citation_id\"\n        ) AS f\n        JOIN (\n            SELECT \n                cited.\"patent_id\",\n                IFNULL(COUNT(*), 0) AS \"bkwdCitations\"\n            FROM \n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"USPATENTCITATION\" AS cited\n            JOIN\n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" < apps.\"date\" -- backward citation count\n            GROUP BY \n                cited.\"patent_id\"\n        ) AS b\n        ON b.\"patent_id\" = f.\"patent_id\"\n        WHERE\n            b.\"bkwdCitations\" IS NOT NULL\n            AND f.\"fwrdCitations_5\" IS NOT NULL\n    ) AS citation_5 \n    ON cpc.\"patent_id\" = citation_5.\"patent_id\"\n    WHERE \n        cpc.\"subsection_id\" IN ('C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', 'C13')\n        OR cpc.\"group_id\" IN ('A01G', 'A01H', 'A61K', 'A61P', 'A61Q', 'B01F', 'B01J', 'B81B', 'B82B', 'B82Y', 'G01N', 'G16H')\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nWHERE\n    TRY_CAST(app.\"date\" AS DATE) < '2014-02-01' \n    AND TRY_CAST(app.\"date\" AS DATE) >= '2014-01-01';\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq150",
        "score": 1,
        "pred_sql": "WITH\ncohortExpr AS (\n  SELECT\n    \"sample_barcode\",\n    LOG(10, \"normalized_count\") AS \"expr\"\n  FROM\n    \"TCGA_HG19_DATA_V0\".\"TCGA_HG19_DATA_V0\".\"RNASEQ_GENE_EXPRESSION_UNC_RSEM\"\n  WHERE\n    \"project_short_name\" = 'TCGA-BRCA'\n    AND \"HGNC_gene_symbol\" = 'TP53'\n    AND \"normalized_count\" IS NOT NULL\n    AND \"normalized_count\" > 0\n),\ncohortVar AS (\n  SELECT\n    \"Variant_Type\",\n    \"sample_barcode_tumor\" AS \"sample_barcode\"\n  FROM\n    \"TCGA_HG19_DATA_V0\".\"TCGA_HG19_DATA_V0\".\"SOMATIC_MUTATION_MC3\"\n  WHERE\n    \"SYMBOL\" = 'TP53'\n),\ncohort AS (\n  SELECT\n    e.\"sample_barcode\" AS \"sample_barcode\",\n    v.\"Variant_Type\" AS \"group_name\",\n    e.\"expr\"\n  FROM\n    cohortExpr e\n  JOIN\n    cohortVar v\n  ON\n    e.\"sample_barcode\" = v.\"sample_barcode\"\n),\ngrandMeanTable AS (\n  SELECT\n    AVG(\"expr\") AS \"grand_mean\"\n  FROM\n    cohort\n),\ngroupMeansTable AS (\n  SELECT\n    AVG(\"expr\") AS \"group_mean\",\n    \"group_name\",\n    COUNT(\"sample_barcode\") AS \"n\"\n  FROM\n    cohort\n  GROUP BY\n    \"group_name\"\n),\nssBetween AS (\n  SELECT\n    g.\"group_name\",\n    g.\"group_mean\",\n    gm.\"grand_mean\",\n    g.\"n\",\n    g.\"n\" * POW(g.\"group_mean\" - gm.\"grand_mean\", 2) AS \"n_diff_sq\"\n  FROM\n    groupMeansTable g\n  CROSS JOIN\n    grandMeanTable gm\n),\nssWithin AS (\n  SELECT\n    c.\"group_name\" AS \"group_name\",\n    c.\"expr\",\n    b.\"group_mean\",\n    b.\"n\" AS \"n\",\n    POW(c.\"expr\" - b.\"group_mean\", 2) AS \"s2\"\n  FROM\n    cohort c\n  JOIN\n    ssBetween b\n  ON\n    c.\"group_name\" = b.\"group_name\"\n),\nnumerator AS (\n  SELECT\n    SUM(\"n_diff_sq\") / (COUNT(\"group_name\") - 1) AS \"mean_sq_between\"\n  FROM\n    ssBetween\n),\ndenominator AS (\n  SELECT\n    COUNT(DISTINCT \"group_name\") AS \"k\",\n    COUNT(\"group_name\") AS \"n\",\n    SUM(\"s2\") / (COUNT(\"group_name\") - COUNT(DISTINCT \"group_name\")) AS \"mean_sq_within\"\n  FROM\n    ssWithin\n)\n\nSELECT\n  \"n\",\n  \"k\",\n  \"mean_sq_between\",\n  \"mean_sq_within\",\n  \"mean_sq_between\" / \"mean_sq_within\" AS \"F\"\nFROM\n  numerator,\n  denominator;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq153",
        "score": 1,
        "pred_sql": "WITH\n    table1 AS (\n        SELECT \n            \"Symbol\" AS \"symbol\", \n            AVG(LOG(10, \"normalized_count\" + 1)) AS \"data\", \n            \"ParticipantBarcode\"\n        FROM \n            PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.EBPP_ADJUSTPANCAN_ILLUMINAHISEQ_RNASEQV2_GENEXP_FILTERED\n        WHERE \n            \"Study\" = 'LGG' \n            AND \"Symbol\" = 'IGF2' \n            AND \"normalized_count\" IS NOT NULL\n        GROUP BY \n            \"ParticipantBarcode\", \"symbol\"\n    ),\n    table2 AS (\n        SELECT\n            \"symbol\",\n            \"avgdata\" AS \"data\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                'icd_o_3_histology' AS \"symbol\", \n                \"icd_o_3_histology\" AS \"avgdata\",\n                \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n            FROM \n                PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\n            WHERE \n                \"acronym\" = 'LGG' \n                AND \"icd_o_3_histology\" IS NOT NULL  \n                AND NOT REGEXP_LIKE(\"icd_o_3_histology\", '^(\\\\[.*\\\\]$)')\n        )\n    ),\n    table_data AS (\n        SELECT \n            n1.\"data\" AS \"data1\",\n            n2.\"data\" AS \"data2\",\n            n1.\"ParticipantBarcode\"\n        FROM \n            table1 AS n1\n        INNER JOIN \n            table2 AS n2\n        ON \n            n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n    ) \n\nSELECT \n    \"data2\" AS \"Histology_Type\", \n    AVG(\"data1\") AS \"Average_Log_Expression\"\nFROM \n    table_data\nGROUP BY \n    \"data2\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq155",
        "score": 1,
        "pred_sql": "WITH cohort AS (\n    SELECT \"case_barcode\"\n    FROM \"TCGA_HG38_DATA_V0\".\"TCGA_BIOCLIN_V0\".\"CLINICAL\"\n    WHERE \"project_short_name\" = 'TCGA-BRCA'\n        AND \"age_at_diagnosis\" <= 80\n        AND \"pathologic_stage\" IN ('Stage I', 'Stage II', 'Stage IIA')\n),\ntable1 AS (\n    SELECT\n        \"symbol\",\n        \"data\" AS \"rnkdata\",\n        \"ParticipantBarcode\"\n    FROM (\n        SELECT\n            \"gene_name\" AS \"symbol\", \n            AVG(LOG(10, \"HTSeq__Counts\" + 1)) AS \"data\",\n            \"case_barcode\" AS \"ParticipantBarcode\"\n        FROM \"TCGA_HG38_DATA_V0\".\"TCGA_HG38_DATA_V0\".\"RNASEQ_GENE_EXPRESSION\"\n        WHERE \"case_barcode\" IN (SELECT \"case_barcode\" FROM cohort)\n            AND \"gene_name\" = 'SNORA31'\n            AND \"HTSeq__Counts\" IS NOT NULL\n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    )\n),\ntable2 AS (\n    SELECT\n        \"symbol\",\n        \"data\" AS \"rnkdata\",\n        \"ParticipantBarcode\"\n    FROM (\n        SELECT\n            \"mirna_id\" AS \"symbol\", \n            AVG(\"reads_per_million_miRNA_mapped\") AS \"data\",\n            \"case_barcode\" AS \"ParticipantBarcode\"\n        FROM \"TCGA_HG38_DATA_V0\".\"TCGA_HG38_DATA_V0\".\"MIRNASEQ_EXPRESSION\"\n        WHERE \"case_barcode\" IN (SELECT \"case_barcode\" FROM cohort)\n            AND \"mirna_id\" IS NOT NULL\n            AND \"reads_per_million_miRNA_mapped\" IS NOT NULL\n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    )\n),\nsumm_table AS (\n    SELECT \n        n1.\"symbol\" AS \"symbol1\",\n        n2.\"symbol\" AS \"symbol2\",\n        COUNT(n1.\"ParticipantBarcode\") AS \"n\",\n        CORR(n1.\"rnkdata\", n2.\"rnkdata\") AS \"correlation\"\n    FROM\n        table1 AS n1\n    INNER JOIN\n        table2 AS n2\n    ON\n        n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n    GROUP BY\n        \"symbol1\", \"symbol2\"\n)\n\nSELECT \n    \"symbol1\", \n    \"symbol2\", \n    ABS(\"correlation\") * SQRT(( \"n\" - 2 ) / (1 - \"correlation\" * \"correlation\")) AS \"t\"\nFROM \n    summ_table\nWHERE \n    \"n\" > 25 \n    AND ABS(\"correlation\") >= 0.3 \n    AND ABS(\"correlation\") < 1.0;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq158",
        "score": 1,
        "pred_sql": "WITH\n    table1 AS (\n        SELECT\n            \"histological_type\" AS \"data1\",\n            \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n        FROM \n            \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\"\n        WHERE \n            \"acronym\" = 'BRCA' \n            AND \"histological_type\" IS NOT NULL      \n    ),\n    table2 AS (\n        SELECT\n            \"Hugo_Symbol\" AS \"symbol\", \n            \"ParticipantBarcode\"\n        FROM \n            \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"MC3_MAF_V5_ONE_PER_TUMOR_SAMPLE\"\n        WHERE \n            \"Study\" = 'BRCA' \n            AND \"Hugo_Symbol\" = 'CDH1'\n            AND \"FILTER\" = 'PASS'  \n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    ),\n    summ_table AS (\n        SELECT \n            n1.\"data1\",\n            CASE \n                WHEN n2.\"ParticipantBarcode\" IS NULL THEN 'NO' \n                ELSE 'YES' \n            END AS \"data2\",\n            COUNT(*) AS \"Nij\"\n        FROM\n            table1 AS n1\n        LEFT JOIN\n            table2 AS n2 \n            ON n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n        GROUP BY\n            n1.\"data1\", \"data2\"\n    ),\n    percentages AS (\n        SELECT\n            \"data1\",\n            SUM(CASE WHEN \"data2\" = 'YES' THEN \"Nij\" ELSE 0 END) AS \"mutation_count\",\n            SUM(\"Nij\") AS \"total\",\n            SUM(CASE WHEN \"data2\" = 'YES' THEN \"Nij\" ELSE 0 END) / SUM(\"Nij\") AS \"mutation_percentage\"\n        FROM \n            summ_table\n        GROUP BY \n            \"data1\"\n    )\nSELECT \n    \"data1\" AS \"Histological_Type\"\nFROM \n    percentages\nORDER BY \n    \"mutation_percentage\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq159",
        "score": 1,
        "pred_sql": "WITH\n    table1 AS (\n        SELECT\n            \"symbol\",\n            \"avgdata\" AS \"data\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                'histological_type' AS \"symbol\", \n                \"histological_type\" AS \"avgdata\",\n                \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n            FROM \n                \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\"\n            WHERE \n                \"acronym\" = 'BRCA' \n                AND \"histological_type\" IS NOT NULL      \n        )\n    ),\n    table2 AS (\n        SELECT\n            \"symbol\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                \"Hugo_Symbol\" AS \"symbol\", \n                \"ParticipantBarcode\" AS \"ParticipantBarcode\"\n            FROM \n                \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"MC3_MAF_V5_ONE_PER_TUMOR_SAMPLE\"\n            WHERE \n                \"Study\" = 'BRCA' \n                AND \"Hugo_Symbol\" = 'CDH1'\n                AND \"FILTER\" = 'PASS'  \n            GROUP BY\n                \"ParticipantBarcode\", \"symbol\"\n        )\n    ),\n    summ_table AS (\n        SELECT \n            n1.\"data\" AS \"data1\",\n            CASE \n                WHEN n2.\"ParticipantBarcode\" IS NULL THEN 'NO' \n                ELSE 'YES' \n            END AS \"data2\",\n            COUNT(*) AS \"Nij\"\n        FROM\n            table1 AS n1\n        LEFT JOIN\n            table2 AS n2 \n            ON n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n        GROUP BY\n            n1.\"data\", \"data2\"\n    ),\n    expected_table AS (\n        SELECT \n            \"data1\", \n            \"data2\"\n        FROM (     \n            SELECT \n                \"data1\", \n                SUM(\"Nij\") AS \"Ni\"   \n            FROM \n                summ_table\n            GROUP BY \n                \"data1\"\n        ) AS Ni_table\n        CROSS JOIN ( \n            SELECT \n                \"data2\", \n                SUM(\"Nij\") AS \"Nj\"\n            FROM \n                summ_table\n            GROUP BY \n                \"data2\"\n        ) AS Nj_table\n        WHERE \n            Ni_table.\"Ni\" > 10 \n            AND Nj_table.\"Nj\" > 10\n    ),\n    contingency_table AS (\n        SELECT\n            T1.\"data1\",\n            T1.\"data2\",\n            COALESCE(T2.\"Nij\", 0) AS \"Nij\",\n            (SUM(T2.\"Nij\") OVER (PARTITION BY T1.\"data1\")) * \n            (SUM(T2.\"Nij\") OVER (PARTITION BY T1.\"data2\")) / \n            SUM(T2.\"Nij\") OVER () AS \"E_nij\"\n        FROM\n            expected_table AS T1\n        LEFT JOIN\n            summ_table AS T2\n        ON \n            T1.\"data1\" = T2.\"data1\" \n            AND T1.\"data2\" = T2.\"data2\"\n    )\nSELECT\n    SUM( ( \"Nij\" - \"E_nij\" ) * ( \"Nij\" - \"E_nij\" ) / \"E_nij\" ) AS \"Chi2\"\nFROM \n    contingency_table;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq166",
        "score": 1,
        "pred_sql": "WITH copy AS (\n  SELECT \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\", \n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    \"TCGA_MITELMAN\".\"TCGA_VERSIONED\".\"COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23\" \n  WHERE  \n    \"project_short_name\" = 'TCGA-KIRC'\n  GROUP BY \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\"\n),\ntotal_cases AS (\n  SELECT COUNT(DISTINCT \"case_barcode\") AS \"total\"\n  FROM copy \n),\ncytob AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\"\n  FROM \n    \"TCGA_MITELMAN\".\"PROD\".\"CYTOBANDS_HG38\"\n),\njoined AS (\n  SELECT \n    cytob.\"chromosome\", \n    cytob.\"cytoband_name\", \n    cytob.\"hg38_start\", \n    cytob.\"hg38_stop\",\n    copy.\"case_barcode\",\n    copy.\"copy_number\"  \n  FROM \n    copy\n  LEFT JOIN cytob\n    ON cytob.\"chromosome\" = copy.\"chromosome\" \n  WHERE \n    (cytob.\"hg38_start\" >= copy.\"start_pos\" AND copy.\"end_pos\" >= cytob.\"hg38_start\")\n    OR (copy.\"start_pos\" >= cytob.\"hg38_start\" AND copy.\"start_pos\" <= cytob.\"hg38_stop\")\n),\ncbands AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\",\n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    joined\n  GROUP BY \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\"\n),\naberrations AS (\n  SELECT\n    \"chromosome\",\n    \"cytoband_name\",\n    -- Amplifications: more than two copies for diploid > 4\n    SUM( CASE WHEN \"copy_number\" > 3 THEN 1 ELSE 0 END ) AS \"total_amp\",\n    -- Gains: at most two extra copies\n    SUM( CASE WHEN \"copy_number\" = 3 THEN 1 ELSE 0 END ) AS \"total_gain\",\n    -- Homozygous deletions, or complete deletions\n    SUM( CASE WHEN \"copy_number\" = 0 THEN 1 ELSE 0 END ) AS \"total_homodel\",\n    -- Heterozygous deletions, 1 copy lost\n    SUM( CASE WHEN \"copy_number\" = 1 THEN 1 ELSE 0 END ) AS \"total_heterodel\",\n    -- Normal for Diploid = 2\n    SUM( CASE WHEN \"copy_number\" = 2 THEN 1 ELSE 0 END ) AS \"total_normal\"\n  FROM \n    cbands\n  GROUP BY \n    \"chromosome\", \n    \"cytoband_name\"\n)\nSELECT \n  aberrations.\"chromosome\", \n  aberrations.\"cytoband_name\",\n  total_cases.\"total\",  \n  100 * aberrations.\"total_amp\" / total_cases.\"total\" AS \"freq_amp\", \n  100 * aberrations.\"total_gain\" / total_cases.\"total\" AS \"freq_gain\",\n  100 * aberrations.\"total_homodel\" / total_cases.\"total\" AS \"freq_homodel\", \n  100 * aberrations.\"total_heterodel\" / total_cases.\"total\" AS \"freq_heterodel\", \n  100 * aberrations.\"total_normal\" / total_cases.\"total\" AS \"freq_normal\"  \nFROM \n  aberrations, \n  total_cases\nORDER BY \n  aberrations.\"chromosome\", \n  aberrations.\"cytoband_name\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq167",
        "score": 1,
        "pred_sql": "WITH UserPairUpvotes AS (\n  SELECT\n    ToUsers.\"UserName\" AS \"ToUserName\",\n    FromUsers.\"UserName\" AS \"FromUserName\",\n    COUNT(DISTINCT \"ForumMessageVotes\".\"Id\") AS \"UpvoteCount\"\n  FROM META_KAGGLE.META_KAGGLE.FORUMMESSAGEVOTES AS \"ForumMessageVotes\"\n  INNER JOIN META_KAGGLE.META_KAGGLE.USERS AS FromUsers\n    ON FromUsers.\"Id\" = \"ForumMessageVotes\".\"FromUserId\"\n  INNER JOIN META_KAGGLE.META_KAGGLE.USERS AS ToUsers\n    ON ToUsers.\"Id\" = \"ForumMessageVotes\".\"ToUserId\"\n  GROUP BY\n    ToUsers.\"UserName\",\n    FromUsers.\"UserName\"\n),\nTopPairs AS (\n  SELECT\n    \"ToUserName\",\n    \"FromUserName\",\n    \"UpvoteCount\",\n    ROW_NUMBER() OVER (ORDER BY \"UpvoteCount\" DESC) AS \"Rank\"\n  FROM UserPairUpvotes\n),\nReciprocalUpvotes AS (\n  SELECT\n    t.\"ToUserName\",\n    t.\"FromUserName\",\n    t.\"UpvoteCount\" AS \"UpvotesReceived\",\n    COALESCE(u.\"UpvoteCount\", 0) AS \"UpvotesGiven\"\n  FROM TopPairs t\n  LEFT JOIN UserPairUpvotes u\n    ON t.\"ToUserName\" = u.\"FromUserName\" AND t.\"FromUserName\" = u.\"ToUserName\"\n  WHERE t.\"Rank\" = 1\n)\nSELECT\n  \"ToUserName\" AS \"UpvotedUserName\",\n  \"FromUserName\" AS \"UpvotingUserName\",\n  \"UpvotesReceived\" AS \"UpvotesReceivedByUpvotedUser\",\n  \"UpvotesGiven\" AS \"UpvotesGivenByUpvotedUser\"\nFROM ReciprocalUpvotes\nORDER BY \"UpvotesReceived\" DESC, \"UpvotesGiven\" DESC;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq176",
        "score": 1,
        "pred_sql": "WITH copy AS (\n  SELECT \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\", \n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    \"TCGA_MITELMAN\".\"TCGA_VERSIONED\".\"COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23\"\n  WHERE \n    \"project_short_name\" = 'TCGA-LAML'\n  GROUP BY \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\"\n),\ntotal_cases AS (\n  SELECT COUNT(DISTINCT \"case_barcode\") AS \"total\"\n  FROM copy\n),\ncytob AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\"\n  FROM \n    \"TCGA_MITELMAN\".\"PROD\".\"CYTOBANDS_HG38\"\n),\njoined AS (\n  SELECT \n    cytob.\"chromosome\", \n    cytob.\"cytoband_name\", \n    cytob.\"hg38_start\", \n    cytob.\"hg38_stop\", \n    copy.\"case_barcode\",\n    (ABS(cytob.\"hg38_stop\" - cytob.\"hg38_start\") + ABS(copy.\"end_pos\" - copy.\"start_pos\") \n      - ABS(cytob.\"hg38_stop\" - copy.\"end_pos\") - ABS(cytob.\"hg38_start\" - copy.\"start_pos\")) / 2.0 AS \"overlap\", \n    copy.\"copy_number\"\n  FROM \n    copy\n  LEFT JOIN \n    cytob\n  ON \n    cytob.\"chromosome\" = copy.\"chromosome\"\n  WHERE \n    (cytob.\"hg38_start\" >= copy.\"start_pos\" AND copy.\"end_pos\" >= cytob.\"hg38_start\")\n    OR (copy.\"start_pos\" >= cytob.\"hg38_start\" AND copy.\"start_pos\" <= cytob.\"hg38_stop\")\n),\nINFO AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\",\n    ROUND(SUM(\"overlap\" * \"copy_number\") / SUM(\"overlap\")) AS \"copy_number\"\n  FROM \n    joined\n  GROUP BY \n    \"chromosome\", \"cytoband_name\", \"hg38_start\", \"hg38_stop\", \"case_barcode\"\n)\n\nSELECT \n  \"case_barcode\"\nFROM \n  INFO\nWHERE \n  \"chromosome\" = 'chr15' \n  AND \"cytoband_name\" = '15q11'\nORDER BY \n  \"copy_number\" DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq182",
        "score": 1,
        "pred_sql": "WITH\n  event_data AS (\n    SELECT\n      \"type\",\n      EXTRACT(YEAR FROM TO_TIMESTAMP(\"created_at\" / 1000000)) AS \"year\",\n      EXTRACT(QUARTER FROM TO_TIMESTAMP(\"created_at\" / 1000000)) AS \"quarter\",\n      REGEXP_REPLACE(\n        \"repo\"::variant:\"url\"::string,\n        'https:\\\\/\\\\/github\\\\.com\\\\/|https:\\\\/\\\\/api\\\\.github\\\\.com\\\\/repos\\\\/',\n        ''\n      ) AS \"name\"\n    FROM GITHUB_REPOS_DATE.DAY._20230118\n  ),\n\n  repo_languages AS (\n    SELECT\n      \"repo_name\" AS \"name\",\n      \"lang\"\n    FROM (\n      SELECT\n        \"repo_name\",\n        FIRST_VALUE(\"language\") OVER (\n          PARTITION BY \"repo_name\" ORDER BY \"bytes\" DESC\n        ) AS \"lang\"\n      FROM (\n        SELECT\n          \"repo_name\",\n          \"language\".value:\"name\" AS \"language\",\n          \"language\".value:\"bytes\" AS \"bytes\"\n        FROM GITHUB_REPOS_DATE.GITHUB_REPOS.LANGUAGES,\n        LATERAL FLATTEN(INPUT => \"language\") AS \"language\"\n      )\n    )\n    WHERE \"lang\" IS NOT NULL\n    GROUP BY \"repo_name\", \"lang\"\n  ),\n\n  joined_data AS (\n    SELECT\n      a.\"type\" AS \"type\",\n      b.\"lang\" AS \"language\",\n      a.\"year\" AS \"year\",\n      a.\"quarter\" AS \"quarter\"\n    FROM event_data a\n    JOIN repo_languages b\n      ON a.\"name\" = b.\"name\"\n  ),\n\n  count_data AS (\n    SELECT\n      \"language\",\n      \"year\",\n      \"quarter\",\n      \"type\",\n      COUNT(*) AS \"count\"\n    FROM joined_data\n    GROUP BY \"type\", \"language\", \"year\", \"quarter\"\n    ORDER BY \"year\", \"quarter\", \"count\" DESC\n  )\n\nSELECT\n  REPLACE(\"language\", '\"', '') AS \"language_name\",\n  \"count\"\nFROM count_data\nWHERE \"count\" >= 5\n  AND \"type\" = 'PullRequestEvent';\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq187",
        "score": 1,
        "pred_sql": "WITH tokenInfo AS (\n    SELECT \"address\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\"\n    WHERE \"name\" = 'BNB'\n),\n\nreceivedTx AS (\n    SELECT \"tx\".\"to_address\" AS \"addr\", \n           \"tokens\".\"name\" AS \"name\", \n           SUM(CAST(\"tx\".\"value\" AS FLOAT) / POWER(10, 18)) AS \"amount_received\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKEN_TRANSFERS\" AS \"tx\"\n    JOIN tokenInfo ON \"tx\".\"token_address\" = tokenInfo.\"address\"\n    JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\" AS \"tokens\"\n      ON \"tx\".\"token_address\" = \"tokens\".\"address\"\n    WHERE \"tx\".\"to_address\" <> '0x0000000000000000000000000000000000000000'\n    GROUP BY \"tx\".\"to_address\", \"tokens\".\"name\"\n),\n\nsentTx AS (\n    SELECT \"tx\".\"from_address\" AS \"addr\", \n           \"tokens\".\"name\" AS \"name\", \n           SUM(CAST(\"tx\".\"value\" AS FLOAT) / POWER(10, 18)) AS \"amount_sent\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKEN_TRANSFERS\" AS \"tx\"\n    JOIN tokenInfo ON \"tx\".\"token_address\" = tokenInfo.\"address\"\n    JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\" AS \"tokens\"\n      ON \"tx\".\"token_address\" = \"tokens\".\"address\"\n    WHERE \"tx\".\"from_address\" <> '0x0000000000000000000000000000000000000000'\n    GROUP BY \"tx\".\"from_address\", \"tokens\".\"name\"\n),\n\nwalletBalances AS (\n    SELECT r.\"addr\",\n           COALESCE(SUM(r.\"amount_received\"), 0) - COALESCE(SUM(s.\"amount_sent\"), 0) AS \"balance\"\n    FROM receivedTx AS r\n    LEFT JOIN sentTx AS s\n      ON r.\"addr\" = s.\"addr\"\n    GROUP BY r.\"addr\"\n)\n\nSELECT \n    SUM(\"balance\") AS \"circulating_supply\"\nFROM walletBalances;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq193",
        "score": 1,
        "pred_sql": "WITH content_extracted AS (\n    SELECT \n        \"D\".\"id\" AS \"id\",\n        \"repo_name\",\n        \"path\",\n        SPLIT(\"content\", '\\n') AS \"lines\",\n        \"language_name\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_CONTENTS\"\n        ) AS \"D\"\n    INNER JOIN \n        (\n            SELECT \n                \"id\",\n                \"C\".\"repo_name\" AS \"repo_name\",\n                \"path\",\n                \"language_name\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_FILES\"\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                ) AS \"C\"\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        \"language_struct\".value:\"name\" AS \"language_name\"\n                    FROM \n                        (\n                            SELECT \n                                \"repo_name\", \n                                \"language\"\n                            FROM \n                                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"LANGUAGES\"\n                        )\n                    CROSS JOIN \n                        LATERAL FLATTEN(INPUT => \"language\") AS \"language_struct\"\n                ) AS \"F\"\n            ON \n                \"C\".\"repo_name\" = \"F\".\"repo_name\"\n        ) AS \"E\"\n    ON \n        \"E\".\"id\" = \"D\".\"id\"\n),\nnon_empty_lines AS (\n    SELECT \n        \"line\".value AS \"line_\",\n        \"language_name\"\n    FROM \n        content_extracted,\n        LATERAL FLATTEN(INPUT => \"lines\") AS \"line\"\n    WHERE \n        TRIM(\"line\".value) != ''\n        AND NOT STARTSWITH(TRIM(\"line\".value), '#')\n        AND NOT STARTSWITH(TRIM(\"line\".value), '//')\n),\naggregated_languages AS (\n    SELECT \n        \"line_\",\n        COUNT(*) AS \"frequency\",\n        ARRAY_AGG(\"language_name\") AS \"languages\"\n    FROM \n        non_empty_lines\n    GROUP BY \n        \"line_\"\n)\n\nSELECT \n    REGEXP_REPLACE(\"line_\", '^\"|\"$', '') AS \"line\",\n    \"frequency\",\n    ARRAY_TO_STRING(ARRAY_SORT(\"languages\"), ', ') AS \"languages_sorted\"\nFROM \n    aggregated_languages\nORDER BY \n    \"frequency\" DESC;\n\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq209",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (\n    SELECT\n        t1.\"publication_number\",\n        t1.\"application_number\"\n    FROM\n        PATENTS.PATENTS.PUBLICATIONS t1\n    WHERE\n        TO_DATE(\n            CASE\n                WHEN t1.\"grant_date\" != 0 THEN TO_CHAR(t1.\"grant_date\")\n                ELSE NULL\n            END, \n            'YYYYMMDD'\n        ) BETWEEN TO_DATE('20100101', 'YYYYMMDD') AND TO_DATE('20101231', 'YYYYMMDD')\n),\nforward_citation AS (\n    SELECT\n        patents_sample.\"publication_number\",\n        COUNT(DISTINCT t3.\"citing_application_number\") AS \"forward_citations\"\n    FROM\n        patents_sample\n        LEFT JOIN (\n            SELECT\n                x2.\"publication_number\",\n                TO_DATE(\n                    CASE\n                        WHEN x2.\"filing_date\" != 0 THEN TO_CHAR(x2.\"filing_date\")\n                        ELSE NULL\n                    END,\n                    'YYYYMMDD'\n                ) AS \"filing_date\"\n            FROM\n                PATENTS.PATENTS.PUBLICATIONS x2\n            WHERE\n                x2.\"filing_date\" != 0\n        ) t2\n            ON t2.\"publication_number\" = patents_sample.\"publication_number\"\n        LEFT JOIN (\n            SELECT\n                x3.\"publication_number\" AS \"citing_publication_number\",\n                x3.\"application_number\" AS \"citing_application_number\",\n                TO_DATE(\n                    CASE\n                        WHEN x3.\"filing_date\" != 0 THEN TO_CHAR(x3.\"filing_date\")\n                        ELSE NULL\n                    END,\n                    'YYYYMMDD'\n                ) AS \"joined_filing_date\",\n                cite.value:\"publication_number\"::STRING AS \"cited_publication_number\"\n            FROM\n                PATENTS.PATENTS.PUBLICATIONS x3,\n                LATERAL FLATTEN(INPUT => x3.\"citation\") cite\n            WHERE\n                x3.\"filing_date\" != 0\n        ) t3\n            ON patents_sample.\"publication_number\" = t3.\"cited_publication_number\"\n            AND t3.\"joined_filing_date\" BETWEEN t2.\"filing_date\" AND DATEADD(YEAR, 10, t2.\"filing_date\")\n    GROUP BY\n        patents_sample.\"publication_number\"\n)\n\nSELECT\n    COUNT(*)\nFROM\n    forward_citation\nWHERE\n    \"forward_citations\" = 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq210",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (\n  SELECT \n    t1.\"publication_number\" AS publication_number,\n    claim.value:\"text\" AS claims_text\n  FROM \n    PATENTS.PATENTS.PUBLICATIONS t1,\n    LATERAL FLATTEN(input => t1.\"claims_localized\") AS claim\n  WHERE \n    t1.\"country_code\" = 'US'\n    AND t1.\"grant_date\" BETWEEN 20080101 AND 20181231\n    AND t1.\"grant_date\" != 0\n    AND t1.\"publication_number\" LIKE '%B2%'\n),\nPublication_data AS (\n  SELECT\n    publication_number,\n    COUNT_IF(claims_text NOT LIKE '%claim%') AS nb_indep_claims\n  FROM\n    patents_sample\n  GROUP BY\n    publication_number\n)\n\nSELECT COUNT(nb_indep_claims)\nFROM Publication_data\nWHERE nb_indep_claims != 0",
        "error_info": null
    },
    {
        "instance_id": "sf_bq213",
        "score": 1,
        "pred_sql": "WITH interim_table as(\nSELECT \n    t1.\"publication_number\", \n    SUBSTR(ipc_u.value:\"code\", 0, 4) as ipc4\nFROM \n    PATENTS.PATENTS.PUBLICATIONS t1,\n    LATERAL FLATTEN(input => t1.\"ipc\") AS ipc_u\nWHERE\n\"country_code\" = 'US'  \nAND \"grant_date\" between 20220601 AND 20220831\n  AND \"grant_date\" != 0\n  AND \"publication_number\" LIKE '%B2%'  \nGROUP BY \n    t1.\"publication_number\", \n    ipc4\n) \nSELECT \nipc4\nFROM \ninterim_table \nGROUP BY ipc4\nORDER BY COUNT(\"publication_number\") DESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "sf_bq216",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (\n    SELECT \n        \"publication_number\", \n        \"application_number\"\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS\n    WHERE\n        \"publication_number\" = 'US-9741766-B2'\n),\nflattened_t5 AS (\n    SELECT\n        t5.\"publication_number\",\n        f.value AS element_value,\n        f.index AS pos\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.ABS_AND_EMB t5,\n        LATERAL FLATTEN(input => t5.\"embedding_v1\") AS f\n),\nflattened_t6 AS (\n    SELECT\n        t6.\"publication_number\",\n        f.value AS element_value,\n        f.index AS pos\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.ABS_AND_EMB t6,\n        LATERAL FLATTEN(input => t6.\"embedding_v1\") AS f\n),\nsimilarities AS (\n    SELECT\n        t1.\"publication_number\" AS base_publication_number,\n        t4.\"publication_number\" AS similar_publication_number,\n        SUM(ft5.element_value * ft6.element_value) AS similarity\n    FROM\n        (SELECT * FROM patents_sample LIMIT 1) t1\n    LEFT JOIN (\n        SELECT \n            x3.\"publication_number\",\n            EXTRACT(YEAR, TO_DATE(CAST(x3.\"filing_date\" AS STRING), 'YYYYMMDD')) AS focal_filing_year\n        FROM \n            PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS x3\n        WHERE \n            x3.\"filing_date\" != 0\n    ) t3 ON t3.\"publication_number\" = t1.\"publication_number\"\n    LEFT JOIN (\n        SELECT \n            x4.\"publication_number\",\n            EXTRACT(YEAR, TO_DATE(CAST(x4.\"filing_date\" AS STRING), 'YYYYMMDD')) AS filing_year\n        FROM \n            PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS x4\n        WHERE \n            x4.\"filing_date\" != 0\n    ) t4 ON\n        t4.\"publication_number\" != t1.\"publication_number\"\n        AND t3.focal_filing_year = t4.filing_year\n    LEFT JOIN flattened_t5 AS ft5 ON ft5.\"publication_number\" = t1.\"publication_number\"\n    LEFT JOIN flattened_t6 AS ft6 ON ft6.\"publication_number\" = t4.\"publication_number\"\n    AND ft5.pos = ft6.pos  -- Align vector positions\n    GROUP BY\n        t1.\"publication_number\", t4.\"publication_number\"\n)\nSELECT\n    s.similar_publication_number,\n    s.similarity\nFROM (\n    SELECT\n        s.*,\n        ROW_NUMBER() OVER (PARTITION BY s.base_publication_number ORDER BY s.similarity DESC) AS seqnum\n    FROM\n        similarities s\n) s\nWHERE\n    seqnum <= 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq219",
        "score": 1,
        "pred_sql": "WITH\nMonthlyTotals AS\n(\n  SELECT\n    TO_CHAR(\"date\", 'YYYY-MM') AS \"month\",\n    SUM(\"volume_sold_gallons\") AS \"total_monthly_volume\"\n  FROM\n    IOWA_LIQUOR_SALES.IOWA_LIQUOR_SALES.\"SALES\"\n  WHERE\n    \"date\" >= '2022-01-01' \n    AND TO_CHAR(\"date\", 'YYYY-MM') < TO_CHAR(CURRENT_DATE(), 'YYYY-MM')\n  GROUP BY\n    TO_CHAR(\"date\", 'YYYY-MM')\n),\n\nMonthCategory AS\n(\n  SELECT\n    TO_CHAR(\"date\", 'YYYY-MM') AS \"month\",\n    \"category\",\n    \"category_name\",\n    SUM(\"volume_sold_gallons\") AS \"category_monthly_volume\",\n    CASE \n      WHEN \"total_monthly_volume\" != 0 THEN (SUM(\"volume_sold_gallons\") / \"total_monthly_volume\") * 100\n      ELSE NULL\n    END AS \"category_pct_of_month_volume\"\n  FROM\n    IOWA_LIQUOR_SALES.IOWA_LIQUOR_SALES.\"SALES\" AS Sales\n  LEFT JOIN\n    MonthlyTotals ON TO_CHAR(Sales.\"date\", 'YYYY-MM') = MonthlyTotals.\"month\"\n  WHERE\n    Sales.\"date\" >= '2022-01-01' \n    AND TO_CHAR(Sales.\"date\", 'YYYY-MM') < TO_CHAR(CURRENT_DATE(), 'YYYY-MM')\n  GROUP BY\n    TO_CHAR(Sales.\"date\", 'YYYY-MM'), \"category\", \"category_name\", \"total_monthly_volume\"\n),\n\nmiddle_info AS \n(\n  SELECT\n    Category1.\"category\" AS \"category1\",\n    Category1.\"category_name\" AS \"category_name1\",\n    Category2.\"category\" AS \"category2\",\n    Category2.\"category_name\" AS \"category_name2\",\n    COUNT(DISTINCT Category1.\"month\") AS \"num_months\",\n    CORR(Category1.\"category_pct_of_month_volume\", Category2.\"category_pct_of_month_volume\") AS \"category_corr_across_months\",\n    AVG(Category1.\"category_pct_of_month_volume\") AS \"category1_avg_pct_of_month_volume\",\n    AVG(Category2.\"category_pct_of_month_volume\") AS \"category2_avg_pct_of_month_volume\"\n  FROM\n    MonthCategory Category1\n  INNER JOIN\n    MonthCategory Category2 \n    ON Category1.\"month\" = Category2.\"month\"\n  GROUP BY\n    Category1.\"category\", Category1.\"category_name\", Category2.\"category\", Category2.\"category_name\"\n  HAVING\n    \"num_months\" >= 24\n    AND \"category1_avg_pct_of_month_volume\" >= 1\n    AND \"category2_avg_pct_of_month_volume\" >= 1\n)\n\nSELECT \n  \"category_name1\", \n  \"category_name2\"\nFROM \n  middle_info\nORDER BY \n  \"category_corr_across_months\"\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq221",
        "score": 1,
        "pred_sql": "WITH patent_cpcs AS (\n    SELECT\n        cd.\"parents\",\n        CAST(FLOOR(\"filing_date\" / 10000) AS INT) AS \"filing_year\"\n    FROM (\n        SELECT\n            MAX(\"cpc\") AS \"cpc\", MAX(\"filing_date\") AS \"filing_date\"\n        FROM\n            PATENTS.PATENTS.PUBLICATIONS\n        WHERE \n            \"application_number\" != ''\n        GROUP BY\n            \"application_number\"\n    ) AS publications\n    , LATERAL FLATTEN(INPUT => \"cpc\") AS cpcs\n    JOIN\n        PATENTS.PATENTS.CPC_DEFINITION cd ON cd.\"symbol\" = cpcs.value:\"code\"\n    WHERE \n        cpcs.value:\"first\" = TRUE\n          AND \"filing_date\" > 0\n\n),\nyearly_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        COUNT(*) AS \"cnt\"\n    FROM (\n        SELECT\n            cpc_parent.value::STRING AS \"cpc_group\",\n            \"filing_year\"\n        FROM patent_cpcs,\n             LATERAL FLATTEN(input => patent_cpcs.\"parents\") AS cpc_parent\n    )\n    GROUP BY \"cpc_group\", \"filing_year\"\n),\nordered_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        ROW_NUMBER() OVER (PARTITION BY \"cpc_group\" ORDER BY \"filing_year\" ASC) AS rn\n    FROM yearly_counts\n),\nrecursive_ema AS (\n    -- Anchor member: first year per cpc_group\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        \"cnt\" * 0.2 + 0 * 0.8 AS \"ema\",\n        rn\n    FROM ordered_counts\n    WHERE rn = 1\n\n    UNION ALL\n\n    -- Recursive member: subsequent years\n    SELECT\n        oc.\"cpc_group\",\n        oc.\"filing_year\",\n        oc.\"cnt\",\n        oc.\"cnt\" * 0.2 + re.\"ema\" * 0.8 AS \"ema\",\n        oc.rn\n    FROM ordered_counts oc\n    JOIN recursive_ema re\n        ON oc.\"cpc_group\" = re.\"cpc_group\"\n       AND oc.rn = re.rn + 1\n),\nmax_ema AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"ema\"\n    FROM recursive_ema\n),\nranked_ema AS (\n    SELECT\n        me.\"cpc_group\",\n        me.\"filing_year\",\n        me.\"ema\",\n        ROW_NUMBER() OVER (\n            PARTITION BY me.\"cpc_group\" \n            ORDER BY me.\"ema\" DESC, me.\"filing_year\" DESC\n        ) AS rn_rank\n    FROM max_ema me\n)\nSELECT \n    c.\"titleFull\",\n    REPLACE(r.\"cpc_group\", '\"', '') AS \"cpc_group\",\n    r.\"filing_year\" AS \"best_filing_year\"\nFROM ranked_ema r\nJOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" c \n    ON r.\"cpc_group\" = c.\"symbol\"\nWHERE \n    c.\"level\" = 5\n    AND r.rn_rank = 1\nORDER BY \n    c.\"titleFull\", \n    \"cpc_group\" ASC;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq222",
        "score": 1,
        "pred_sql": "WITH patent_cpcs AS (\n    SELECT\n        cd.\"parents\",\n        CAST(FLOOR(\"filing_date\" / 10000) AS INT) AS \"filing_year\"\n    FROM (\n        SELECT MAX(\"cpc\") AS \"cpc\", MAX(\"filing_date\") AS \"filing_date\"\n        FROM \"PATENTS\".\"PATENTS\".\"PUBLICATIONS\"\n        WHERE \"application_number\" != ''\n          AND \"country_code\" = 'DE'\n          AND \"grant_date\" >= 20161201\n          AND \"grant_date\" <= 20161231\n        GROUP BY \"application_number\"\n    ), LATERAL FLATTEN(INPUT => \"cpc\") AS cpcs\n    JOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" cd ON cd.\"symbol\" = cpcs.value:\"code\"\n    WHERE cpcs.value:\"first\" = TRUE\n      AND \"filing_date\" > 0\n),\nyearly_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        COUNT(*) AS \"cnt\"\n    FROM (\n        SELECT\n            cpc_parent.VALUE AS \"cpc_group\",  -- Corrected reference to flattened \"parents\"\n            \"filing_year\"\n        FROM patent_cpcs,\n             LATERAL FLATTEN(INPUT => \"parents\") AS cpc_parent  -- Corrected reference to flattened \"parents\"\n    )\n    GROUP BY \"cpc_group\", \"filing_year\"\n),\nmoving_avg AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        AVG(\"cnt\") OVER (PARTITION BY \"cpc_group\" ORDER BY \"filing_year\" ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS \"moving_avg\"\n    FROM yearly_counts\n)\nSELECT \n    c.\"titleFull\",  -- Ensure correct column name (check case)\n    REPLACE(\"cpc_group\", '\"', '') AS \"cpc_group\",\n    MAX(\"filing_year\") AS \"best_filing_year\"\nFROM moving_avg\nJOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" c ON \"cpc_group\" = c.\"symbol\"\nWHERE c.\"level\" = 4\nGROUP BY c.\"titleFull\", \"cpc_group\"\nORDER BY c.\"titleFull\", \"cpc_group\" ASC;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq223",
        "score": 1,
        "pred_sql": "SELECT\n    REPLACE(citing_assignee, '\"', '') AS citing_assignee,\n    cpcdef.\"titleFull\" AS cpc_title,\n    COUNT(*) AS number\nFROM (\n    SELECT\n        pubs.\"publication_number\" AS citing_publication_number,\n        cite.value:\"publication_number\" AS cited_publication_number,\n        citing_assignee_s.value:\"name\" AS citing_assignee,\n        SUBSTR(cpcs.value:\"code\", 1, 4) AS citing_cpc_subclass\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs\n    , LATERAL FLATTEN(input => pubs.\"citation\") AS cite\n    , LATERAL FLATTEN(input => pubs.\"assignee_harmonized\") AS citing_assignee_s\n    , LATERAL FLATTEN(input => pubs.\"cpc\") AS cpcs\n    WHERE\n        cpcs.value:\"first\" = TRUE\n) AS pubs\nJOIN (\n    SELECT\n        \"publication_number\" AS cited_publication_number,\n        cited_assignee_s.value:\"name\" AS cited_assignee\n    FROM\n        PATENTS.PATENTS.PUBLICATIONS\n    , LATERAL FLATTEN(input => \"assignee_harmonized\") AS cited_assignee_s\n) AS refs\n    ON pubs.cited_publication_number = refs.cited_publication_number\nJOIN\n    PATENTS.PATENTS.CPC_DEFINITION AS cpcdef\n    ON cpcdef.\"symbol\" = pubs.citing_cpc_subclass\nWHERE\n    refs.cited_assignee = 'DENSO CORP'\n    AND pubs.citing_assignee != 'DENSO CORP'\nGROUP BY\n    citing_assignee, cpcdef.\"titleFull\"\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq224",
        "score": 1,
        "pred_sql": "WITH allowed_repos AS (\n    SELECT \n        \"repo_name\",\n        \"license\"\n    FROM \n        GITHUB_REPOS_DATE.GITHUB_REPOS.LICENSES\n    WHERE \n        \"license\" IN (\n            'gpl-3.0', 'artistic-2.0', 'isc', 'cc0-1.0', 'epl-1.0', 'gpl-2.0',\n            'mpl-2.0', 'lgpl-2.1', 'bsd-2-clause', 'apache-2.0', 'mit', 'lgpl-3.0'\n        )\n),\nwatch_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(DISTINCT TRY_PARSE_JSON(\"actor\"):\"login\"::STRING) AS \"watches\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'WatchEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n),\nissue_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(*) AS \"issue_events\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'IssuesEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n),\nfork_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(*) AS \"forks\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'ForkEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n)\nSELECT \n    ar.\"repo_name\"\nFROM \n    allowed_repos AS ar\nINNER JOIN \n    fork_counts AS fc ON ar.\"repo_name\" = fc.\"repo\"\nINNER JOIN \n    issue_counts AS ic ON ar.\"repo_name\" = ic.\"repo\"\nINNER JOIN \n    watch_counts AS wc ON ar.\"repo_name\" = wc.\"repo\"\nORDER BY \n    (fc.\"forks\" + ic.\"issue_events\" + wc.\"watches\") DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq233",
        "score": 1,
        "pred_sql": "WITH extracted_modules AS (\nSELECT \n    el.\"file_id\" AS \"file_id\", \n    el.\"repo_name\", \n    el.\"path\" AS \"path_\", \n    REPLACE(line.value, '\"', '') AS \"line_\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN 'python'\n        WHEN ENDSWITH(el.\"path\", '.r') THEN 'r'\n        ELSE NULL\n    END AS \"language\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN\n            ARRAY_CAT(\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bimport\\\\s+(\\\\w+)', 1, 1, 'e')),\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bfrom\\\\s+(\\\\w+)', 1, 1, 'e'))\n            )\n        WHEN ENDSWITH(el.\"path\", '.r') THEN\n            ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, 'library\\\\s*\\\\(\\\\s*([^\\\\s)]+)\\\\s*\\\\)', 1, 1, 'e'))\n        ELSE ARRAY_CONSTRUCT()\n    END AS \"modules\"\nFROM (\n    SELECT\n        ct.\"id\" AS \"file_id\", \n        fl.\"repo_name\" AS \"repo_name\", \n        fl.\"path\", \n        SPLIT(REPLACE(ct.\"content\", '\\n', ' \\n'), '\\n') AS \"lines\"\n    FROM \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS fl\n    JOIN \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS ct \n        ON fl.\"id\" = ct.\"id\"\n) AS el,\nLATERAL FLATTEN(input => el.\"lines\") AS line \nWHERE\n    (\n        ENDSWITH(\"path_\", '.py') \n        AND \n        (\n            \"line_\" LIKE 'import %' \n            OR \n            \"line_\" LIKE 'from %'\n        )\n    )\n    OR\n    (\n        ENDSWITH(\"path_\", '.r') \n        AND \n        \"line_\" LIKE 'library%('\n    )\n\n),\nmodule_counts AS (\n    SELECT \n        em.\"language\",\n        f.value::STRING AS \"module\",\n        COUNT(*) AS \"occurrence_count\"\n    FROM \n        extracted_modules AS em,\n        LATERAL FLATTEN(input => em.\"modules\") AS f\n    WHERE \n        em.\"modules\" IS NOT NULL\n        AND f.value IS NOT NULL\n    GROUP BY \n        em.\"language\", \n        f.value\n),\npython AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts\n    WHERE \n        \"language\" = 'python'\n),\nrlanguage AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts AS mc_inner\n    WHERE \n        \"language\" = 'r'\n)\nSELECT \n    *\nFROM \n    python\nUNION ALL\nSELECT \n    *\nFROM \n    rlanguage\nORDER BY \n    \"language\", \n    \"occurrence_count\" DESC;",
        "error_info": null
    },
    {
        "instance_id": "sf_bq236",
        "score": 1,
        "pred_sql": "SELECT\n  CONCAT(\"city\", ', ', \"state_name\") AS \"city\",\n  \"zip_code\",\n  COUNT(\"event_id\") AS \"count_storms\"\nFROM (\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2014\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2015\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2016\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2017\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2018\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2019\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2020\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2021\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2022\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2023\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2024\n) AS storms\nJOIN NOAA_DATA_PLUS.GEO_US_BOUNDARIES.ZIP_CODES\n  ON ST_WITHIN(ST_GEOGFROMWKB(storms.\"event_point\"), ST_GEOGFROMWKB(\"zip_code_geom\"))\nWHERE\n   LOWER(storms.\"event_type\") = 'hail'\nGROUP BY\n  \"zip_code\", \n  \"city\", \n  \"state_name\"\nORDER BY\n  \"count_storms\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq246",
        "score": 1,
        "pred_sql": "SELECT filterData.\"fwrdCitations_3\"\nFROM\n  PATENTSVIEW.PATENTSVIEW.APPLICATION AS app\nJOIN (\n  SELECT DISTINCT \n    cpc.\"patent_id\", \n    IFNULL(citation_3.\"bkwdCitations_3\", 0) AS \"bkwdCitations_3\", \n    IFNULL(citation_3.\"fwrdCitations_3\", 0) AS \"fwrdCitations_3\"\n  FROM\n    PATENTSVIEW.PATENTSVIEW.CPC_CURRENT AS cpc\n  LEFT JOIN (\n    SELECT \n      b.\"patent_id\", \n      b.\"bkwdCitations_3\", \n      f.\"fwrdCitations_3\"\n    FROM \n      (SELECT \n         cited.\"patent_id\",\n         COUNT(*) AS \"fwrdCitations_3\"\n       FROM \n         PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n       JOIN\n         PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n         ON cited.\"patent_id\" = apps.\"patent_id\"\n       WHERE\n         apps.\"country\" = 'US'\n         AND cited.\"date\" >= apps.\"date\"\n         AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(YEAR, 1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 year\n       GROUP BY \n         cited.\"patent_id\"\n      ) AS f\n    JOIN (\n      SELECT \n        cited.\"patent_id\",\n        COUNT(*) AS \"bkwdCitations_3\"\n      FROM \n        PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n      JOIN\n        PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n        ON cited.\"patent_id\" = apps.\"patent_id\"\n      WHERE\n        apps.\"country\" = 'US'\n        AND cited.\"date\" < apps.\"date\"\n        AND TRY_CAST(cited.\"date\" AS DATE) >= DATEADD(YEAR, -1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 year before\n      GROUP BY \n        cited.\"patent_id\"\n    ) AS b\n    ON b.\"patent_id\" = f.\"patent_id\"\n    WHERE \n      b.\"bkwdCitations_3\" IS NOT NULL\n      AND f.\"fwrdCitations_3\" IS NOT NULL\n  ) AS citation_3 \n  ON cpc.\"patent_id\" = citation_3.\"patent_id\"\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nORDER BY filterData.\"bkwdCitations_3\" DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq248",
        "score": 1,
        "pred_sql": "WITH requests AS (\n    SELECT \n        D.\"id\",\n        D.\"content\",\n        E.\"repo_name\",\n        E.\"path\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS\n            GROUP BY \n                \"id\", \"content\"\n        ) AS D\n    INNER JOIN \n        (\n            SELECT \n                C.\"id\",\n                C.\"repo_name\",\n                C.\"path\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                    GROUP BY \n                        \"path\", \"id\", \"repo_name\"\n                ) AS C\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        language_struct.value:\"name\"::STRING AS \"language_name\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.LANGUAGES,\n                        LATERAL FLATTEN(input => \"language\") AS language_struct\n                    WHERE \n                        LOWER(language_struct.value:\"name\"::STRING) NOT LIKE '%python%'\n                    GROUP BY \n                        \"language_name\", \"repo_name\"\n                ) AS F\n            ON \n                C.\"repo_name\" = F.\"repo_name\"\n        ) AS E\n    ON \n        D.\"id\" = E.\"id\"\n)\nSELECT \n    (SELECT COUNT(*) FROM requests WHERE \"content\" LIKE '%Copyright (c)%') / COUNT(*) AS \"proportion\"\nFROM \n    requests;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq250",
        "score": 1,
        "pred_sql": "WITH country_name AS (\n  SELECT 'Singapore' AS value\n),\n\nlast_updated AS (\n  SELECT\n    MAX(\"last_updated\") AS value\n  FROM GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON (pop.\"country_name\" = country_name.value)\n  WHERE \"last_updated\" < '2023-01-01'\n),\n\naggregated_population AS (\n  SELECT\n    \"geo_id\",\n    SUM(\"population\") AS sum_population,\n    ST_POINT(\"longitude_centroid\", \"latitude_centroid\") AS centr  -- \u8ba1\u7b97\u6bcf\u4e2a geo_id \u7684\u4e2d\u5fc3\u70b9\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON (pop.\"country_name\" = country_name.value)\n    INNER JOIN last_updated ON (pop.\"last_updated\" = last_updated.value)\n  GROUP BY \"geo_id\", \"longitude_centroid\", \"latitude_centroid\"\n),\n\npopulation AS (\n  SELECT\n    SUM(sum_population) AS sum_population,\n    ST_ENVELOPE(ST_UNION_AGG(centr)) AS boundingbox  -- \u4f7f\u7528 ST_ENVELOPE \u6765\u4ee3\u66ff ST_CONVEXHULL\n  FROM aggregated_population\n),\n\nhospitals AS (\n  SELECT\n    layer.\"geometry\"\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.GEO_OPENSTREETMAP.PLANET_LAYERS AS layer\n    INNER JOIN population ON ST_INTERSECTS(population.boundingbox, ST_GEOGFROMWKB(layer.\"geometry\"))\n  WHERE\n    layer.\"layer_code\" IN (2110, 2120)\n),\n\ndistances AS (\n  SELECT\n    pop.\"geo_id\",\n    pop.\"population\",\n    MIN(ST_DISTANCE(ST_GEOGFROMWKB(pop.\"geog\"), ST_GEOGFROMWKB(hospitals.\"geometry\"))) AS distance\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON pop.\"country_name\" = country_name.value\n    INNER JOIN last_updated ON pop.\"last_updated\" = last_updated.value\n    CROSS JOIN hospitals\n  WHERE pop.\"population\" > 0\n  GROUP BY \"geo_id\", \"population\"\n)\n\nSELECT\n  SUM(pd.\"population\") AS population\nFROM\n  distances pd\nCROSS JOIN population p\nGROUP BY distance\nORDER BY distance DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq252",
        "score": 1,
        "pred_sql": "WITH selected_repos AS (\n  SELECT\n    f.\"id\",\n    f.\"repo_name\" AS \"repo_name\",\n    f.\"path\" AS \"path\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES AS f\n),\ndeduped_files AS (\n  SELECT\n    f.\"id\",\n    MIN(f.\"repo_name\") AS \"repo_name\",\n    MIN(f.\"path\") AS \"path\"\n  FROM\n    selected_repos AS f\n  GROUP BY\n    f.\"id\"\n)\nSELECT\n  f.\"repo_name\"\nFROM\n  deduped_files AS f\n  JOIN GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS AS c \n  ON f.\"id\" = c.\"id\"\nWHERE\n  NOT c.\"binary\"\n  AND f.\"path\" LIKE '%.swift'\nORDER BY c.\"copies\" DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq254",
        "score": 1,
        "pred_sql": "WITH bounding_area AS (\n    SELECT \"geometry\" AS geometry\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => \"all_tags\") AS tag\n    WHERE \"feature_type\" = 'multipolygons'\n      AND tag.value:\"key\" = 'wikidata'\n      AND tag.value:\"value\" = 'Q191'\n),\nbounding_area_features AS (\n    SELECT \n        planet_features.\"osm_id\", \n        planet_features.\"feature_type\", \n        planet_features.\"geometry\", \n        planet_features.\"all_tags\"\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES AS planet_features,\n         bounding_area\n    WHERE ST_DWITHIN(\n        ST_GEOGFROMWKB(planet_features.\"geometry\"), \n        ST_GEOGFROMWKB(bounding_area.geometry), \n        0.0\n    )\n),\nosm_id_with_wikidata AS (\n    SELECT DISTINCT\n        baf.\"osm_id\"\n    FROM bounding_area_features AS baf,\n         LATERAL FLATTEN(INPUT => baf.\"all_tags\") AS tag\n    WHERE tag.value:\"key\" = 'wikidata'\n),\n\npolygons_wo_wikidata AS (\n    SELECT \n        baf.\"osm_id\",\n        tag.value:\"value\" as name,\n        baf.\"geometry\" as geometry\n    FROM bounding_area_features AS baf\n    LEFT JOIN osm_id_with_wikidata AS wd\n      ON baf.\"osm_id\" = wd.\"osm_id\",\n    LATERAL FLATTEN(INPUT => \"all_tags\") AS tag\n    WHERE wd.\"osm_id\" IS NULL\n    AND baf.\"osm_id\" IS NOT NULL\n    AND baf.\"feature_type\" = 'multipolygons'\n    AND tag.value:\"key\" = 'name'\n)\n\nSELECT \n    TRIM(pww.name) as name\nFROM bounding_area_features AS baf\nJOIN polygons_wo_wikidata AS pww\n    ON ST_DWITHIN(\n        ST_GEOGFROMWKB(baf.\"geometry\"), \n        ST_GEOGFROMWKB(pww.geometry), \n        0.0\n    )\nLEFT JOIN osm_id_with_wikidata AS wd\n    ON baf.\"osm_id\" = wd.\"osm_id\"\nWHERE wd.\"osm_id\" IS NOT NULL\n  AND baf.\"feature_type\" = 'points'\nGROUP BY pww.name\nORDER BY COUNT(baf.\"osm_id\") DESC\nLIMIT 2\n\n\n\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq255",
        "score": 1,
        "pred_sql": "SELECT\n  COUNT(commits_table.\"message\") AS \"num_messages\"\nFROM (\n  SELECT\n    L.\"repo_name\",\n    language_struct.value:\"name\"::STRING AS \"language_name\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.LANGUAGES AS L,\n    LATERAL FLATTEN(input => L.\"language\") AS language_struct\n) AS lang_table\nJOIN \n  GITHUB_REPOS.GITHUB_REPOS.LICENSES AS license_table\nON \n  license_table.\"repo_name\" = lang_table.\"repo_name\"\nJOIN (\n  SELECT\n    *\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS\n) AS commits_table\nON \n  commits_table.\"repo_name\" = lang_table.\"repo_name\"\nWHERE\n  license_table.\"license\" LIKE 'apache-2.0'\n  AND lang_table.\"language_name\" LIKE 'Shell'\n  AND LENGTH(commits_table.\"message\") > 5\n  AND LENGTH(commits_table.\"message\") < 10000\n  AND LOWER(commits_table.\"message\") NOT LIKE 'update%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'test%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'merge%';\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq260",
        "score": 1,
        "pred_sql": "WITH filtered_users AS (\n    SELECT \n        \"first_name\", \n        \"last_name\", \n        \"gender\", \n        \"age\",\n        CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) AS \"created_at\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) BETWEEN '2019-01-01' AND '2022-04-30'\n),\nyoungest_ages AS (\n    SELECT \n        \"gender\", \n        MIN(\"age\") AS \"age\"\n    FROM \n        filtered_users\n    GROUP BY \n        \"gender\"\n),\noldest_ages AS (\n    SELECT \n        \"gender\", \n        MAX(\"age\") AS \"age\"\n    FROM \n        filtered_users\n    GROUP BY \n        \"gender\"\n),\nyoungest_oldest AS (\n    SELECT \n        u.\"first_name\", \n        u.\"last_name\", \n        u.\"gender\", \n        u.\"age\", \n        'youngest' AS \"tag\"\n    FROM \n        filtered_users u\n    JOIN \n        youngest_ages y\n    ON \n        u.\"gender\" = y.\"gender\" AND u.\"age\" = y.\"age\"\n    \n    UNION ALL\n    \n    SELECT \n        u.\"first_name\", \n        u.\"last_name\", \n        u.\"gender\", \n        u.\"age\", \n        'oldest' AS \"tag\"\n    FROM \n        filtered_users u\n    JOIN \n        oldest_ages o\n    ON \n        u.\"gender\" = o.\"gender\" AND u.\"age\" = o.\"age\"\n)\nSELECT \n    \"tag\", \n    \"gender\", \n    COUNT(*) AS \"num\"\nFROM \n    youngest_oldest\nGROUP BY \n    \"tag\", \"gender\"\nORDER BY \n    \"tag\", \"gender\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq263",
        "score": 1,
        "pred_sql": "WITH d AS (\n    SELECT\n        a.\"order_id\", \n        TO_CHAR(TO_TIMESTAMP(a.\"created_at\" / 1000000.0), 'YYYY-MM') AS \"month\",  -- \u683c\u5f0f\u5316\u4e3a\u5e74\u6708\n        TO_CHAR(TO_TIMESTAMP(a.\"created_at\" / 1000000.0), 'YYYY') AS \"year\",  -- \u683c\u5f0f\u5316\u4e3a\u5e74\u4efd\n        b.\"product_id\", b.\"sale_price\", c.\"category\", c.\"cost\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\" AS a\n    JOIN \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\" AS b\n        ON a.\"order_id\" = b.\"order_id\"\n    JOIN \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"PRODUCTS\" AS c\n        ON b.\"product_id\" = c.\"id\"\n    WHERE \n        a.\"status\" = 'Complete'\n        AND TO_TIMESTAMP(a.\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2023-01-01') AND TO_TIMESTAMP('2023-12-31')\n        AND c.\"category\" = 'Sleep & Lounge'\n),\n\ne AS (\n    SELECT \n        \"month\", \n        \"year\", \n        \"sale_price\", \n        \"category\", \n        \"cost\",\n        SUM(\"sale_price\") OVER (PARTITION BY \"month\", \"category\") AS \"TPV\",\n        SUM(\"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"total_cost\",\n        COUNT(DISTINCT \"order_id\") OVER (PARTITION BY \"month\", \"category\") AS \"TPO\",\n        SUM(\"sale_price\" - \"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"total_profit\",\n        SUM((\"sale_price\" - \"cost\") / \"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"Profit_to_cost_ratio\"\n    FROM \n        d\n)\n\nSELECT DISTINCT \n    \"month\", \n    \"category\", \n    \"TPV\", \n    \"total_cost\", \n    \"TPO\", \n    \"total_profit\", \n    \"Profit_to_cost_ratio\"\nFROM \n    e\nORDER BY \n    \"month\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq264",
        "score": 1,
        "pred_sql": "WITH youngest AS (\n    SELECT\n        \"gender\", \n        \"id\", \n        \"first_name\", \n        \"last_name\", \n        \"age\", \n        'youngest' AS \"tag\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        \"age\" = (SELECT MIN(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\")\n        AND TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2022-04-30')\n    GROUP BY \n        \"gender\", \"id\", \"first_name\", \"last_name\", \"age\"\n    ORDER BY \n        \"gender\"\n),\n\noldest AS (\n    SELECT\n        \"gender\", \n        \"id\", \n        \"first_name\", \n        \"last_name\", \n        \"age\", \n        'oldest' AS \"tag\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        \"age\" = (SELECT MAX(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\")\n        AND TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2022-04-30')\n    GROUP BY \n        \"gender\", \"id\", \"first_name\", \"last_name\", \"age\"\n    ORDER BY \n        \"gender\"\n),\n\nTEMP_record AS (\n    SELECT * FROM youngest\n    UNION ALL\n    SELECT * FROM oldest\n)\n\nSELECT \n    SUM(CASE WHEN \"age\" = (SELECT MAX(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\") THEN 1 END) - \n    SUM(CASE WHEN \"age\" = (SELECT MIN(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\") THEN 1 END) AS \"diff\"\nFROM \n    TEMP_record;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq265",
        "score": 1,
        "pred_sql": "WITH\n  main AS (\n    SELECT\n      \"id\" AS \"user_id\",\n      \"email\",\n      \"gender\",\n      \"country\",\n      \"traffic_source\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  daate AS (\n    SELECT\n      \"user_id\",\n      \"order_id\",\n      CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) AS \"order_date\",\n      \"num_of_item\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  orders AS (\n    SELECT\n      \"user_id\",\n      \"order_id\",\n      \"product_id\",\n      \"sale_price\",\n      \"status\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  nest AS (\n    SELECT\n      o.\"user_id\",\n      o.\"order_id\",\n      o.\"product_id\",\n      d.\"order_date\",\n      d.\"num_of_item\",\n      ROUND(o.\"sale_price\", 2) AS \"sale_price\",\n      ROUND(d.\"num_of_item\" * o.\"sale_price\", 2) AS \"total_sale\"\n    FROM\n      orders o\n    INNER JOIN\n      daate d\n    ON\n      o.\"order_id\" = d.\"order_id\"\n    ORDER BY\n      o.\"user_id\"\n  ),\n\n  type AS (\n    SELECT\n      \"user_id\",\n      MIN(nest.\"order_date\") AS \"cohort_date\",\n      MAX(nest.\"order_date\") AS \"latest_shopping_date\",\n      DATEDIFF(MONTH, MIN(nest.\"order_date\"), MAX(nest.\"order_date\")) AS \"lifespan_months\",\n      ROUND(SUM(\"total_sale\"), 2) AS \"ltv\",\n      COUNT(\"order_id\") AS \"no_of_order\"\n    FROM\n      nest\n    GROUP BY\n      \"user_id\"\n  ),\n\n  kite AS (\n    SELECT\n      m.\"user_id\",\n      m.\"email\",\n      m.\"gender\",\n      m.\"country\",\n      m.\"traffic_source\",\n      EXTRACT(YEAR FROM n.\"cohort_date\") AS \"cohort_year\",\n      n.\"latest_shopping_date\",\n      n.\"lifespan_months\",\n      n.\"ltv\",\n      n.\"no_of_order\",\n      ROUND(n.\"ltv\" / n.\"no_of_order\", 2) AS \"avg_order_value\"\n    FROM\n      main m\n    INNER JOIN\n      type n\n    ON\n      m.\"user_id\" = n.\"user_id\"\n  )\n\nSELECT\n  \"email\"\nFROM\n  kite\nORDER BY\n  \"avg_order_value\" DESC\nLIMIT 10;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq271",
        "score": 1,
        "pred_sql": "WITH\norders_x_order_items AS (\n  SELECT orders.*,\n         order_items.\"inventory_item_id\",\n         order_items.\"sale_price\"\n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\" AS orders\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\" AS order_items\n  ON orders.\"order_id\" = order_items.\"order_id\"\n  WHERE TO_TIMESTAMP_NTZ(orders.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n),\n\norders_x_inventory AS (\n  SELECT orders_x_order_items.*,\n         inventory_items.\"product_category\",\n         inventory_items.\"product_department\",\n         inventory_items.\"product_retail_price\",\n         inventory_items.\"product_distribution_center_id\",\n         inventory_items.\"cost\",\n         distribution_centers.\"name\"\n  FROM orders_x_order_items\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"INVENTORY_ITEMS\" AS inventory_items\n  ON orders_x_order_items.\"inventory_item_id\" = inventory_items.\"id\"\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"DISTRIBUTION_CENTERS\" AS distribution_centers\n  ON inventory_items.\"product_distribution_center_id\" = distribution_centers.\"id\"\n  WHERE TO_TIMESTAMP_NTZ(inventory_items.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n),\n\norders_x_users AS (\n  SELECT orders_x_inventory.*,\n         users.\"country\" AS \"users_country\"\n  FROM orders_x_inventory\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\" AS users\n  ON orders_x_inventory.\"user_id\" = users.\"id\"\n  WHERE TO_TIMESTAMP_NTZ(users.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n)\n\nSELECT \n  DATE_TRUNC('MONTH', TO_DATE(TO_TIMESTAMP_NTZ(orders_x_users.\"created_at\" / 1000000))) AS \"reporting_month\",\n  orders_x_users.\"users_country\",\n  orders_x_users.\"product_department\",\n  orders_x_users.\"product_category\",\n  COUNT(DISTINCT orders_x_users.\"order_id\") AS \"n_order\",\n  COUNT(DISTINCT orders_x_users.\"user_id\") AS \"n_purchasers\",\n  SUM(orders_x_users.\"product_retail_price\") - SUM(orders_x_users.\"cost\") AS \"profit\"\nFROM orders_x_users\nGROUP BY 1, 2, 3, 4\nORDER BY \"reporting_month\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq273",
        "score": 1,
        "pred_sql": "WITH \norders AS (\n  SELECT\n    \"order_id\", \n    \"user_id\", \n    \"created_at\",\n    DATE_TRUNC('MONTH', TO_TIMESTAMP_NTZ(\"delivered_at\" / 1000000)) AS \"delivery_month\",  -- Converting to timestamp\n    \"status\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\"\n),\n\norder_items AS (\n  SELECT \n    \"order_id\", \n    \"product_id\", \n    \"sale_price\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\"\n),\n\nproducts AS (\n  SELECT \n    \"id\", \n    \"cost\"\n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"PRODUCTS\"\n),\n\nusers AS (\n  SELECT\n    \"id\", \n    \"traffic_source\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n),\n\nfilter_join AS (\n  SELECT \n    orders.\"order_id\",\n    orders.\"user_id\",\n    order_items.\"product_id\",\n    orders.\"delivery_month\",\n    orders.\"status\",\n    order_items.\"sale_price\",\n    products.\"cost\",\n    users.\"traffic_source\"\n  FROM orders\n  JOIN order_items ON orders.\"order_id\" = order_items.\"order_id\"\n  JOIN products ON order_items.\"product_id\" = products.\"id\"\n  JOIN users ON orders.\"user_id\" = users.\"id\"\n  WHERE orders.\"status\" = 'Complete' \n    AND users.\"traffic_source\" = 'Facebook'\n    AND TO_TIMESTAMP_NTZ(orders.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2022-07-01') AND TO_TIMESTAMP_NTZ('2023-11-30')  -- Include July for calculation\n),\n\nmonthly_sales AS (\n  SELECT \n    \"delivery_month\",\n    \"traffic_source\",\n    SUM(\"sale_price\") AS \"total_revenue\",\n    SUM(\"sale_price\") - SUM(\"cost\") AS \"total_profit\",\n    COUNT(DISTINCT \"product_id\") AS \"product_quantity\",\n    COUNT(DISTINCT \"order_id\") AS \"orders_quantity\",\n    COUNT(DISTINCT \"user_id\") AS \"users_quantity\"\n  FROM filter_join\n  GROUP BY \"delivery_month\", \"traffic_source\"\n)\n\n-- Filter to show only 8th month and onwards, but calculate using July\nSELECT \n  current_month.\"delivery_month\",\n  COALESCE(\n    current_month.\"total_profit\" - previous_month.\"total_profit\", \n    0  -- If there is no previous month (i.e. for 8\u6708), return 0\n  ) AS \"profit_vs_prior_month\"\nFROM monthly_sales AS current_month\nLEFT JOIN monthly_sales AS previous_month\n  ON current_month.\"traffic_source\" = previous_month.\"traffic_source\"\n  AND current_month.\"delivery_month\" = DATEADD(MONTH, -1, previous_month.\"delivery_month\")  -- Correctly join to previous month\nWHERE current_month.\"delivery_month\" >= '2022-08-01'  -- Only show August and later data, but use July for calculation\nORDER BY \"profit_vs_prior_month\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq289",
        "score": 1,
        "pred_sql": "WITH philadelphia AS (\n    SELECT \n        * \n    FROM \n        GEO_OPENSTREETMAP_CENSUS_PLACES.GEO_US_CENSUS_PLACES.PLACES_PENNSYLVANIA\n    WHERE \n        \"place_name\" = 'Philadelphia'\n),\namenities AS (\n    SELECT \n        features.*, \n        tags.value:\"value\" AS amenity\n    FROM \n        GEO_OPENSTREETMAP_CENSUS_PLACES.GEO_OPENSTREETMAP.PLANET_FEATURES_POINTS AS features\n    CROSS JOIN philadelphia\n    -- Use FLATTEN on \"all_tags\" to get the tags and filter by \"key\"\n    , LATERAL FLATTEN(input => features.\"all_tags\") AS tags\n    WHERE \n        ST_CONTAINS(ST_GEOGFROMWKB(philadelphia.\"place_geom\"), ST_GEOGFROMWKB(features.\"geometry\"))\n    AND \n        tags.value:\"key\" = 'amenity' \n    AND \n        tags.value:\"value\" IN ('library', 'place_of_worship', 'community_centre')\n),\njoiin AS (\n    SELECT \n        a1.*, \n        a2.\"osm_id\" AS nearest_osm_id, \n        ST_DISTANCE(ST_GEOGFROMWKB(a1.\"geometry\"), ST_GEOGFROMWKB(a2.\"geometry\")) AS distance, \n        ROW_NUMBER() OVER (PARTITION BY a1.\"osm_id\" ORDER BY ST_DISTANCE(ST_GEOGFROMWKB(a1.\"geometry\"), ST_GEOGFROMWKB(a2.\"geometry\"))) AS row_num\n    FROM amenities a1\n    CROSS JOIN amenities a2\n    WHERE a1.\"osm_id\" < a2.\"osm_id\"\n    ORDER BY a1.\"osm_id\", distance\n) \nSELECT distance\nFROM joiin  \nWHERE row_num = 1\nORDER BY distance ASC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq291",
        "score": 1,
        "pred_sql": "WITH daily_forecasts AS (\n    SELECT\n        \"TRI\".\"creation_time\",\n\n        CAST(DATEADD(hour, 1, TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000)) AS DATE) AS \"local_forecast_date\",\n        MAX(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"max_temp\",\n        MIN(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"min_temp\",\n        AVG(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"avg_temp\",\n        SUM(\n            CASE \n                WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                THEN \"forecast\".value:\"total_precipitation_surface\" \n                ELSE 0 \n            END\n        ) AS \"total_precipitation\",\n        AVG(\n            CASE \n                WHEN CAST(DATEADD(hour, 1, TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000)    ) AS TIME) BETWEEN '10:00:00' AND '17:00:00'\n                     AND \"forecast\".value:\"total_cloud_cover_entire_atmosphere\" IS NOT NULL \n                THEN \"forecast\".value:\"total_cloud_cover_entire_atmosphere\" \n                ELSE NULL \n            END\n        ) AS \"avg_cloud_cover\",\n        CASE\n            WHEN AVG(\"forecast\".value:\"temperature_2m_above_ground\") < 32 THEN \n                SUM(\n                    CASE \n                        WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                        THEN \"forecast\".value:\"total_precipitation_surface\" \n                        ELSE 0 \n                    END\n                )\n            ELSE 0\n        END AS \"total_snow\",\n        CASE\n            WHEN AVG(\"forecast\".value:\"temperature_2m_above_ground\") >= 32 THEN \n                SUM(\n                    CASE \n                        WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                        THEN \"forecast\".value:\"total_precipitation_surface\" \n                        ELSE 0 \n                    END\n                )\n            ELSE 0\n        END AS \"total_rain\"\n    FROM\n        \"NOAA_GLOBAL_FORECAST_SYSTEM\".\"NOAA_GLOBAL_FORECAST_SYSTEM\".\"NOAA_GFS0P25\" AS \"TRI\"\n    CROSS JOIN LATERAL FLATTEN(input => \"TRI\".\"forecast\") AS \"forecast\"\n    WHERE\n        TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"creation_time\") / 1000000) BETWEEN '2019-07-01' AND '2021-07-31'  \n        AND ST_DWITHIN(\n            ST_GEOGFROMWKB(\"TRI\".\"geography\"),\n            ST_POINT(26.75, 51.5),\n            5000\n        )\n        AND CAST(TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000) AS DATE) = DATEADD(day, 1, CAST( TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"creation_time\") / 1000000) AS DATE))\n    GROUP BY\n        \"TRI\".\"creation_time\",\n        \"local_forecast_date\"\n)\n\nSELECT\n    TO_TIMESTAMP_NTZ(TO_NUMBER(\"creation_time\") / 1000000),\n    \"local_forecast_date\" AS \"forecast_date\",\n    \"max_temp\",\n    \"min_temp\",\n    \"avg_temp\",\n    \"total_precipitation\",\n    \"avg_cloud_cover\",\n    \"total_snow\",\n    \"total_rain\"\nFROM\n    daily_forecasts\nORDER BY\n    \"creation_time\",\n    \"forecast_date\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq294",
        "score": 1,
        "pred_sql": "SELECT\n  \"trip_id\",\n  \"duration_sec\",\n  DATE(TO_TIMESTAMP_LTZ(\"start_date\" / 1000000)) AS \"star_date\", -- \u5c06\u5fae\u79d2\u8f6c\u6362\u4e3a\u65e5\u671f\n  \"start_station_name\",\n  CONCAT(\"start_station_name\", ' - ', \"end_station_name\") AS \"route\",\n  \"bike_number\",\n  \"subscriber_type\",\n  \"member_birth_year\",\n  (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") AS \"age\",\n  CASE\n    WHEN (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") < 40 THEN 'Young (<40 Y.O)'\n    WHEN (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") BETWEEN 40 AND 60 THEN 'Adult (40-60 Y.O)'\n    ELSE 'Senior Adult (>60 Y.O)'\n  END AS \"age_class\",\n  \"member_gender\",\n  c.\"name\" AS \"region_name\"\nFROM \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_TRIPS\" a\nLEFT JOIN \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_STATION_INFO\" b \n  ON a.\"start_station_name\" = b.\"name\"\nLEFT JOIN \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_REGIONS\" c \n  ON b.\"region_id\" = c.\"region_id\"\nWHERE TO_TIMESTAMP_LTZ(\"start_date\" / 1000000) BETWEEN '2017-07-01' AND '2017-12-31'\n  AND b.\"name\" IS NOT NULL\n  AND \"member_birth_year\" IS NOT NULL\n  AND \"member_gender\" IS NOT NULL\nORDER BY \"duration_sec\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq295",
        "score": 1,
        "pred_sql": "WITH watched_repos AS (\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201701\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201702\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201703\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201704\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201705\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201706\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201707\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201708\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201709\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201710\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201711\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201712\n    WHERE\n        \"type\" = 'WatchEvent'\n),\n\nrepo_watch_counts AS (\n    SELECT\n        \"repo\",\n        COUNT(*) AS \"watch_count\"\n    FROM\n        watched_repos\n    GROUP BY\n        \"repo\"\n)\n\nSELECT\n    REPLACE(r.\"repo\", '\"', '') AS \"repo\",\n    r.\"watch_count\"\nFROM\n    GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS f\nJOIN\n    GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS c\n    ON f.\"id\" = c.\"id\"\nJOIN \n    repo_watch_counts AS r\n    ON f.\"repo_name\" = r.\"repo\"\nWHERE\n    f.\"path\" LIKE '%.py' \n    AND c.\"size\" < 15000 \n    AND POSITION('def ' IN c.\"content\") > 0\nGROUP BY\n    r.\"repo\", r.\"watch_count\"\nORDER BY\n    r.\"watch_count\" DESC\nLIMIT \n    3;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq320",
        "score": 1,
        "pred_sql": "SELECT\n  COUNT(*) AS \"total_count\"\nFROM\n  IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\nWHERE\n  \"StudyInstanceUID\" IN (\n    SELECT\n      \"StudyInstanceUID\"\n    FROM\n      IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n    WHERE\n      \"StudyInstanceUID\" IN (\n        SELECT\n          \"StudyInstanceUID\"\n        FROM\n          IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n        WHERE\n          LOWER(\"dicom_pivot\".\"SegmentedPropertyTypeCodeSequence\") LIKE LOWER('15825003')\n        GROUP BY\n          \"StudyInstanceUID\"\n        INTERSECT\n        SELECT\n          \"StudyInstanceUID\"\n        FROM\n          IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n        WHERE\n          \"dicom_pivot\".\"collection_id\" IN ('Community', 'nsclc_radiomics')\n        GROUP BY\n          \"StudyInstanceUID\"\n      )\n    GROUP BY\n      \"StudyInstanceUID\"\n  );\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq321",
        "score": 1,
        "pred_sql": "WITH relevant_series AS (\n  SELECT \n    DISTINCT \"StudyInstanceUID\"\n  FROM \n    IDC.IDC_V17.DICOM_ALL\n  WHERE \n    \"collection_id\" = 'qin_prostate_repeatability'\n    AND \"SeriesDescription\" IN (\n      'DWI',\n      'T2 Weighted Axial',\n      'Apparent Diffusion Coefficient',\n      'T2 Weighted Axial Segmentations',\n      'Apparent Diffusion Coefficient Segmentations'\n    )    \n),\nt2_seg_lesion_series AS (\n  SELECT \n    DISTINCT \"StudyInstanceUID\"\n  FROM \n    IDC.IDC_V17.DICOM_ALL\n  CROSS JOIN LATERAL FLATTEN(input => \"SegmentSequence\") AS segSeq\n  WHERE \n    \"collection_id\" = 'qin_prostate_repeatability'\n    AND \"SeriesDescription\" = 'T2 Weighted Axial Segmentations'\n)\n\nSELECT \n    COUNT(DISTINCT \"StudyInstanceUID\") AS \"total_count\"\nFROM (\n  SELECT \n    \"StudyInstanceUID\" \n  FROM relevant_series\n  UNION ALL\n  SELECT \n    \"StudyInstanceUID\"\n  FROM t2_seg_lesion_series\n);\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq334",
        "score": 1,
        "pred_sql": "WITH all_transactions AS (\n    SELECT \n        TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000) AS \"timestamp\",  -- \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u65e5\u671f\u65f6\u95f4\u683c\u5f0f\n        \"value\",\n        'input' AS \"type\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"INPUTS\"\n    UNION ALL\n    SELECT \n        TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000) AS \"timestamp\",  -- \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u65e5\u671f\u65f6\u95f4\u683c\u5f0f\n        \"value\",\n        'output' AS \"type\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"OUTPUTS\"\n),\nfiltered_transactions AS (\n    SELECT\n        EXTRACT(YEAR FROM \"timestamp\") AS \"year\",\n        \"value\"\n    FROM \n        all_transactions\n    WHERE \"type\" = 'output'\n),\naverage_output_values AS (\n    SELECT\n        \"year\",\n        AVG(\"value\") AS \"avg_value\"\n    FROM \n        filtered_transactions\n    GROUP BY \"year\"\n),\naverage_transaction_values AS (\n    SELECT \n        EXTRACT(YEAR FROM TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) AS \"year\",  -- \u540c\u6837\u8f6c\u6362\u65f6\u95f4\u6233\n        AVG(\"output_value\") AS \"avg_transaction_value\" \n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"TRANSACTIONS\" \n    GROUP BY \"year\" \n    ORDER BY \"year\"\n),\ncommon_years AS (\n    SELECT\n        ao.\"year\",\n        ao.\"avg_value\" AS \"avg_output_value\",\n        atv.\"avg_transaction_value\"\n    FROM\n        average_output_values ao\n    JOIN\n        average_transaction_values atv \n        ON ao.\"year\" = atv.\"year\"\n)\n\nSELECT\n    \"year\",\n    \"avg_transaction_value\" - \"avg_output_value\" AS \"difference\"\nFROM\n    common_years\nORDER BY\n    \"year\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq341",
        "score": 1,
        "pred_sql": "WITH transaction_addresses AS (\n    SELECT \n        \"from_address\", \n        \"to_address\", \n        CAST(\"value\" AS NUMERIC) / 1000000 AS \"value\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_ETHEREUM\".\"TOKEN_TRANSFERS\"\n    WHERE \n        \"token_address\" = '0xa92a861fc11b99b24296af880011b47f9cafb5ab'\n),\n\nout_addresses AS (\n    SELECT \n        \"from_address\", \n        SUM(-1 * \"value\") AS \"total_value\"\n    FROM \n        transaction_addresses\n    GROUP BY \n        \"from_address\"\n),\n\nin_addresses AS (\n    SELECT \n        \"to_address\", \n        SUM(\"value\") AS \"total_value\"\n    FROM \n        transaction_addresses\n    GROUP BY \n        \"to_address\"\n),\n\nall_addresses AS (\n    SELECT \n        \"from_address\" AS \"address\", \n        \"total_value\"\n    FROM \n        out_addresses\n\n    UNION ALL\n\n    SELECT \n        \"to_address\" AS \"address\", \n        \"total_value\"\n    FROM \n        in_addresses\n)\n\nSELECT \n    \"address\"\nFROM \n    all_addresses\nGROUP BY \n    \"address\"\nHAVING \n    SUM(\"total_value\") > 0\nORDER BY \n    SUM(\"total_value\") ASC\nLIMIT 3;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq345",
        "score": 1,
        "pred_sql": "WITH seg_rtstruct AS (\n  SELECT\n    \"collection_id\",\n    \"StudyInstanceUID\",\n    \"SeriesInstanceUID\",\n    CONCAT('https://viewer.imaging.datacommons.cancer.gov/viewer/', \"StudyInstanceUID\") AS \"viewer_url\",\n    \"instance_size\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\"\n  WHERE\n    \"Modality\" IN ('SEG', 'RTSTRUCT')\n    AND \"SOPClassUID\" = '1.2.840.10008.5.1.4.1.1.66.4'\n    AND ARRAY_SIZE(\"ReferencedSeriesSequence\") = 0\n    AND ARRAY_SIZE(\"ReferencedImageSequence\") = 0\n    AND ARRAY_SIZE(\"SourceImageSequence\") = 0\n)\n\nSELECT\n  seg_rtstruct.\"collection_id\",\n  seg_rtstruct.\"SeriesInstanceUID\",\n  seg_rtstruct.\"StudyInstanceUID\",\n  seg_rtstruct.\"viewer_url\",\n  SUM(seg_rtstruct.\"instance_size\") / 1024 AS \"collection_size_KB\"\nFROM\n  seg_rtstruct\nGROUP BY\n  seg_rtstruct.\"collection_id\",\n  seg_rtstruct.\"SeriesInstanceUID\",\n  seg_rtstruct.\"StudyInstanceUID\",\n  seg_rtstruct.\"viewer_url\"\nORDER BY\n  \"collection_size_KB\" DESC;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq346",
        "score": 1,
        "pred_sql": "WITH\n  sampled_sops AS (\n    SELECT\n      \"collection_id\",\n      \"SeriesDescription\",\n      \"SeriesInstanceUID\",\n      \"SOPInstanceUID\" AS \"seg_SOPInstanceUID\",\n      COALESCE(\n        \"ReferencedSeriesSequence\"[0].\"ReferencedInstanceSequence\"[0].\"ReferencedSOPInstanceUID\",\n        \"ReferencedImageSequence\"[0].\"ReferencedSOPInstanceUID\",\n        \"SourceImageSequence\"[0].\"ReferencedSOPInstanceUID\"\n      ) AS \"referenced_sop\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\"\n    WHERE\n      \"Modality\" = 'SEG'\n      AND \"SOPClassUID\" = '1.2.840.10008.5.1.4.1.1.66.4'\n      AND \"access\" = 'Public'\n  ),\n  segmentations_data AS (\n    SELECT\n      dicom_all.\"collection_id\",\n      dicom_all.\"PatientID\",\n      dicom_all.\"SOPInstanceUID\",\n      REPLACE(segmentations.\"SegmentedPropertyCategory\":CodeMeaning::STRING, '\"', '') AS \"segmentation_category\",\n      REPLACE(segmentations.\"SegmentedPropertyType\":CodeMeaning::STRING, '\"', '') AS \"segmentation_type\"\n    FROM\n      sampled_sops\n    JOIN\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS dicom_all\n    ON\n      sampled_sops.\"referenced_sop\" = dicom_all.\"SOPInstanceUID\"\n    JOIN\n      \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS segmentations\n    ON\n      segmentations.\"SOPInstanceUID\" = sampled_sops.\"seg_SOPInstanceUID\"\n  )\nSELECT\n  \"segmentation_category\",\n  COUNT(*) AS \"count_\"\nFROM\n  segmentations_data\nGROUP BY\n  \"segmentation_category\"\nORDER BY\n  \"count_\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq347",
        "score": 1,
        "pred_sql": "WITH union_mr_seg AS (\n  SELECT\n    \"dicom_all_mr\".\"SOPInstanceUID\",\n    '' AS \"segPropertyTypeCodeMeaning\", \n    '' AS \"segPropertyCategoryCodeMeaning\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_mr\"\n  WHERE\n    \"dicom_all_mr\".\"SeriesInstanceUID\" IN ('1.3.6.1.4.1.14519.5.2.1.3671.4754.105976129314091491952445656147')\n    \n  UNION ALL\n\n  SELECT\n    \"dicom_all_seg\".\"SOPInstanceUID\",\n    \"segmentations\".\"SegmentedPropertyType\":\"CodeMeaning\" AS \"segPropertyTypeCodeMeaning\",\n    \"segmentations\".\"SegmentedPropertyCategory\":\"CodeMeaning\" AS \"segPropertyCategoryCodeMeaning\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_seg\"\n  JOIN\n    \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS \"segmentations\"\n  ON\n    \"dicom_all_seg\".\"SOPInstanceUID\" = \"segmentations\".\"SOPInstanceUID\"\n)\n\nSELECT\n  \"dc_all\".\"Modality\",\n  COUNT(*) AS \"count_\"\nFROM \n  \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dc_all\"\nINNER JOIN\n  union_mr_seg\nON \n  \"dc_all\".\"SOPInstanceUID\" = union_mr_seg.\"SOPInstanceUID\"\nGROUP BY\n  \"dc_all\".\"Modality\"\nORDER BY\n  \"count_\" DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq349",
        "score": 1,
        "pred_sql": "WITH bounding_area AS (\n    SELECT \n        \"osm_id\",\n        \"geometry\" AS geometry,\n        ST_AREA(ST_GEOGRAPHYFROMWKB(\"geometry\")) AS area\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => PLANET_FEATURES.\"all_tags\") AS \"tag\"\n    WHERE \n        \"feature_type\" = 'multipolygons'\n        AND \"tag\".value:\"key\" = 'boundary'\n        AND \"tag\".value:\"value\" = 'administrative'\n),\n\npoi AS (\n    SELECT \n        nodes.\"id\" AS poi_id,\n        nodes.\"geometry\" AS poi_geometry,\n        tags.value:\"value\" AS poitype\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_NODES AS nodes,\n    LATERAL FLATTEN(INPUT => nodes.\"all_tags\") AS tags\n    WHERE tags.value:\"key\" = 'amenity'\n),\n\npoi_counts AS (\n    SELECT\n        ba.\"osm_id\",\n        COUNT(poi.poi_id) AS total_pois\n    FROM bounding_area ba\n    JOIN poi\n    ON ST_DWITHIN(\n        ST_GEOGRAPHYFROMWKB(ba.geometry), \n        ST_GEOGRAPHYFROMWKB(poi.poi_geometry), \n        0.0\n    )\n    GROUP BY ba.\"osm_id\"\n),\n\nmedian_value AS (\n    SELECT \n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY total_pois) AS median_pois\n    FROM poi_counts\n),\n\nclosest_to_median AS (\n    SELECT\n        \"osm_id\",\n        total_pois,\n        ABS(total_pois - (SELECT median_pois FROM median_value)) AS diff_from_median\n    FROM poi_counts\n)\n\nSELECT\n    \"osm_id\"\nFROM closest_to_median\nORDER BY diff_from_median\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq358",
        "score": 1,
        "pred_sql": "SELECT\n    \"ZIPSTART\".\"zip_code\" AS zip_code_start,\n    \"ZIPEND\".\"zip_code\" AS zip_code_end\nFROM  \n    \"NEW_YORK_CITIBIKE_1\".\"NEW_YORK_CITIBIKE\".\"CITIBIKE_TRIPS\" AS \"TRI\"\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPSTART\"\n    ON ST_WITHIN(\n        ST_POINT(\"TRI\".\"start_station_longitude\", \"TRI\".\"start_station_latitude\"),\n        ST_GEOGFROMWKB(\"ZIPSTART\".\"zip_code_geom\")\n    )\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPEND\"\n    ON ST_WITHIN(\n        ST_POINT(\"TRI\".\"end_station_longitude\", \"TRI\".\"end_station_latitude\"),\n        ST_GEOGFROMWKB(\"ZIPEND\".\"zip_code_geom\")\n    )\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"GSOD2015\" AS \"WEA\"\n    ON TO_DATE(TO_CHAR(\"WEA\".\"year\") || LPAD(TO_CHAR(\"WEA\".\"mo\"), 2, '0') || LPAD(TO_CHAR(\"WEA\".\"da\"), 2, '0'), 'YYYYMMDD') = DATE_TRUNC('DAY', TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"starttime\") / 1000000))\nWHERE\n    \"WEA\".\"wban\" = '94728'\n    AND DATE_TRUNC('DAY', TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"starttime\") / 1000000)) = DATE '2015-07-15'\nORDER BY \n    \"WEA\".\"temp\" DESC, \"ZIPSTART\".\"zip_code\" ASC, \"ZIPEND\".\"zip_code\" DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq359",
        "score": 1,
        "pred_sql": "WITH repositories AS (\n    SELECT\n        t2.\"repo_name\",\n        t2.\"language\"\n    FROM (\n        SELECT\n            t1.\"repo_name\",\n            t1.\"language\",\n            RANK() OVER (PARTITION BY t1.\"repo_name\" ORDER BY t1.\"language_bytes\" DESC) AS \"rank\"\n        FROM (\n            SELECT\n                l.\"repo_name\",\n                lang.value:\"name\"::STRING AS \"language\",\n                lang.value:\"bytes\"::NUMBER AS \"language_bytes\"\n            FROM\n                GITHUB_REPOS.GITHUB_REPOS.LANGUAGES AS l,\n                LATERAL FLATTEN(input => l.\"language\") AS lang\n        ) AS t1\n    ) AS t2\n    WHERE t2.\"rank\" = 1\n),\npython_repo AS (\n    SELECT\n        \"repo_name\",\n        \"language\"\n    FROM\n        repositories\n    WHERE\n        \"language\" = 'JavaScript'\n)\nSELECT \n    sc.\"repo_name\", \n    COUNT(sc.\"commit\") AS \"num_commits\"\nFROM \n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS AS sc\nINNER JOIN \n    python_repo \nON \n    python_repo.\"repo_name\" = sc.\"repo_name\"\nGROUP BY \n    sc.\"repo_name\"\nORDER BY \n    \"num_commits\" DESC\nLIMIT 2;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq377",
        "score": 1,
        "pred_sql": "WITH json_files AS (\n  SELECT\n    c.\"id\",\n    TRY_PARSE_JSON(c.\"content\"):\"require\" AS \"dependencies\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS c\n),\npackage_names AS (\n  SELECT\n    f.key AS \"package_name\"\n  FROM\n    json_files,\n    LATERAL FLATTEN(input => \"dependencies\") AS f\n)\nSELECT\n  \"package_name\",\n  COUNT(*) AS \"count\"\nFROM\n  package_names\nWHERE\n  \"package_name\" IS NOT NULL\nGROUP BY\n  \"package_name\"\nORDER BY\n  \"count\" DESC;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq390",
        "score": 1,
        "pred_sql": "WITH\n-- Studies that have MR volumes\n\"mr_studies\" AS (\n  SELECT\n    \"dicom_all_mr\".\"StudyInstanceUID\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_mr\"\n  WHERE\n    \"Modality\" = 'MR'\n    AND \"collection_id\" = 'qin_prostate_repeatability'\n    AND CONTAINS(\"SeriesDescription\", 'T2 Weighted Axial')\n),\n\n\"seg_studies\" AS (\n  SELECT\n    \"dicom_all_seg\".\"StudyInstanceUID\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_seg\"\n  JOIN\n    \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS \"segmentations\"\n  ON\n    \"dicom_all_seg\".\"SOPInstanceUID\" = \"segmentations\".\"SOPInstanceUID\"\n  WHERE\n    \"collection_id\" = 'qin_prostate_repeatability'\n    AND CONTAINS(\"segmentations\".\"SegmentedPropertyType\":\"CodeMeaning\", 'Peripheral zone')\n    AND \"segmentations\".\"SegmentedPropertyCategory\":\"CodeMeaning\" = 'Anatomical Structure'\n)\n\nSELECT DISTINCT\n  \"mr_studies\".\"StudyInstanceUID\"\nFROM\n  \"mr_studies\"\nJOIN\n  \"seg_studies\"\nON\n  \"mr_studies\".\"StudyInstanceUID\" = \"seg_studies\".\"StudyInstanceUID\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq412",
        "score": 1,
        "pred_sql": "SELECT\n    \"creative_page_url\",\n    TO_TIMESTAMP(GET(\"region_stat\".value, 'first_shown')) AS \"first_shown\",\n    TO_TIMESTAMP(GET(\"region_stat\".value, 'last_shown')) AS \"last_shown\",\n    REPLACE(REPLACE(\"disapproval\"[0].\"removal_reason\", '\"\"', '\"'), '\"', '') AS \"removal_reason\", \n    REPLACE(REPLACE(\"disapproval\"[0].\"violation_category\", '\"\"', '\"'), '\"', '') AS \"violation_category\",\n    GET(\"region_stat\".value, 'times_shown_lower_bound') AS \"times_shown_lower\",\n    GET(\"region_stat\".value, 'times_shown_upper_bound') AS \"times_shown_upper\"\nFROM\n    \"GOOGLE_ADS\".\"GOOGLE_ADS_TRANSPARENCY_CENTER\".\"REMOVED_CREATIVE_STATS\",\n    LATERAL FLATTEN(input => \"region_stats\") AS \"region_stat\"\nWHERE\n    GET(\"region_stat\".value, 'region_code') = 'HR' \n    AND GET(\"region_stat\".value, 'times_shown_availability_date') IS NULL \n    AND GET(\"region_stat\".value, 'times_shown_lower_bound') > 10000 \n    AND GET(\"region_stat\".value, 'times_shown_upper_bound') < 25000\n    AND (\n        GET(\"audience_selection_approach_info\", 'demographic_info') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'geo_location') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'contextual_signals') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'customer_lists') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'topics_of_interest') != 'CRITERIA_UNUSED'\n    )\nORDER BY\n    \"last_shown\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq421",
        "score": 1,
        "pred_sql": "WITH\n  SpecimenPreparationSequence_unnested AS (\n    SELECT\n      d.\"SOPInstanceUID\",\n      concept_name_code_sequence.value:\"CodeMeaning\"::STRING AS \"cnc_cm\",\n      concept_name_code_sequence.value:\"CodingSchemeDesignator\"::STRING AS \"cnc_csd\",\n      concept_name_code_sequence.value:\"CodeValue\"::STRING AS \"cnc_val\",\n      concept_code_sequence.value:\"CodeMeaning\"::STRING AS \"ccs_cm\",\n      concept_code_sequence.value:\"CodingSchemeDesignator\"::STRING AS \"ccs_csd\",\n      concept_code_sequence.value:\"CodeValue\"::STRING AS \"ccs_val\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS d,\n      LATERAL FLATTEN(input => d.\"SpecimenDescriptionSequence\") AS spec_desc,\n      LATERAL FLATTEN(input => spec_desc.value:\"SpecimenPreparationSequence\") AS prep_seq,\n      LATERAL FLATTEN(input => prep_seq.value:\"SpecimenPreparationStepContentItemSequence\") AS prep_step,\n      LATERAL FLATTEN(input => prep_step.value:\"ConceptNameCodeSequence\") AS concept_name_code_sequence,\n      LATERAL FLATTEN(input => prep_step.value:\"ConceptCodeSequence\") AS concept_code_sequence\n  ),\n  slide_embedding AS (\n    SELECT\n      \"SOPInstanceUID\",\n      ARRAY_AGG(DISTINCT(CONCAT(\"ccs_cm\", ':', \"ccs_csd\", ':', \"ccs_val\"))) AS \"embeddingMedium_code_str\"\n    FROM\n      SpecimenPreparationSequence_unnested\n    WHERE\n      \"cnc_csd\" = 'SCT' AND \"cnc_val\" = '430863003' -- CodeMeaning is 'Embedding medium'\n    GROUP BY\n      \"SOPInstanceUID\"\n  ),\n  slide_staining AS (\n    SELECT\n      \"SOPInstanceUID\",\n      ARRAY_AGG(DISTINCT(CONCAT(\"ccs_cm\", ':', \"ccs_csd\", ':', \"ccs_val\"))) AS \"staining_usingSubstance_code_str\"\n    FROM\n      SpecimenPreparationSequence_unnested\n    WHERE\n      \"cnc_csd\" = 'SCT' AND \"cnc_val\" = '424361007' -- CodeMeaning is 'Using substance'\n    GROUP BY\n      \"SOPInstanceUID\"\n  ),\n  embedding_data AS (\n    SELECT\n      d.\"SOPInstanceUID\",\n      d.\"instance_size\",\n      e.\"embeddingMedium_code_str\",\n      s.\"staining_usingSubstance_code_str\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS d\n    LEFT JOIN\n      slide_embedding AS e ON d.\"SOPInstanceUID\" = e.\"SOPInstanceUID\"\n    LEFT JOIN\n      slide_staining AS s ON d.\"SOPInstanceUID\" = s.\"SOPInstanceUID\"\n    WHERE\n      d.\"Modality\" = 'SM'\n  )\nSELECT\n  SPLIT_PART(embeddingMedium_CodeMeaning_flat.VALUE::STRING, ':', 1) AS \"embeddingMedium_CodeMeaning\",\n  SPLIT_PART(staining_usingSubstance_CodeMeaning_flat.VALUE::STRING, ':', 1) AS \"staining_usingSubstance_CodeMeaning\",\n  COUNT(*) AS \"count_\"\nFROM\n  embedding_data\n  , LATERAL FLATTEN(input => embedding_data.\"embeddingMedium_code_str\") AS embeddingMedium_CodeMeaning_flat\n  , LATERAL FLATTEN(input => embedding_data.\"staining_usingSubstance_code_str\") AS staining_usingSubstance_CodeMeaning_flat\nGROUP BY\n  SPLIT_PART(embeddingMedium_CodeMeaning_flat.VALUE::STRING, ':', 1),\n  SPLIT_PART(staining_usingSubstance_CodeMeaning_flat.VALUE::STRING, ':', 1);\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq422",
        "score": 1,
        "pred_sql": "WITH\n  nonLocalizerRawData AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      \"StudyInstanceUID\",\n      \"PatientID\",\n      TRY_CAST(\"Exposure\"::STRING AS FLOAT) AS \"Exposure\",  -- \u76f4\u63a5\u4ece bid \u83b7\u53d6 Exposure\n      TRY_CAST(axes.VALUE::STRING AS FLOAT) AS \"zImagePosition\",\n      LEAD(TRY_CAST(axes.VALUE::STRING AS FLOAT)) OVER (\n        PARTITION BY \"SeriesInstanceUID\" \n        ORDER BY TRY_CAST(axes.VALUE::STRING AS FLOAT)\n      ) - TRY_CAST(axes.VALUE::STRING AS FLOAT) AS \"slice_interval\",\n      \"instance_size\" AS \"instanceSize\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"bid\",\n      LATERAL FLATTEN(input => \"bid\".\"ImagePositionPatient\") AS axes  -- \u4f7f\u7528 LATERAL FLATTEN \u5c55\u5f00\u6570\u7ec4\n    WHERE\n      \"collection_id\" = 'nlst' \n      AND \"Modality\" = 'CT' \n  ),\n  geometryChecks AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      \"StudyInstanceUID\",\n      \"PatientID\",\n      ARRAY_AGG(DISTINCT \"slice_interval\") AS \"sliceIntervalDifferences\",\n      ARRAY_AGG(DISTINCT \"Exposure\") AS \"distinctExposures\",\n      SUM(\"instanceSize\") / 1024 / 1024 AS \"seriesSizeInMB\"\n    FROM\n      nonLocalizerRawData\n    GROUP BY\n      \"SeriesInstanceUID\", \n      \"StudyInstanceUID\",\n      \"PatientID\"\n  ),\n  patientMetrics AS (\n    SELECT\n      \"PatientID\",\n      MAX(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"maxSliceIntervalDifference\",\n      MIN(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"minSliceIntervalDifference\",\n      MAX(TRY_CAST(sid.VALUE::STRING AS FLOAT)) - MIN(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"sliceIntervalDifferenceTolerance\",\n      MAX(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"maxExposure\",\n      MIN(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"minExposure\",\n      MAX(TRY_CAST(de.VALUE::STRING AS FLOAT)) - MIN(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"maxExposureDifference\",\n      \"seriesSizeInMB\"\n    FROM\n      geometryChecks,\n      LATERAL FLATTEN(input => \"sliceIntervalDifferences\") AS sid,  -- \u5c55\u5f00 sliceIntervalDifferences\n      LATERAL FLATTEN(input => \"distinctExposures\") AS de  -- \u5c55\u5f00 distinctExposures\n    WHERE\n      sid.VALUE IS NOT NULL\n      AND de.VALUE IS NOT NULL\n    GROUP BY\n      \"PatientID\",\n      \"seriesSizeInMB\"\n  ),\n  top3BySliceInterval AS (\n    SELECT\n      \"PatientID\",\n      \"seriesSizeInMB\"\n    FROM\n      patientMetrics\n    ORDER BY\n      \"sliceIntervalDifferenceTolerance\" DESC\n    LIMIT 3\n  ),\n  top3ByMaxExposure AS (\n    SELECT\n      \"PatientID\",\n      \"seriesSizeInMB\"\n    FROM\n      patientMetrics\n    ORDER BY\n      \"maxExposureDifference\" DESC\n    LIMIT 3\n  )\nSELECT\n  'Top 3 by Slice Interval' AS \"MetricGroup\",\n  AVG(\"seriesSizeInMB\") AS \"AverageSeriesSizeInMB\"\nFROM\n  top3BySliceInterval\nUNION ALL\nSELECT\n  'Top 3 by Max Exposure' AS \"MetricGroup\",\n  AVG(\"seriesSizeInMB\") AS \"AverageSeriesSizeInMB\"\nFROM\n  top3ByMaxExposure;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq429",
        "score": 1,
        "pred_sql": "WITH median_income_diff_by_zipcode AS (\n  WITH acs_2018 AS (\n    SELECT\n      \"geo_id\",\n      \"median_income\" AS \"median_income_2018\"\n    FROM\n      CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2018_5YR\"\n  ),\n  acs_2015 AS (\n    SELECT\n      \"geo_id\",\n      \"median_income\" AS \"median_income_2015\"\n    FROM\n      CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2015_5YR\"\n  ),\n  acs_diff AS (\n    SELECT\n      a18.\"geo_id\",\n      (a18.\"median_income_2018\" - a15.\"median_income_2015\") AS \"median_income_diff\"\n    FROM\n      acs_2018 a18\n    JOIN\n      acs_2015 a15 ON a18.\"geo_id\" = a15.\"geo_id\"\n  )\n  SELECT\n    \"geo_id\",\n    AVG(\"median_income_diff\") AS \"avg_median_income_diff\"\n  FROM\n    acs_diff\n  WHERE\n    \"median_income_diff\" IS NOT NULL\n  GROUP BY \"geo_id\"\n),\nbase_census AS (\n  SELECT\n    geo.\"state_name\",\n    AVG(i.\"avg_median_income_diff\") AS \"avg_median_income_diff\",\n    AVG(\n      \"employed_wholesale_trade\" * 0.38423645320197042 +\n      \"occupation_natural_resources_construction_maintenance\" * 0.48071410777129553 +\n      \"employed_arts_entertainment_recreation_accommodation_food\" * 0.89455676291236841 +\n      \"employed_information\" * 0.31315240083507306 +\n      \"employed_retail_trade\" * 0.51\n    ) AS \"avg_vulnerable\"\n  FROM\n    CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2017_5YR\" AS census\n  JOIN\n    median_income_diff_by_zipcode i ON CAST(census.\"geo_id\" AS STRING) = i.\"geo_id\"\n  JOIN\n    CENSUS_BUREAU_ACS_2.GEO_US_BOUNDARIES.\"ZIP_CODES\" geo ON census.\"geo_id\" = geo.\"zip_code\"\n  GROUP BY geo.\"state_name\"\n)\n\nSELECT \n  \"state_name\",\n  \"avg_median_income_diff\",\n  \"avg_vulnerable\"\nFROM \n  base_census\nORDER BY \n  \"avg_median_income_diff\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq444",
        "score": 1,
        "pred_sql": "WITH parsed_burn_logs AS (\n  SELECT\n    logs.\"block_timestamp\" AS block_timestamp,\n    logs.\"block_number\" AS block_number,\n    logs.\"transaction_hash\" AS transaction_hash,\n    logs.\"log_index\" AS log_index,\n    PARSE_JSON(logs.\"data\") AS data,\n    logs.\"topics\"\n  FROM CRYPTO.CRYPTO_ETHEREUM.LOGS AS logs\n  WHERE logs.\"address\" = '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'\n    AND logs.\"topics\"[0] = '0x0c396cd989a39f4459b5fa1aed6a9a8dcdbc45908acfd67e028cd568da98982c'\n),\nparsed_mint_logs AS (\n  SELECT\n    logs.\"block_timestamp\" AS block_timestamp,\n    logs.\"block_number\" AS block_number,\n    logs.\"transaction_hash\" AS transaction_hash,\n    logs.\"log_index\" AS log_index,\n    PARSE_JSON(logs.\"data\") AS data,\n    logs.\"topics\"\n  FROM CRYPTO.CRYPTO_ETHEREUM.LOGS AS logs\n  WHERE logs.\"address\" = '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'\n    AND logs.\"topics\"[0] = '0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde'\n)\n\nSELECT\n    block_timestamp,\n    block_number,\n    transaction_hash\nFROM parsed_mint_logs\n\nUNION ALL\n\nSELECT\n    block_timestamp,\n    block_number,\n    transaction_hash\nFROM parsed_burn_logs\n\nORDER BY block_timestamp\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_bq455",
        "score": 1,
        "pred_sql": "WITH\n  -- Create a common table expression (CTE) named localizerAndJpegCompressedSeries\n  localizerAndJpegCompressedSeries AS (\n    SELECT \n      \"SeriesInstanceUID\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid\n    WHERE \n      \"ImageType\" = 'LOCALIZER' OR\n      \"TransferSyntaxUID\" IN ('1.2.840.10008.1.2.4.70', '1.2.840.10008.1.2.4.51')\n  ),\n  \n  -- Create a common table expression (CTE) for x_vector calculation (first three elements)\n  imageOrientation AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      ARRAY_AGG(CAST(part.value AS FLOAT)) AS \"x_vector\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid,\n      LATERAL FLATTEN(input => bid.\"ImageOrientationPatient\") AS part\n    WHERE\n      part.index BETWEEN 0 AND 2\n    GROUP BY \"SeriesInstanceUID\"\n  ),\n  \n  -- Create a common table expression (CTE) for y_vector calculation (next three elements)\n  imageOrientationY AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      ARRAY_AGG(CAST(part.value AS FLOAT)) AS \"y_vector\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid,\n      LATERAL FLATTEN(input => bid.\"ImageOrientationPatient\") AS part\n    WHERE\n      part.index BETWEEN 3 AND 5\n    GROUP BY \"SeriesInstanceUID\"\n  ),\n  \n  -- Create a common table expression (CTE) named nonLocalizerRawData\n  nonLocalizerRawData AS (\n    SELECT\n      bid.\"SeriesInstanceUID\",  -- Added table alias bid\n      bid.\"StudyInstanceUID\",\n      bid.\"PatientID\",\n      bid.\"SOPInstanceUID\",\n      bid.\"SliceThickness\",\n      bid.\"ImageType\",\n      bid.\"TransferSyntaxUID\",\n      bid.\"SeriesNumber\",\n      bid.\"aws_bucket\",\n      bid.\"crdc_series_uuid\",\n      CAST(bid.\"Exposure\" AS FLOAT) AS \"Exposure\",  -- Use CAST directly\n      CAST(ipp.value AS FLOAT) AS \"zImagePosition\", -- Use CAST directly\n      CONCAT(ipp2.value, '/', ipp3.value) AS \"xyImagePosition\",\n      LEAD(CAST(ipp.value AS FLOAT)) OVER (PARTITION BY bid.\"SeriesInstanceUID\" ORDER BY CAST(ipp.value AS FLOAT)) - CAST(ipp.value AS FLOAT) AS \"slice_interval\",\n      ARRAY_TO_STRING(bid.\"ImageOrientationPatient\", '/') AS \"iop\",\n      bid.\"PixelSpacing\",\n      bid.\"Rows\" AS \"pixelRows\",\n      bid.\"Columns\" AS \"pixelColumns\",\n      bid.\"instance_size\" AS \"instanceSize\"\n    FROM\n      IDC.IDC_V17.\"DICOM_ALL\" AS bid\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp2\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp3\n    WHERE\n      bid.\"collection_id\" != 'nlst'\n      AND bid.\"Modality\" = 'CT'\n      AND ipp.index = 2\n      AND ipp2.index = 0\n      AND ipp3.index = 1\n      AND bid.\"SeriesInstanceUID\" NOT IN (SELECT \"SeriesInstanceUID\" FROM localizerAndJpegCompressedSeries)\n  ),\n  \n  -- Cross product calculation\n  crossProduct AS (\n    SELECT\n      nld.\"SOPInstanceUID\",  -- Added table alias nld\n      nld.\"SeriesInstanceUID\",  -- Added table alias nld\n      OBJECT_CONSTRUCT(\n        'x', (\"x_vector\"[1] * \"y_vector\"[2] - \"x_vector\"[2] * \"y_vector\"[1]),\n        'y', (\"x_vector\"[2] * \"y_vector\"[0] - \"x_vector\"[0] * \"y_vector\"[2]),\n        'z', (\"x_vector\"[0] * \"y_vector\"[1] - \"x_vector\"[1] * \"y_vector\"[0])\n      ) AS \"xyCrossProduct\"\n    FROM \n      nonLocalizerRawData AS nld  -- Added alias for nonLocalizerRawData\n    JOIN imageOrientation AS io ON nld.\"SeriesInstanceUID\" = io.\"SeriesInstanceUID\"\n    JOIN imageOrientationY AS ioy ON nld.\"SeriesInstanceUID\" = ioy.\"SeriesInstanceUID\"\n  ),\n  \n  -- Cross product elements extraction and row numbering\n  crossProductElements AS (\n    SELECT\n      cp.\"SOPInstanceUID\",  \n      cp.\"SeriesInstanceUID\",  \n      elem.value,\n      ROW_NUMBER() OVER (PARTITION BY cp.\"SOPInstanceUID\", cp.\"SeriesInstanceUID\" ORDER BY elem.value) AS rn\n    FROM \n      crossProduct AS cp  \n    -- Use LATERAL FLATTEN to explode the cross product object into individual 'x', 'y', and 'z'\n    JOIN LATERAL FLATTEN(input => ARRAY_CONSTRUCT(\n          cp.\"xyCrossProduct\"['x'],\n          cp.\"xyCrossProduct\"['y'],\n          cp.\"xyCrossProduct\"['z']\n    )) AS elem -- Simplified 'elem.value' reference here\n  ),\n  \n  -- Dot product calculation\n  dotProduct AS (\n    SELECT\n      cpe.\"SOPInstanceUID\",  \n      cpe.\"SeriesInstanceUID\",  \n      SUM(\n        CASE \n          WHEN cpe.rn = 1 THEN cpe.value * 0  -- x * 0\n          WHEN cpe.rn = 2 THEN cpe.value * 0  -- y * 0\n          WHEN cpe.rn = 3 THEN cpe.value * 1  -- z * 1\n        END\n      ) AS \"xyDotProduct\"\n    FROM \n      crossProductElements AS cpe\n    GROUP BY \n      cpe.\"SOPInstanceUID\",  \n      cpe.\"SeriesInstanceUID\"\n  ),\n  \n  -- Geometry checks for series consistency\n  geometryChecks AS (\n    SELECT\n      gc.\"SeriesInstanceUID\",  -- Added table alias gc\n      gc.\"SeriesNumber\",\n      gc.\"aws_bucket\",\n      gc.\"crdc_series_uuid\",\n      gc.\"StudyInstanceUID\",\n      gc.\"PatientID\",\n      ARRAY_AGG(DISTINCT gc.\"slice_interval\") AS \"sliceIntervalDifferences\",\n      ARRAY_AGG(DISTINCT gc.\"Exposure\") AS \"distinctExposures\",\n      COUNT(DISTINCT gc.\"iop\") AS \"iopCount\",\n      COUNT(DISTINCT gc.\"PixelSpacing\") AS \"pixelSpacingCount\",\n      COUNT(DISTINCT gc.\"zImagePosition\") AS \"positionCount\",\n      COUNT(DISTINCT gc.\"xyImagePosition\") AS \"xyPositionCount\",\n      COUNT(DISTINCT gc.\"SOPInstanceUID\") AS \"sopInstanceCount\",\n      COUNT(DISTINCT gc.\"SliceThickness\") AS \"sliceThicknessCount\",\n      COUNT(DISTINCT gc.\"Exposure\") AS \"exposureCount\",\n      COUNT(DISTINCT gc.\"pixelRows\") AS \"pixelRowCount\",\n      COUNT(DISTINCT gc.\"pixelColumns\") AS \"pixelColumnCount\",\n      dp.\"xyDotProduct\",  -- Added xyDotProduct from dotProduct\n      SUM(gc.\"instanceSize\") / 1024 / 1024 AS \"seriesSizeInMiB\"\n    FROM \n      nonLocalizerRawData AS gc  -- Added table alias gc\n    JOIN dotProduct AS dp ON gc.\"SeriesInstanceUID\" = dp.\"SeriesInstanceUID\" \n    AND gc.\"SOPInstanceUID\" = dp.\"SOPInstanceUID\"\n    GROUP BY\n      gc.\"SeriesInstanceUID\", \n      gc.\"SeriesNumber\",\n      gc.\"aws_bucket\",\n      gc.\"crdc_series_uuid\",\n      gc.\"StudyInstanceUID\",\n      gc.\"PatientID\",\n      dp.\"xyDotProduct\"  -- Include xyDotProduct in GROUP BY\n    HAVING\n      COUNT(DISTINCT gc.\"iop\") = 1 \n      AND COUNT(DISTINCT gc.\"PixelSpacing\") = 1  \n      AND COUNT(DISTINCT gc.\"SOPInstanceUID\") = COUNT(DISTINCT gc.\"zImagePosition\") \n      AND COUNT(DISTINCT gc.\"xyImagePosition\") = 1\n      AND COUNT(DISTINCT gc.\"pixelRows\") = 1 \n      AND COUNT(DISTINCT gc.\"pixelColumns\") = 1 \n      AND ABS(dp.\"xyDotProduct\") BETWEEN 0.99 AND 1.01\n  )\n\nSELECT\n  geometryChecks.\"SeriesInstanceUID\",  -- Added table alias\n  geometryChecks.\"SeriesNumber\",  -- Added table alias\n  geometryChecks.\"PatientID\",  -- Added table alias\n  geometryChecks.\"seriesSizeInMiB\"\nFROM\n  geometryChecks\nORDER BY\n  geometryChecks.\"seriesSizeInMiB\" DESC\nLIMIT 5;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_ga001",
        "score": 1,
        "pred_sql": "\nWITH\n  PurchaseEvents AS (\nSELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201201 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201202 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201203 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201204 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201205 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201206 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201207 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201208 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201209 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201210 WHERE event_name = 'purchase' \nUNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201211 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201212 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201213 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201214 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201215 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201216 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201217 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201218 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201219 WHERE event_name = 'purchase' \nUNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201220 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201221 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201222 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201223 WHERE event_name = 'purchase' \nUNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201224 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201225 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201226 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201227 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201228 WHERE event_name = 'purchase' \nUNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201229 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201230 WHERE event_name = 'purchase' UNION ALL SELECT user_pseudo_id, PARSE_JSON(items) as items FROM GA4.GA4_OBFUSCATED_SAMPLE_ECOMMERCE.EVENTS_20201231 WHERE event_name = 'purchase'\n),\n\nProductABuyers AS (\nSELECT\n  user_pseudo_id,\n  item.value:item_name::STRING AS item_name,\n  item.value:quantity::STRING AS quantity,\nFROM\n  PurchaseEvents,\n  LATERAL FLATTEN(input => items) AS item\nWHERE\n  item_name = 'Google Navy Speckled Tee'\n),\n\nITEM_QUANTITY AS (\n    SELECT\n      item.value:item_name::STRING AS item_name,\n      item.value:quantity::STRING AS quantity\n    FROM\n      PurchaseEvents,\n      LATERAL FLATTEN(input => items) AS item\n    WHERE\n      user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers)\n      AND item_name != 'Google Navy Speckled Tee'\n)\n\nSELECT item_name, SUM(quantity) AS total_quantity\nFROM ITEM_QUANTITY\nGROUP BY item_name\nHAVING SUM(quantity) IS NOT NULL\nORDER BY total_quantity DESC\nLIMIT 1;\n\n  \n\n\n  ",
        "error_info": null
    },
    {
        "instance_id": "sf_local003",
        "score": 0,
        "pred_sql": "WITH RecencyScore AS (\n    SELECT \"customer_unique_id\",\n           MAX(\"order_purchase_timestamp\") AS \"last_purchase\",\n           NTILE(5) OVER (ORDER BY MAX(\"order_purchase_timestamp\") DESC) AS \"recency\"\n    FROM E_COMMERCE.E_COMMERCE.ORDERS\n        JOIN E_COMMERCE.E_COMMERCE.CUSTOMERS USING (\"customer_id\")\n    WHERE \"order_status\" = 'delivered'\n    GROUP BY \"customer_unique_id\"\n),\nFrequencyScore AS (\n    SELECT \"customer_unique_id\",\n           COUNT(\"order_id\") AS \"total_orders\",\n           NTILE(5) OVER (ORDER BY COUNT(\"order_id\") DESC) AS \"frequency\"\n    FROM E_COMMERCE.E_COMMERCE.ORDERS\n        JOIN E_COMMERCE.E_COMMERCE.CUSTOMERS USING (\"customer_id\")\n    WHERE \"order_status\" = 'delivered'\n    GROUP BY \"customer_unique_id\"\n),\nMonetaryScore AS (\n    SELECT \"customer_unique_id\",\n           SUM(\"price\") AS \"total_spent\",\n           NTILE(5) OVER (ORDER BY SUM(\"price\") DESC) AS \"monetary\"\n    FROM E_COMMERCE.E_COMMERCE.ORDERS\n        JOIN E_COMMERCE.E_COMMERCE.ORDER_ITEMS USING (\"order_id\")\n        JOIN E_COMMERCE.E_COMMERCE.CUSTOMERS USING (\"customer_id\")\n    WHERE \"order_status\" = 'delivered'\n    GROUP BY \"customer_unique_id\"\n),\n\nRFM AS (\n    SELECT \"last_purchase\", \"total_orders\", \"total_spent\",\n        CASE\n            WHEN \"recency\" = 1 AND \"frequency\" + \"monetary\" IN (1, 2, 3, 4) THEN 'Champions'\n            WHEN \"recency\" IN (4, 5) AND \"frequency\" + \"monetary\" IN (1, 2) THEN 'Can\\'t Lose Them'\n            WHEN \"recency\" IN (4, 5) AND \"frequency\" + \"monetary\" IN (3, 4, 5, 6) THEN 'Hibernating'\n            WHEN \"recency\" IN (4, 5) AND \"frequency\" + \"monetary\" IN (7, 8, 9, 10) THEN 'Lost'\n            WHEN \"recency\" IN (2, 3) AND \"frequency\" + \"monetary\" IN (1, 2, 3, 4) THEN 'Loyal Customers'\n            WHEN \"recency\" = 3 AND \"frequency\" + \"monetary\" IN (5, 6) THEN 'Needs Attention'\n            WHEN \"recency\" = 1 AND \"frequency\" + \"monetary\" IN (7, 8) THEN 'Recent Users'\n            WHEN \"recency\" = 1 AND \"frequency\" + \"monetary\" IN (5, 6) OR\n                 \"recency\" = 2 AND \"frequency\" + \"monetary\" IN (5, 6, 7, 8) THEN 'Potentital Loyalists'\n            WHEN \"recency\" = 1 AND \"frequency\" + \"monetary\" IN (9, 10) THEN 'Price Sensitive'\n            WHEN \"recency\" = 2 AND \"frequency\" + \"monetary\" IN (9, 10) THEN 'Promising'\n            WHEN \"recency\" = 3 AND \"frequency\" + \"monetary\" IN (7, 8, 9, 10) THEN 'About to Sleep'\n        END AS \"RFM_Bucket\"\n    FROM RecencyScore\n        JOIN FrequencyScore USING (\"customer_unique_id\")\n        JOIN MonetaryScore USING (\"customer_unique_id\")\n)\n\nSELECT \"RFM_Bucket\", \n       AVG(\"total_spent\" / \"total_orders\") AS \"avg_sales_per_customer\"\nFROM RFM\nGROUP BY \"RFM_Bucket\"",
        "error_info": "Result Error"
    },
    {
        "instance_id": "sf_local004",
        "score": 1,
        "pred_sql": "WITH CustomerData AS (\n    SELECT\n        \"customer_unique_id\",\n        COUNT(DISTINCT E_COMMERCE.E_COMMERCE.ORDERS.\"order_id\") AS order_count,\n        SUM(TO_NUMBER(\"payment_value\")) AS total_payment,\n        DATE_PART('day', MIN(TO_TIMESTAMP(\"order_purchase_timestamp\", 'YYYY-MM-DD HH24:MI:SS'))) AS first_order_day,\n        DATE_PART('day', MAX(TO_TIMESTAMP(\"order_purchase_timestamp\", 'YYYY-MM-DD HH24:MI:SS'))) AS last_order_day\n    FROM E_COMMERCE.E_COMMERCE.CUSTOMERS \n        JOIN E_COMMERCE.E_COMMERCE.ORDERS USING (\"customer_id\")\n        JOIN E_COMMERCE.E_COMMERCE.ORDER_PAYMENTS USING (\"order_id\")\n    GROUP BY \"customer_unique_id\"\n)\nSELECT\n    \"customer_unique_id\",\n    order_count AS PF,\n    ROUND(total_payment / order_count, 2) AS AOV,\n    CASE\n        WHEN (last_order_day - first_order_day) < 7 THEN\n            1\n        ELSE\n            (last_order_day - first_order_day) / 7\n        END AS ACL\nFROM CustomerData\nORDER BY AOV DESC\nLIMIT 3;",
        "error_info": null
    },
    {
        "instance_id": "sf_local009",
        "score": 1,
        "pred_sql": "WITH FLIGHT_INFO AS (\n    SELECT    \n        FLIGHTS.\"flight_id\",\n        PARSE_JSON(DEPARTURE.\"city\"):\"en\" AS \"from_city\",\n        CAST(SUBSTR(DEPARTURE.\"coordinates\", 2, POSITION(',' IN DEPARTURE.\"coordinates\") - 2) AS DOUBLE) AS \"from_longitude\",\n        CAST(SUBSTR(DEPARTURE.\"coordinates\", POSITION(',' IN DEPARTURE.\"coordinates\") + 1, LENGTH(DEPARTURE.\"coordinates\") - POSITION(',' IN DEPARTURE.\"coordinates\") - 2) AS DOUBLE) AS \"from_latitude\",\n        PARSE_JSON(ARRIVAL.\"city\"):\"en\" AS \"to_city\",\n        CAST(SUBSTR(ARRIVAL.\"coordinates\", 2, POSITION(',' IN ARRIVAL.\"coordinates\") - 2) AS DOUBLE) AS \"to_longitude\",\n        CAST(SUBSTR(ARRIVAL.\"coordinates\", POSITION(',' IN ARRIVAL.\"coordinates\") + 1, LENGTH(ARRIVAL.\"coordinates\") - POSITION(',' IN ARRIVAL.\"coordinates\") - 2) AS DOUBLE) AS \"to_latitude\"\n    FROM\n        AIRLINES.AIRLINES.FLIGHTS \n    LEFT JOIN AIRLINES.AIRLINES.AIRPORTS_DATA AS DEPARTURE ON FLIGHTS.\"departure_airport\" = DEPARTURE.\"airport_code\"\n    LEFT JOIN AIRLINES.AIRLINES.AIRPORTS_DATA AS ARRIVAL ON FLIGHTS.\"arrival_airport\" = ARRIVAL.\"airport_code\"\n),\nDISTANCES AS (\n    SELECT\n        \"flight_id\",\n        \"from_city\",\n        \"to_city\",\n        CASE\n            WHEN \"from_city\" < \"to_city\" THEN \"from_city\" ELSE \"to_city\" END AS \"city1\",\n        CASE\n            WHEN \"from_city\" < \"to_city\" THEN \"to_city\" ELSE \"from_city\" END AS \"city2\",\n        2 * 6371 * ASIN(SQRT(\n            POWER(SIN(RADIANS((\"to_latitude\" - \"from_latitude\") / 2)), 2) +\n            COS(RADIANS(\"from_latitude\")) * COS(RADIANS(\"to_latitude\")) *\n            POWER(SIN(RADIANS((\"to_longitude\" - \"from_longitude\") / 2)), 2)\n        )) AS \"distance_km\"\n    FROM FLIGHT_INFO\n),\nALL_Route AS (\n    SELECT\n        \"city1\",\n        \"city2\",\n        \"distance_km\",\n        COUNT(*) AS \"number_of_flights\" -- Count flights for both directions\n    FROM DISTANCES\n    WHERE (\"city1\" = 'Abakan' OR \"city2\" = 'Abakan')\n    GROUP BY \"city1\", \"city2\", \"distance_km\"\n)\nSELECT \n    \"distance_km\"\nFROM ALL_Route\nORDER BY \"distance_km\" DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "sf_local010",
        "score": 1,
        "pred_sql": "\nWITH FLIGHT_INFO AS (\n    SELECT    \n        FLIGHTS.\"flight_id\",\n        PARSE_JSON(DEPARTURE.\"city\"):\"en\" AS \"from_city\",\n        CAST(SUBSTR(DEPARTURE.\"coordinates\", 2, POSITION(',' IN DEPARTURE.\"coordinates\") - 2) AS DOUBLE) AS \"from_longitude\",\n        CAST(SUBSTR(DEPARTURE.\"coordinates\", POSITION(',' IN DEPARTURE.\"coordinates\") + 1, LENGTH(DEPARTURE.\"coordinates\") - POSITION(',' IN DEPARTURE.\"coordinates\") - 2) AS DOUBLE) AS \"from_latitude\",\n        PARSE_JSON(ARRIVAL.\"city\"):\"en\" AS \"to_city\",\n        CAST(SUBSTR(ARRIVAL.\"coordinates\", 2, POSITION(',' IN ARRIVAL.\"coordinates\") - 2) AS DOUBLE) AS \"to_longitude\",\n        CAST(SUBSTR(ARRIVAL.\"coordinates\", POSITION(',' IN ARRIVAL.\"coordinates\") + 1, LENGTH(ARRIVAL.\"coordinates\") - POSITION(',' IN ARRIVAL.\"coordinates\") - 2) AS DOUBLE) AS \"to_latitude\"\n    FROM\n        AIRLINES.AIRLINES.FLIGHTS \n    LEFT JOIN AIRLINES.AIRLINES.AIRPORTS_DATA AS DEPARTURE ON FLIGHTS.\"departure_airport\" = DEPARTURE.\"airport_code\"\n    LEFT JOIN AIRLINES.AIRLINES.AIRPORTS_DATA AS ARRIVAL ON FLIGHTS.\"arrival_airport\" = ARRIVAL.\"airport_code\"\n)\n-- Create a histogram distribution of average_distance_km\nSELECT \"group_count\" FROM\n(\n    SELECT\n        FLOOR(\"average_distance_km\" / 1000) * 1000 AS \"distance_range\",\n        COUNT(*) AS \"group_count\"\n    FROM (\n        -- Calculate the average distance for each unique combination of from_city and to_city\n        SELECT\n            \"from_city\",\n            \"to_city\",\n            AVG(\"distance_km\") AS \"average_distance_km\"\n        FROM (\n            -- Subquery to calculate the distances as before\n            SELECT\n                \"from_city\",\n                \"to_city\",\n                -- Calculate the distance using the Haversine formula\n                2 * 6371 * ASIN(SQRT(\n                    POWER(SIN(RADIANS((\"to_latitude\" - \"from_latitude\") / 2)), 2) +\n                    COS(RADIANS(\"from_latitude\")) * COS(RADIANS(\"to_latitude\")) *\n                    POWER(SIN(RADIANS((\"to_longitude\" - \"from_longitude\") / 2)), 2)\n                )) AS \"distance_km\"\n            FROM FLIGHT_INFO\n        ) AS subquery\n        GROUP BY \"from_city\", \"to_city\"\n    ) AS distances\n    GROUP BY \"distance_range\"\n    ORDER BY \"group_count\"\n    LIMIT 1\n)",
        "error_info": null
    },
    {
        "instance_id": "sf_local015",
        "score": 1,
        "pred_sql": "WITH BASE AS (\n    SELECT \n        COL.\"case_id\" AS \"case_id\",\n        COL.\"motorcyclist_killed_count\" AS \"motorcyclist_killed_count\",\n        CASE WHEN PARTY.\"party_safety_equipment_1\" = 'driver, motorcycle helmet used' THEN 1\n             WHEN PARTY.\"party_safety_equipment_2\" = 'driver, motorcycle helmet used' THEN 1\n             WHEN PARTY.\"party_safety_equipment_1\" = 'passenger, motorcycle helmet used' THEN 1\n             WHEN PARTY.\"party_safety_equipment_2\" = 'passenger, motorcycle helmet used' THEN 1\n             ELSE 0 END AS \"helmet_used\",\n        CASE WHEN PARTY.\"party_safety_equipment_1\" = 'driver, motorcycle helmet not used' THEN 1\n             WHEN PARTY.\"party_safety_equipment_2\" = 'driver, motorcycle helmet not used' THEN 1\n             WHEN PARTY.\"party_safety_equipment_1\" = 'passenger, motorcycle helmet not used' THEN 1\n             WHEN PARTY.\"party_safety_equipment_2\" = 'passenger, motorcycle helmet not used' THEN 1\n             ELSE 0 END AS \"helmet_not_used\"\n    FROM CALIFORNIA_TRAFFIC_COLLISION.CALIFORNIA_TRAFFIC_COLLISION.COLLISIONS COL\n    JOIN CALIFORNIA_TRAFFIC_COLLISION.CALIFORNIA_TRAFFIC_COLLISION.PARTIES PARTY\n        ON COL.\"case_id\" = PARTY.\"case_id\"\n    WHERE \n        COL.\"motorcycle_collision\" = '1'\n        AND PARTY.\"party_age\" IS NOT NULL\n    GROUP BY 1, 2, PARTY.\"party_safety_equipment_1\", PARTY.\"party_safety_equipment_2\"\n)\nSELECT \n    ROUND(SUM(CASE WHEN \"helmet_used\" = 1 THEN \"motorcyclist_killed_count\" ELSE 0 END) * 100.0 / NULLIF(COUNT(CASE WHEN \"helmet_used\" = 1 THEN \"case_id\" END), 0), 2) AS \"percent_killed_helmet_used\",\n    ROUND(SUM(CASE WHEN \"helmet_not_used\" = 1 THEN \"motorcyclist_killed_count\" ELSE 0 END) * 100.0 / NULLIF(COUNT(CASE WHEN \"helmet_not_used\" = 1 THEN \"case_id\" END), 0), 2) AS \"percent_killed_helmet_not_used\"\nFROM \n    BASE",
        "error_info": null
    },
    {
        "instance_id": "sf_local019",
        "score": 1,
        "pred_sql": "WITH MatchDetails AS (\n    SELECT\n        B.\"name\" AS \"titles\",\n        M.\"duration\" AS \"match_duration\",\n        W1.\"name\" || ' vs ' || W2.\"name\" AS \"matches\",\n        M.\"win_type\" AS \"win_type\",\n        L.\"name\" AS \"location\",\n        E.\"name\" AS \"event\",\n        ROW_NUMBER() OVER (PARTITION BY B.\"name\" ORDER BY CAST(SPLIT_PART(M.\"duration\", ':', 1) AS DOUBLE) * 60 + CAST(SPLIT_PART(M.\"duration\", ':', 2) AS DOUBLE) ASC) AS \"rank\"\n    FROM \n        WWE.WWE.BELTS B\n    INNER JOIN WWE.WWE.MATCHES M ON M.\"title_id\" = B.\"id\"\n    INNER JOIN WWE.WWE.WRESTLERS W1 ON W1.\"id\" = M.\"winner_id\"\n    INNER JOIN WWE.WWE.WRESTLERS W2 ON W2.\"id\" = M.\"loser_id\"\n    INNER JOIN WWE.WWE.CARDS C ON C.\"id\" = M.\"card_id\"\n    INNER JOIN WWE.WWE.LOCATIONS L ON L.\"id\" = C.\"location_id\"\n    INNER JOIN WWE.WWE.EVENTS E ON E.\"id\" = C.\"event_id\"\n    INNER JOIN WWE.WWE.PROMOTIONS P ON P.\"id\" = C.\"promotion_id\"\n    WHERE\n        P.\"name\" = 'NXT'\n        AND M.\"duration\" <> ''\n        AND B.\"name\" <> ''\n        AND B.\"name\" NOT IN (\n            SELECT \"name\" \n            FROM WWE.WWE.BELTS \n            WHERE \"name\" LIKE '%title change%'\n        )\n),\nRank1 AS (\n    SELECT \n        \"titles\",\n        \"match_duration\",\n        \"matches\",\n        \"win_type\",\n        \"location\",\n        \"event\"\n    FROM \n        MatchDetails\n    WHERE \n        \"rank\" = 1\n)\nSELECT\n    SUBSTR(\"matches\", 1, POSITION(' vs ' IN \"matches\") - 1) AS \"wrestler1\",\n    SUBSTR(\"matches\", POSITION(' vs ' IN \"matches\") + 4) AS \"wrestler2\"\nFROM\n    Rank1\nORDER BY CAST(SPLIT_PART(\"match_duration\", ':', 1) AS DOUBLE) * 60 + CAST(SPLIT_PART(\"match_duration\", ':', 2) AS DOUBLE) \nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "sf_local022",
        "score": 1,
        "pred_sql": "-- Step 1: Calculate players' total runs in each match\nWITH PLAYER_RUNS AS (\n    SELECT \n        BBB.\"striker\" AS \"player_id\", \n        BBB.\"match_id\", \n        SUM(CAST(BSC.\"runs_scored\" AS DOUBLE)) AS \"total_runs\"\n    FROM \n        IPL.IPL.BALL_BY_BALL AS BBB\n    JOIN \n        IPL.IPL.BATSMAN_SCORED AS BSC\n    ON \n        BBB.\"match_id\" = BSC.\"match_id\" \n        AND BBB.\"over_id\" = BSC.\"over_id\" \n        AND BBB.\"ball_id\" = BSC.\"ball_id\" \n        AND BBB.\"innings_no\" = BSC.\"innings_no\"\n    GROUP BY \n        BBB.\"striker\", BBB.\"match_id\"\n    HAVING \n        SUM(CAST(BSC.\"runs_scored\" AS DOUBLE)) >= 100\n),\n\n-- Step 2: Identify losing teams for each match\nLOSING_TEAMS AS (\n    SELECT \n        \"match_id\", \n        CASE \n            WHEN \"match_winner\" = \"team_1\" THEN \"team_2\"\n            ELSE \"team_1\" \n        END AS \"loser\" \n    FROM \n        IPL.IPL.MATCH\n),\n\n-- Step 3: Combine the above results to get players who scored 100 or more runs in losing teams\nPLAYERS_IN_LOSING_TEAMS AS (\n    SELECT \n        PR.\"player_id\", \n        PR.\"match_id\" \n    FROM \n        PLAYER_RUNS AS PR\n    JOIN \n        LOSING_TEAMS AS LT\n    ON \n        PR.\"match_id\" = LT.\"match_id\"\n    JOIN \n        IPL.IPL.PLAYER_MATCH AS PM\n    ON \n        PR.\"player_id\" = PM.\"player_id\" \n        AND PR.\"match_id\" = PM.\"match_id\" \n        AND LT.\"loser\" = PM.\"team_id\"\n)\n\n-- Step 4: Select distinct player names from the player table\nSELECT DISTINCT \n    P.\"player_name\" \nFROM \n    IPL.IPL.PLAYER AS P\nJOIN \n    PLAYERS_IN_LOSING_TEAMS AS PLT\nON \n    P.\"player_id\" = PLT.\"player_id\"\nORDER BY \n    P.\"player_name\";",
        "error_info": null
    },
    {
        "instance_id": "sf_local026",
        "score": 1,
        "pred_sql": "\nWITH COMBINED_RUNS AS (\n    SELECT \"match_id\", \"over_id\", \"ball_id\", \"innings_no\", CAST(\"runs_scored\" AS DOUBLE) AS \"runs\"\n    FROM IPL.IPL.BATSMAN_SCORED\n    UNION ALL\n    SELECT \"match_id\", \"over_id\", \"ball_id\", \"innings_no\", CAST(\"extra_runs\" AS DOUBLE) AS \"runs\"\n    FROM IPL.IPL.EXTRA_RUNS\n),\nOVER_RUNS AS (\n    SELECT \"match_id\", \"innings_no\", \"over_id\", SUM(\"runs\") AS \"runs_scored\"\n    FROM COMBINED_RUNS\n    GROUP BY \"match_id\", \"innings_no\", \"over_id\"\n),\nMAX_OVER_RUNS AS (\n    SELECT \"match_id\", MAX(\"runs_scored\") AS \"max_runs\"\n    FROM OVER_RUNS\n    GROUP BY \"match_id\"\n),\nTOP_OVERS AS (\n    SELECT o.\"match_id\", o.\"innings_no\", o.\"over_id\", o.\"runs_scored\"\n    FROM OVER_RUNS o\n    JOIN MAX_OVER_RUNS m ON o.\"match_id\" = m.\"match_id\" AND o.\"runs_scored\" = m.\"max_runs\"\n),\nTOP_BOWLERS AS (\n    SELECT\n        bb.\"match_id\",\n        t.\"runs_scored\" AS \"maximum_runs\",\n        bb.\"bowler\"\n    FROM IPL.IPL.BALL_BY_BALL bb\n    JOIN TOP_OVERS t ON bb.\"match_id\" = t.\"match_id\"\n    AND bb.\"innings_no\" = t.\"innings_no\"\n    AND bb.\"over_id\" = t.\"over_id\"\n    GROUP BY bb.\"match_id\", t.\"runs_scored\", bb.\"bowler\"\n)\nSELECT\n    b.\"match_id\",\n    p.\"player_name\"\nFROM (\n    SELECT *\n    FROM TOP_BOWLERS\n    ORDER BY CAST(\"maximum_runs\" AS DOUBLE) DESC\n    LIMIT 3\n) b\nJOIN IPL.IPL.PLAYER p ON p.\"player_id\" = b.\"bowler\"\nORDER BY CAST(b.\"maximum_runs\" AS DOUBLE) DESC, b.\"match_id\", p.\"player_name\";",
        "error_info": null
    },
    {
        "instance_id": "sf_local028",
        "score": 1,
        "pred_sql": "SELECT\n  \"Month\" AS \"month_no\",\n  SUM(CASE WHEN A.\"Year\" = '2016' THEN 1 ELSE 0 END) AS \"Year2016\",\n  SUM(CASE WHEN A.\"Year\" = '2017' THEN 1 ELSE 0 END) AS \"Year2017\",\n  SUM(CASE WHEN A.\"Year\" = '2018' THEN 1 ELSE 0 END) AS \"Year2018\"\nFROM\n(\n  SELECT \n    \"customer_id\",\n    \"order_id\",\n    \"order_delivered_customer_date\",\n    \"order_status\",\n    TO_VARCHAR(TO_DATE(\"order_delivered_customer_date\"), 'YYYY') AS \"Year\",\n    TO_VARCHAR(TO_DATE(\"order_delivered_customer_date\"), 'MM') AS \"Month\"\n  FROM BRAZILIAN_E_COMMERCE.BRAZILIAN_E_COMMERCE.OLIST_ORDERS\n  WHERE \"order_status\" = 'delivered' \n    AND \"order_delivered_customer_date\" IS NOT NULL\n    AND \"order_delivered_customer_date\" <> ''\n  GROUP BY \"customer_id\", \"order_id\", \"order_delivered_customer_date\", \"order_status\"\n  ORDER BY \"order_delivered_customer_date\" ASC\n) A\nGROUP BY \"Month\"\nORDER BY \"month_no\" ASC;",
        "error_info": null
    },
    {
        "instance_id": "sf_local030",
        "score": 1,
        "pred_sql": "WITH bottom_five_cities AS (\n    SELECT \n        C.\"customer_city\",\n        SUM(CAST(P.\"payment_value\" AS DOUBLE)) AS \"Total_Payment_By_Customers\",\n        COUNT(O.\"order_id\") AS \"Total_Number_Of_Orders\"\n    FROM BRAZILIAN_E_COMMERCE.BRAZILIAN_E_COMMERCE.OLIST_CUSTOMERS C\n    JOIN BRAZILIAN_E_COMMERCE.BRAZILIAN_E_COMMERCE.OLIST_ORDERS O ON C.\"customer_id\" = O.\"customer_id\"\n    JOIN BRAZILIAN_E_COMMERCE.BRAZILIAN_E_COMMERCE.OLIST_ORDER_PAYMENTS P ON O.\"order_id\" = P.\"order_id\"\n    WHERE O.\"order_status\" = 'delivered'\n    GROUP BY C.\"customer_city\"\n    ORDER BY \"Total_Payment_By_Customers\" ASC\n    LIMIT 5\n)\nSELECT \n    AVG(\"Total_Payment_By_Customers\") AS \"Average_Total_Payment\",\n    AVG(\"Total_Number_Of_Orders\") AS \"Average_Total_Orders\"\nFROM bottom_five_cities;",
        "error_info": null
    },
    {
        "instance_id": "sf_local038",
        "score": 1,
        "pred_sql": "SELECT\n    ACTOR.\"first_name\" || ' ' || ACTOR.\"last_name\" AS \"full_name\"\nFROM\n    PAGILA.PAGILA.ACTOR\nINNER JOIN PAGILA.PAGILA.FILM_ACTOR ON ACTOR.\"actor_id\" = FILM_ACTOR.\"actor_id\"\nINNER JOIN PAGILA.PAGILA.FILM ON FILM_ACTOR.\"film_id\" = FILM.\"film_id\"\nINNER JOIN PAGILA.PAGILA.FILM_CATEGORY ON FILM.\"film_id\" = FILM_CATEGORY.\"film_id\"\nINNER JOIN PAGILA.PAGILA.CATEGORY ON FILM_CATEGORY.\"category_id\" = CATEGORY.\"category_id\"\n-- Join with the language table\nINNER JOIN PAGILA.PAGILA.LANGUAGE ON FILM.\"language_id\" = LANGUAGE.\"language_id\"\nWHERE\n    CATEGORY.\"name\" = 'Children' AND\n    FILM.\"release_year\" BETWEEN 2000 AND 2010 AND\n    FILM.\"rating\" IN ('G', 'PG') AND\n    LANGUAGE.\"name\" = 'English' AND\n    FILM.\"length\" <= 120\nGROUP BY\n    ACTOR.\"actor_id\", ACTOR.\"first_name\", ACTOR.\"last_name\"\nORDER BY\n    COUNT(FILM.\"film_id\") DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "sf_local039",
        "score": 1,
        "pred_sql": "SELECT\n    CATEGORY.\"name\"\nFROM\n    PAGILA.PAGILA.CATEGORY\nINNER JOIN PAGILA.PAGILA.FILM_CATEGORY USING (\"category_id\")\nINNER JOIN PAGILA.PAGILA.FILM USING (\"film_id\")\nINNER JOIN PAGILA.PAGILA.INVENTORY USING (\"film_id\")\nINNER JOIN PAGILA.PAGILA.RENTAL USING (\"inventory_id\")\nINNER JOIN PAGILA.PAGILA.CUSTOMER USING (\"customer_id\")\nINNER JOIN PAGILA.PAGILA.ADDRESS USING (\"address_id\")\nINNER JOIN PAGILA.PAGILA.CITY USING (\"city_id\")\nWHERE\n    LOWER(CITY.\"city\") LIKE 'a%' OR CITY.\"city\" LIKE '%-%'\nGROUP BY\n    CATEGORY.\"name\"\nORDER BY\n    SUM(CAST((DATEDIFF('hour', TRY_TO_TIMESTAMP(RENTAL.\"rental_date\"), TRY_TO_TIMESTAMP(RENTAL.\"return_date\"))) AS INTEGER)) DESC\nLIMIT\n    1;",
        "error_info": null
    },
    {
        "instance_id": "sf_local056",
        "score": 1,
        "pred_sql": "WITH result_table AS (\n    SELECT \n        TO_CHAR(TO_TIMESTAMP(pm.\"payment_date\"), 'MM') AS pay_mon,  -- Direct conversion to timestamp, no format needed\n        cust.\"first_name\" || ' ' || cust.\"last_name\" AS fullname, \n        SUM(pm.\"amount\") AS pay_amount \n    FROM \n        SQLITE_SAKILA.SQLITE_SAKILA.PAYMENT AS pm \n    JOIN \n        SQLITE_SAKILA.SQLITE_SAKILA.CUSTOMER AS cust \n    ON \n        pm.\"customer_id\" = cust.\"customer_id\" \n    GROUP BY \n        1, \n        2\n), \ndifference_per_mon AS (\n    SELECT \n        rt.fullname, \n        ABS(rt.pay_amount - LAG(rt.pay_amount) OVER (PARTITION BY rt.fullname ORDER BY rt.pay_mon)) AS diff \n    FROM \n        result_table rt\n), \naverage_difference AS (\n    SELECT \n        fullname, \n        AVG(diff) AS avg_diff\n    FROM \n        difference_per_mon \n    WHERE \n        diff IS NOT NULL\n    GROUP BY \n        fullname\n)\nSELECT \n    fullname\nFROM \n    average_difference\nORDER BY \n    avg_diff DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local064",
        "score": 1,
        "pred_sql": "WITH RECURSIVE generate_series AS (\n    SELECT 0 AS \"value\"\n    UNION ALL\n    SELECT \"value\" + 1\n    FROM generate_series\n    WHERE \"value\" < 3\n),\ngenerate_months_cte AS (\n    SELECT DISTINCT\n        \"customer_id\",\n        TO_CHAR(DATEADD(MONTH, \"value\", '2020-01-01'), 'YYYY-MM') AS \"generated_month\"\n    FROM\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"CUSTOMER_TRANSACTIONS\", generate_series\n    WHERE\n        TO_CHAR(DATEADD(MONTH, \"value\", '2020-01-01'), 'YYYY') = '2020'\n),\nclosing_balance AS (\n    SELECT\n        \"customer_id\",\n        TO_CHAR(DATE_TRUNC('MONTH', TO_DATE(\"txn_date\", 'YYYY-MM-DD')), 'YYYY-MM') AS \"txn_month\",  -- Convert to DATE\n        SUM(\n            CASE\n                WHEN \"txn_type\" = 'deposit' THEN \"txn_amount\"\n                ELSE - \"txn_amount\"\n            END\n        ) AS \"transaction_amount\"\n    FROM\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"CUSTOMER_TRANSACTIONS\"\n    WHERE\n        TO_CHAR(TO_DATE(\"txn_date\", 'YYYY-MM-DD'), 'YYYY') = '2020'  -- Convert to DATE for comparison\n    GROUP BY\n        \"customer_id\",\n        \"txn_month\"\n),\nfinal_balance AS (\n    SELECT \n        t1.\"customer_id\",\n        t1.\"generated_month\",\n        COALESCE(SUM(t2.\"transaction_amount\"), 0) AS \"month_end_balance\"\n    FROM\n        generate_months_cte AS t1\n    LEFT JOIN \n        closing_balance AS t2\n    ON\n        t1.\"generated_month\" = t2.\"txn_month\"\n        AND t1.\"customer_id\" = t2.\"customer_id\"\n    GROUP BY\n        t1.\"customer_id\",\n        t1.\"generated_month\"\n),\npositive_balance_counts AS (\n    SELECT\n        \"generated_month\",\n        COUNT(DISTINCT \"customer_id\") AS \"positive_balance_count\"\n    FROM\n        final_balance\n    WHERE\n        \"month_end_balance\" > 0\n    GROUP BY\n        \"generated_month\"\n),\nmost_positive_month AS (\n    SELECT\n        \"generated_month\"\n    FROM\n        positive_balance_counts\n    ORDER BY\n        \"positive_balance_count\" DESC\n    LIMIT 1\n),\nleast_positive_month AS (\n    SELECT\n        \"generated_month\"\n    FROM\n        positive_balance_counts\n    ORDER BY\n        \"positive_balance_count\" ASC\n    LIMIT 1\n),\naverage_balance AS (\n    SELECT\n        'most_positive' AS \"month_type\",\n        AVG(\"month_end_balance\") AS \"avg_balance\"\n    FROM\n        final_balance\n    WHERE\n        \"generated_month\" = (SELECT \"generated_month\" FROM most_positive_month)\n    UNION ALL\n    SELECT\n        'least_positive' AS \"month_type\",\n        AVG(\"month_end_balance\") AS \"avg_balance\"\n    FROM\n        final_balance\n    WHERE\n        \"generated_month\" = (SELECT \"generated_month\" FROM least_positive_month)\n)\nSELECT\n    (SELECT \"avg_balance\" FROM average_balance WHERE \"month_type\" = 'most_positive') -\n    (SELECT \"avg_balance\" FROM average_balance WHERE \"month_type\" = 'least_positive') AS \"balance_diff\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local075",
        "score": 1,
        "pred_sql": "WITH product_viewed AS (\n    SELECT\n        t1.\"page_id\",\n        SUM(CASE WHEN \"event_type\" = 1 THEN 1 ELSE 0 END) AS \"n_page_views\",\n        SUM(CASE WHEN \"event_type\" = 2 THEN 1 ELSE 0 END) AS \"n_added_to_cart\"\n    FROM\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_PAGE_HIERARCHY\" AS t1\n    JOIN\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_EVENTS\" AS t2\n    ON\n        t1.\"page_id\" = t2.\"page_id\"\n    WHERE\n        t1.\"product_id\" IS NOT NULL\n    GROUP BY\n        t1.\"page_id\"\n),\nproduct_purchased AS (\n    SELECT\n        t2.\"page_id\",\n        SUM(CASE WHEN \"event_type\" = 2 THEN 1 ELSE 0 END) AS \"purchased_from_cart\"\n    FROM\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_PAGE_HIERARCHY\" AS t1\n    JOIN\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_EVENTS\" AS t2\n    ON\n        t1.\"page_id\" = t2.\"page_id\"\n    WHERE\n        t1.\"product_id\" IS NOT NULL\n        AND EXISTS (\n            SELECT\n                \"visit_id\"\n            FROM\n                \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_EVENTS\"\n            WHERE\n                \"event_type\" = 3\n                AND t2.\"visit_id\" = \"visit_id\"\n        )\n        AND t1.\"page_id\" NOT IN (1, 2, 12, 13)\n    GROUP BY\n        t2.\"page_id\"\n),\nproduct_abandoned AS (\n    SELECT\n        t2.\"page_id\",\n        SUM(CASE WHEN \"event_type\" = 2 THEN 1 ELSE 0 END) AS \"abandoned_in_cart\"\n    FROM\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_PAGE_HIERARCHY\" AS t1\n    JOIN\n        \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_EVENTS\" AS t2\n    ON\n        t1.\"page_id\" = t2.\"page_id\"\n    WHERE\n        t1.\"product_id\" IS NOT NULL\n        AND NOT EXISTS (\n            SELECT\n                \"visit_id\"\n            FROM\n                \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_EVENTS\"\n            WHERE\n                \"event_type\" = 3\n                AND t2.\"visit_id\" = \"visit_id\"\n        )\n        AND t1.\"page_id\" NOT IN (1, 2, 12, 13)\n    GROUP BY\n        t2.\"page_id\"\n)\nSELECT\n    t1.\"page_id\",\n    t1.\"page_name\",\n    t2.\"n_page_views\" AS \"number of product being viewed\",\n    t2.\"n_added_to_cart\" AS \"number added to the cart\",\n    t4.\"abandoned_in_cart\" AS \"without being purchased in cart\",\n    t3.\"purchased_from_cart\" AS \"count of actual purchases\"\nFROM\n    \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"SHOPPING_CART_PAGE_HIERARCHY\" AS t1\nJOIN\n    product_viewed AS t2 \nON\n    t2.\"page_id\" = t1.\"page_id\"\nJOIN\n    product_purchased AS t3 \nON \n    t3.\"page_id\" = t1.\"page_id\"\nJOIN\n    product_abandoned AS t4 \nON \n    t4.\"page_id\" = t1.\"page_id\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local157",
        "score": 1,
        "pred_sql": "WITH cte_adjusted_prices AS (\n  SELECT\n    \"ticker\",\n    \"market_date\",\n    CASE\n      WHEN SUBSTRING(\"volume\", -1) = 'K' THEN CAST(SUBSTRING(\"volume\", 1, LENGTH(\"volume\") - 1) AS REAL) * 1000\n      WHEN SUBSTRING(\"volume\", -1) = 'M' THEN CAST(SUBSTRING(\"volume\", 1, LENGTH(\"volume\") - 1) AS REAL) * 1000000\n      WHEN \"volume\" = '-' THEN 0\n      ELSE CAST(\"volume\" AS REAL)\n    END AS volume\n  FROM \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"BITCOIN_PRICES\"\n),\ncte_previous_volume AS (\n  SELECT\n    \"ticker\",\n    \"market_date\",\n    volume,\n    LAG(volume) OVER (\n      PARTITION BY \"ticker\"\n      ORDER BY TO_DATE(SUBSTRING(\"market_date\", 7, 4) || '-' || SUBSTRING(\"market_date\", 4, 2) || '-' || SUBSTRING(\"market_date\", 1, 2), 'YYYY-MM-DD')\n    ) AS previous_volume\n  FROM cte_adjusted_prices\n  WHERE volume != 0\n)\nSELECT\n  \"ticker\",\n  \"market_date\",\n  volume,\n  previous_volume,\n  ROUND(\n    100.0 * (volume - previous_volume) / previous_volume,\n    2\n  ) AS daily_change\nFROM cte_previous_volume\nWHERE TO_DATE(SUBSTRING(\"market_date\", 7, 4) || '-' || SUBSTRING(\"market_date\", 4, 2) || '-' || SUBSTRING(\"market_date\", 1, 2), 'YYYY-MM-DD')\n  BETWEEN TO_DATE('2021-08-01', 'YYYY-MM-DD') AND TO_DATE('2021-08-10', 'YYYY-MM-DD')\nORDER BY \"ticker\", \"market_date\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local194",
        "score": 1,
        "pred_sql": "WITH \n    ACTOR_COUNT AS (\n        SELECT \n            f.\"film_id\",\n            f.\"title\",\n            COUNT(fa.\"actor_id\") AS num_actors\n        FROM \n            SQLITE_SAKILA.SQLITE_SAKILA.FILM f\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.FILM_ACTOR fa ON fa.\"film_id\" = f.\"film_id\"\n        GROUP BY \n            f.\"film_id\", f.\"title\"\n        ORDER BY \n            f.\"film_id\"\n    ),\n    FILM_REVENUE AS (\n        SELECT \n            i.\"film_id\",\n            SUM(p.\"amount\") AS gross_revenue\n        FROM \n            SQLITE_SAKILA.SQLITE_SAKILA.PAYMENT p\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.RENTAL r ON r.\"rental_id\" = p.\"rental_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.INVENTORY i ON i.\"inventory_id\" = r.\"inventory_id\"\n        GROUP BY \n            i.\"film_id\"\n        ORDER BY \n            i.\"film_id\"\n    ),\n    FILM_REV_PER_ACTOR AS (\n        SELECT \n            ac.\"title\",\n            fr.gross_revenue / ac.num_actors * 1.0 AS rev_per_actor\n        FROM \n            ACTOR_COUNT ac\n        JOIN \n            FILM_REVENUE fr ON fr.\"film_id\" = ac.\"film_id\"\n    )\nSELECT \n    *\nFROM \n    FILM_REV_PER_ACTOR\nORDER BY \n    rev_per_actor DESC\nFETCH FIRST 3 ROWS ONLY;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local195",
        "score": 1,
        "pred_sql": "WITH \n    ACTORS_SALES AS (\n        SELECT \n            a.\"actor_id\",\n            a.\"first_name\",\n            a.\"last_name\",\n            SUM(p.\"amount\") AS gross_sales\n        FROM \n            SQLITE_SAKILA.SQLITE_SAKILA.ACTOR a\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.FILM_ACTOR fa ON fa.\"actor_id\" = a.\"actor_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.FILM f ON f.\"film_id\" = fa.\"film_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.INVENTORY i ON i.\"film_id\" = f.\"film_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.RENTAL r ON r.\"inventory_id\" = i.\"inventory_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.PAYMENT p ON p.\"rental_id\" = r.\"rental_id\"\n        GROUP BY \n            a.\"actor_id\", a.\"first_name\", a.\"last_name\"\n    ),\n    TOP5 AS (\n        SELECT \n            \"actor_id\",\n            CONCAT(a.\"first_name\", ' ', a.\"last_name\") AS full_name,\n            gross_sales\n        FROM \n            ACTORS_SALES a\n        ORDER BY \n            gross_sales DESC\n        LIMIT \n            5\n    ),\n    TOP_MOVIES AS (\n        SELECT \n            f.\"film_id\",\n            f.\"title\"\n        FROM \n            TOP5 t5\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.FILM_ACTOR fa ON fa.\"actor_id\" = t5.\"actor_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.FILM f ON f.\"film_id\" = fa.\"film_id\"\n        GROUP BY \n            f.\"film_id\", f.\"title\"   -- Add title to the GROUP BY clause\n    ),\n    CUSTOMER_RENTALS AS (\n        SELECT \n            c.\"customer_id\",\n            i.\"film_id\"\n        FROM \n            SQLITE_SAKILA.SQLITE_SAKILA.CUSTOMER c\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.PAYMENT p ON p.\"customer_id\" = c.\"customer_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.RENTAL r ON r.\"rental_id\" = p.\"rental_id\"\n        JOIN \n            SQLITE_SAKILA.SQLITE_SAKILA.INVENTORY i ON i.\"inventory_id\" = r.\"inventory_id\"\n    ),\n    CUSTOMER_TOP_MOVIES AS (\n        SELECT DISTINCT \n            cr.\"customer_id\"\n        FROM \n            CUSTOMER_RENTALS cr\n        WHERE \n            cr.\"film_id\" IN (\n                SELECT \n                    tm.\"film_id\"\n                FROM \n                    TOP_MOVIES tm\n            )\n    )\nSELECT \n    ROUND(\n        100.0 * (SELECT COUNT(\"customer_id\") FROM CUSTOMER_TOP_MOVIES) / \n        (SELECT COUNT(\"customer_id\") FROM SQLITE_SAKILA.SQLITE_SAKILA.CUSTOMER), 2\n    ) AS answer;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local199",
        "score": 1,
        "pred_sql": "WITH result_table AS (\n  SELECT \n    EXTRACT(YEAR FROM TO_TIMESTAMP(\"rental_date\", 'YYYY-MM-DD HH24:MI:SS.FF')) AS \"year\", \n    EXTRACT(MONTH FROM TO_TIMESTAMP(\"rental_date\", 'YYYY-MM-DD HH24:MI:SS.FF')) AS \"rental_month\", \n    \"st\".\"store_id\", \n    COUNT(\"re\".\"rental_id\") AS \"count\"\n  FROM \n    SQLITE_SAKILA.SQLITE_SAKILA.RENTAL \"re\"\n    JOIN SQLITE_SAKILA.SQLITE_SAKILA.STAFF \"st\" \n      ON \"re\".\"staff_id\" = \"st\".\"staff_id\"\n  GROUP BY \n    EXTRACT(YEAR FROM TO_TIMESTAMP(\"re\".\"rental_date\", 'YYYY-MM-DD HH24:MI:SS.FF')),\n    EXTRACT(MONTH FROM TO_TIMESTAMP(\"re\".\"rental_date\", 'YYYY-MM-DD HH24:MI:SS.FF')),\n    \"st\".\"store_id\"\n), \nmonthly_sales AS (\n  SELECT \n    \"year\", \n    \"rental_month\", \n    \"store_id\", \n    SUM(\"count\") AS \"total_rentals\"\n  FROM \n    result_table\n  GROUP BY \n    \"year\", \n    \"rental_month\", \n    \"store_id\"\n),\nstore_max_sales AS (\n  SELECT \n    \"store_id\", \n    \"year\", \n    \"rental_month\", \n    \"total_rentals\", \n    MAX(\"total_rentals\") OVER (PARTITION BY \"store_id\") AS \"max_rentals\"\n  FROM \n    monthly_sales\n)\nSELECT \n  \"store_id\", \n  \"year\", \n  \"rental_month\", \n  \"total_rentals\"\nFROM \n  store_max_sales\nWHERE \n  \"total_rentals\" = \"max_rentals\"\nORDER BY \n  \"store_id\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local209",
        "score": 1,
        "pred_sql": "WITH store_order_counts AS (\n    SELECT\n        s.\"store_name\",\n        COUNT(o.\"order_id\") AS total_orders\n    FROM\n        DELIVERY_CENTER.DELIVERY_CENTER.ORDERS o \n    LEFT JOIN\n        DELIVERY_CENTER.DELIVERY_CENTER.STORES s ON o.\"store_id\" = s.\"store_id\" \n    GROUP BY \n        s.\"store_name\"\n    ORDER BY \n        total_orders DESC\n    LIMIT 1  \n),\ndeliveries_completed AS (\n    SELECT\n        s.\"store_name\",\n        COUNT(o.\"order_id\") AS deliveries_completed\n    FROM\n        DELIVERY_CENTER.DELIVERY_CENTER.ORDERS o \n    LEFT JOIN\n        DELIVERY_CENTER.DELIVERY_CENTER.STORES s ON o.\"store_id\" = s.\"store_id\" \n    INNER JOIN (\n            SELECT \n                DISTINCT \"delivery_order_id\"\n            FROM DELIVERY_CENTER.DELIVERY_CENTER.DELIVERIES\n            WHERE \"delivery_status\" = 'DELIVERED'\n        ) AS ud ON o.\"delivery_order_id\" = ud.\"delivery_order_id\"\n    GROUP BY \n        s.\"store_name\"\n)\nSELECT\n    CAST(dc.deliveries_completed AS REAL) / NULLIF(CAST(soc.total_orders AS REAL), 0) AS completion_ratio\nFROM\n    store_order_counts soc\nLEFT JOIN\n    deliveries_completed dc ON soc.\"store_name\" = dc.\"store_name\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local210",
        "score": 1,
        "pred_sql": "WITH february_orders AS (\n    SELECT\n        h.\"hub_name\" AS hub_name,\n        COUNT(*) AS orders_february\n    FROM \n        DELIVERY_CENTER.DELIVERY_CENTER.ORDERS o \n    LEFT JOIN\n        DELIVERY_CENTER.DELIVERY_CENTER.STORES s ON o.\"store_id\" = s.\"store_id\" \n    LEFT JOIN \n        DELIVERY_CENTER.DELIVERY_CENTER.HUBS h ON s.\"hub_id\" = h.\"hub_id\" \n    WHERE o.\"order_created_month\" = 2 AND o.\"order_status\" = 'FINISHED'\n    GROUP BY\n        h.\"hub_name\"\n),\nmarch_orders AS (\n    SELECT\n        h.\"hub_name\" AS hub_name,\n        COUNT(*) AS orders_march\n    FROM \n        DELIVERY_CENTER.DELIVERY_CENTER.ORDERS o \n    LEFT JOIN\n        DELIVERY_CENTER.DELIVERY_CENTER.STORES s ON o.\"store_id\" = s.\"store_id\" \n    LEFT JOIN \n        DELIVERY_CENTER.DELIVERY_CENTER.HUBS h ON s.\"hub_id\" = h.\"hub_id\" \n    WHERE o.\"order_created_month\" = 3 AND o.\"order_status\" = 'FINISHED'\n    GROUP BY\n        h.\"hub_name\"\n)\nSELECT\n    fo.hub_name\nFROM\n    february_orders fo\nLEFT JOIN \n    march_orders mo ON fo.hub_name = mo.hub_name\nWHERE \n    fo.orders_february > 0 AND \n    mo.orders_march > 0 AND\n    (CAST((mo.orders_march - fo.orders_february) AS REAL) / CAST(fo.orders_february AS REAL)) > 0.2\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local218",
        "score": 1,
        "pred_sql": "WITH goals_per_club AS (\n    SELECT \n        \"team\",\n        \"season\",\n        SUM(\"goals\") AS \"total_goals\"\n    FROM (\n        SELECT \n            \"home_team_api_id\" AS \"team\",\n            \"season\",\n            \"home_team_goal\" AS \"goals\"\n        FROM \n            EU_SOCCER.EU_SOCCER.\"MATCH\"\n        UNION ALL\n        SELECT \n            \"away_team_api_id\" AS \"team\",\n            \"season\",\n            \"away_team_goal\" AS \"goals\"\n        FROM \n            EU_SOCCER.EU_SOCCER.\"MATCH\"\n    ) AS \"goals_data\"\n    GROUP BY \n        \"team\", \"season\"\n),\nmax_goals_per_team AS (\n    SELECT \n        \"team\",\n        MAX(\"total_goals\") AS \"max_goals\"\n    FROM \n        goals_per_club\n    GROUP BY \n        \"team\"\n),\nranked_goals AS (\n    SELECT \n        \"max_goals\",\n        ROW_NUMBER() OVER (ORDER BY \"max_goals\") AS \"row_num\",\n        COUNT(*) OVER () AS \"total_count\"\n    FROM \n        max_goals_per_team\n)\nSELECT \n    AVG(\"max_goals\") AS \"median_max_goals\"\nFROM \n    ranked_goals\nWHERE \n    \"row_num\" IN (( \"total_count\" + 1) / 2, ( \"total_count\" + 2) / 2);\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local244",
        "score": 1,
        "pred_sql": "WITH temp_t1 AS (\n    SELECT \n        MIN(\"Milliseconds\") AS Limit1,\n        AVG(\"Milliseconds\") AS avg_milliseconds,\n        (avg_milliseconds + MIN(\"Milliseconds\")) / 2 AS Limit2,\n        (MAX(\"Milliseconds\") + avg_milliseconds) / 2 AS Limit3,\n        MAX(\"Milliseconds\") AS Limit4\n    FROM MUSIC.MUSIC.TRACK\n),\ncateg AS (\n    SELECT \n        \"TrackId\",\n        CASE \n            WHEN t.\"Milliseconds\" < (SELECT Limit2 FROM temp_t1) THEN 'Short'\n            WHEN t.\"Milliseconds\" < (SELECT Limit3 FROM temp_t1) THEN 'Medium'\n            WHEN t.\"Milliseconds\" <= (SELECT Limit4 FROM temp_t1) THEN 'Long'\n        END AS LengthCateg\n    FROM MUSIC.MUSIC.TRACK t\n)\nSELECT \n    CASE \n        WHEN c.LengthCateg = 'Short' THEN (SELECT Limit1 / 60000.0 FROM temp_t1)\n        WHEN c.LengthCateg = 'Medium' THEN (SELECT Limit2 / 60000.0 FROM temp_t1)\n        WHEN c.LengthCateg = 'Long' THEN (SELECT Limit3 / 60000.0 FROM temp_t1)\n    END AS From_Minutes,\n    CASE \n        WHEN c.LengthCateg = 'Short' THEN (SELECT Limit2 / 60000.0 FROM temp_t1)\n        WHEN c.LengthCateg = 'Medium' THEN (SELECT Limit3 / 60000.0 FROM temp_t1)\n        WHEN c.LengthCateg = 'Long' THEN (SELECT Limit4 / 60000.0 FROM temp_t1)\n    END AS To_Minutes,\n    c.LengthCateg,\n    SUM(i.\"UnitPrice\" * i.\"Quantity\") AS TotalPrice\nFROM categ c\nJOIN MUSIC.MUSIC.INVOICELINE i ON c.\"TrackId\" = i.\"TrackId\"\nGROUP BY c.LengthCateg\nHAVING c.LengthCateg IS NOT NULL\nORDER BY TotalPrice;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local263",
        "score": 1,
        "pred_sql": "WITH model_scores AS (\n    SELECT \n        \"name\", \n        \"version\", \n        \"step\", \n        MAX(CASE WHEN \"model\" <> 'Stack' THEN \"test_score\" END) AS max_test_score,\n        MAX(CASE WHEN \"model\" = 'Stack' THEN \"test_score\" END) AS stack_score\n    FROM STACKING.STACKING.MODEL_SCORE\n    GROUP BY \"name\", \"version\", \"step\"\n),\ncombined AS (\n    SELECT \n        A.\"name\", \n        A.\"version\", \n        A.\"step\", \n        C.\"L1_model\", \n        CASE \n            WHEN A.max_test_score < A.stack_score THEN 'strong'\n            WHEN A.max_test_score = A.stack_score THEN 'soft'\n        END AS \"status\"\n    FROM model_scores A\n    INNER JOIN STACKING.STACKING.MODEL C \n        ON A.\"name\" = C.\"name\" \n        AND A.\"version\" = C.\"version\"\n    WHERE A.max_test_score IS NOT NULL \n      AND A.stack_score IS NOT NULL\n),\nfrequency AS (\n    SELECT \n        \"L1_model\", \n        \"status\", \n        COUNT(*) AS cnt\n    FROM combined\n    GROUP BY \"L1_model\", \"status\"\n),\nmax_frequency AS (\n    SELECT \n        \"status\", \n        MAX(cnt) AS max_cnt\n    FROM frequency\n    GROUP BY \"status\"\n)\nSELECT \n    f.\"status\",\n    f.\"L1_model\",\n    m.max_cnt\nFROM frequency f\nINNER JOIN max_frequency m \n    ON f.\"status\" = m.\"status\" \n    AND f.cnt = m.max_cnt\nORDER BY f.\"status\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local269",
        "score": 1,
        "pred_sql": "WITH RECURSIVE RECURSIVE_PR (root_id, packaging_id, contains_id, qty, lvl) AS (\n    SELECT\n        PR.\"packaging_id\" AS root_id,\n        PR.\"packaging_id\",\n        PR.\"contains_id\",\n        PR.\"qty\",\n        1 AS lvl\n    FROM ORACLE_SQL.ORACLE_SQL.PACKAGING_RELATIONS PR\n    WHERE PR.\"packaging_id\" NOT IN (\n        SELECT C.\"contains_id\" FROM ORACLE_SQL.ORACLE_SQL.PACKAGING_RELATIONS C\n    )\n    UNION ALL\n    SELECT\n        RPR.root_id,\n        PR.\"packaging_id\",\n        PR.\"contains_id\",\n        RPR.qty * PR.\"qty\" AS qty,\n        RPR.lvl + 1 AS lvl\n    FROM RECURSIVE_PR RPR\n    JOIN ORACLE_SQL.ORACLE_SQL.PACKAGING_RELATIONS PR ON PR.\"packaging_id\" = RPR.contains_id\n),\nRANKED_RECURSIVE_PR AS (\n    SELECT\n        RPR.*,\n        ROW_NUMBER() OVER (PARTITION BY RPR.root_id ORDER BY RPR.lvl) AS rpr_order\n    FROM RECURSIVE_PR RPR\n),\nLEAF AS (\n    SELECT\n        RRP.*,\n        CASE\n            WHEN COALESCE(\n                (SELECT MIN(lvl) FROM RANKED_RECURSIVE_PR WHERE root_id = RRP.root_id AND lvl > RRP.lvl),\n                0\n            ) > RRP.lvl THEN 0\n            ELSE 1\n        END AS is_leaf\n    FROM RANKED_RECURSIVE_PR RRP\n),\nPACKAGING_COMBINATION_QUANTITIES AS (\n    SELECT\n        P.\"id\" AS packaging_id,\n        C.\"id\" AS contained_item_id,\n        SUM(LEAF.qty) AS total_qty\n    FROM LEAF\n    JOIN ORACLE_SQL.ORACLE_SQL.PACKAGING P ON P.\"id\" = LEAF.root_id\n    JOIN ORACLE_SQL.ORACLE_SQL.PACKAGING C ON C.\"id\" = LEAF.contains_id\n    WHERE LEAF.is_leaf = 1\n    GROUP BY P.\"id\", C.\"id\"\n)\nSELECT\n    ROUND(AVG(total_qty), 2) AS avg_qty\nFROM PACKAGING_COMBINATION_QUANTITIES;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local283",
        "score": 1,
        "pred_sql": "WITH TABLE_1 AS (\n    SELECT \n        MATCH.\"id\",\n        COUNTRY.\"name\" AS country_name, \n        LEAGUE.\"name\" AS league_name, \n        \"season\", \n        \"stage\", \n        \"date\",\n        HT.\"team_long_name\" AS home_team,\n        AT.\"team_long_name\" AS away_team,\n        \"home_team_goal\", \n        \"away_team_goal\",\n        CASE\n            WHEN \"home_team_goal\" > \"away_team_goal\" THEN 'Win'\n            WHEN \"home_team_goal\" < \"away_team_goal\" THEN 'Loss'\n            ELSE 'Tie'\n        END AS home_team_result, \n        CASE\n            WHEN \"away_team_goal\" > \"home_team_goal\" THEN 'Win'\n            WHEN \"away_team_goal\" < \"home_team_goal\" THEN 'Loss'\n            ELSE 'Tie'\n        END AS away_team_result\n    FROM EU_SOCCER.EU_SOCCER.MATCH\n    JOIN EU_SOCCER.EU_SOCCER.COUNTRY ON COUNTRY.\"id\" = MATCH.\"country_id\"\n    JOIN EU_SOCCER.EU_SOCCER.LEAGUE ON LEAGUE.\"id\" = MATCH.\"league_id\"\n    LEFT JOIN EU_SOCCER.EU_SOCCER.TEAM AS HT ON HT.\"team_api_id\" = MATCH.\"home_team_api_id\"\n    LEFT JOIN EU_SOCCER.EU_SOCCER.TEAM AS AT ON AT.\"team_api_id\" = MATCH.\"away_team_api_id\"\n),\nHOME_TEAM AS (\n    SELECT \n        \"id\",\n        country_name, \n        league_name, \n        \"season\", \n        \"stage\", \n        \"date\",\n        home_team AS team, \n        'Home' AS team_type,\n        \"home_team_goal\" AS goals,\n        home_team_result AS result\n    FROM TABLE_1\n),\nAWAY_TEAM AS (\n    SELECT \n        \"id\",\n        country_name, \n        league_name, \n        \"season\", \n        \"stage\", \n        \"date\",\n        away_team AS team, \n        'Away' AS team_type,\n        \"away_team_goal\" AS goals,\n        away_team_result AS result\n    FROM TABLE_1\n), \nTABLE_2 AS (\n    SELECT * \n    FROM HOME_TEAM\n    UNION ALL\n    SELECT * \n    FROM AWAY_TEAM\n),\nTABLE_3 AS (\n    SELECT *, \n        CASE \n            WHEN result = 'Win' THEN 3\n            WHEN result = 'Tie' THEN 1\n            ELSE 0\n        END AS points\n    FROM TABLE_2\n), \nTABLE_4 AS (\n    SELECT\n        \"season\",\n        team,\n        league_name,\n        country_name,\n        SUM(points) AS total_points,\n        RANK() OVER(PARTITION BY \"season\" ORDER BY SUM(points) DESC) AS season_rank\n    FROM TABLE_3\n    GROUP BY \n        \"season\", \n        team,\n        league_name,\n        country_name\n    ORDER BY total_points DESC\n)\nSELECT * \nFROM TABLE_4 \nWHERE season_rank = 1\nORDER BY total_points DESC;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local285",
        "score": 1,
        "pred_sql": "WITH item_2020 AS (\n    SELECT\n        TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') AS yr,\n        c.\"category_code\",\n        c.\"category_name\",\n        ROUND(AVG(\"whsle_px_rmb-kg\"), 2) AS avg_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\"), 2) AS max_whole_sale,\n        ROUND(MIN(\"whsle_px_rmb-kg\"), 2) AS min_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\") - MIN(\"whsle_px_rmb-kg\"), 2) AS whole_sale_diff,\n        ROUND(SUM(v.\"qty_sold(kg)\" * w.\"whsle_px_rmb-kg\"), 2) AS whole_sale_price,\n        ROUND(SUM(v.\"unit_selling_px_rmb/kg\" * v.\"qty_sold(kg)\"), 2) AS selling_price,\n        ROUND(AVG(alr.\"loss_rate_%\"), 2) AS avg_loss_rate_pct\n    FROM BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_TXN_DF\" v\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_WHSLE_DF\" w \n        ON v.\"txn_date\" = w.\"whsle_date\" AND v.\"item_code\" = w.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_CAT\" c \n        ON v.\"item_code\" = c.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_LOSS_RATE_DF\" alr \n        ON alr.\"item_code\" = v.\"item_code\"\n    WHERE v.\"qty_sold(kg)\" > 0 AND TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') = '2020'\n    GROUP BY TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY'), c.\"category_code\", c.\"category_name\"\n),\nitem_2021 AS (\n    SELECT\n        TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') AS yr,\n        c.\"category_code\",\n        c.\"category_name\",\n        ROUND(AVG(\"whsle_px_rmb-kg\"), 2) AS avg_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\"), 2) AS max_whole_sale,\n        ROUND(MIN(\"whsle_px_rmb-kg\"), 2) AS min_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\") - MIN(\"whsle_px_rmb-kg\"), 2) AS whole_sale_diff,\n        ROUND(SUM(v.\"qty_sold(kg)\" * w.\"whsle_px_rmb-kg\"), 2) AS whole_sale_price,\n        ROUND(SUM(v.\"unit_selling_px_rmb/kg\" * v.\"qty_sold(kg)\"), 2) AS selling_price,\n        ROUND(AVG(alr.\"loss_rate_%\"), 2) AS avg_loss_rate_pct\n    FROM BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_TXN_DF\" v\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_WHSLE_DF\" w \n        ON v.\"txn_date\" = w.\"whsle_date\" AND v.\"item_code\" = w.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_CAT\" c \n        ON v.\"item_code\" = c.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_LOSS_RATE_DF\" alr \n        ON alr.\"item_code\" = v.\"item_code\"\n    WHERE v.\"qty_sold(kg)\" > 0 AND TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') = '2021'\n    GROUP BY TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY'), c.\"category_code\", c.\"category_name\"\n),\nitem_2022 AS (\n    SELECT\n        TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') AS yr,\n        c.\"category_code\",\n        c.\"category_name\",\n        ROUND(AVG(\"whsle_px_rmb-kg\"), 2) AS avg_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\"), 2) AS max_whole_sale,\n        ROUND(MIN(\"whsle_px_rmb-kg\"), 2) AS min_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\") - MIN(\"whsle_px_rmb-kg\"), 2) AS whole_sale_diff,\n        ROUND(SUM(v.\"qty_sold(kg)\" * w.\"whsle_px_rmb-kg\"), 2) AS whole_sale_price,\n        ROUND(SUM(v.\"unit_selling_px_rmb/kg\" * v.\"qty_sold(kg)\"), 2) AS selling_price,\n        ROUND(AVG(alr.\"loss_rate_%\"), 2) AS avg_loss_rate_pct\n    FROM BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_TXN_DF\" v\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_WHSLE_DF\" w \n        ON v.\"txn_date\" = w.\"whsle_date\" AND v.\"item_code\" = w.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_CAT\" c \n        ON v.\"item_code\" = c.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_LOSS_RATE_DF\" alr \n        ON alr.\"item_code\" = v.\"item_code\"\n    WHERE v.\"qty_sold(kg)\" > 0 AND TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') = '2022'\n    GROUP BY TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY'), c.\"category_code\", c.\"category_name\"\n),\nitem_2023 AS (\n    SELECT\n        TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') AS yr,\n        c.\"category_code\",\n        c.\"category_name\",\n        ROUND(AVG(\"whsle_px_rmb-kg\"), 2) AS avg_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\"), 2) AS max_whole_sale,\n        ROUND(MIN(\"whsle_px_rmb-kg\"), 2) AS min_whole_sale,\n        ROUND(MAX(\"whsle_px_rmb-kg\") - MIN(\"whsle_px_rmb-kg\"), 2) AS whole_sale_diff,\n        ROUND(SUM(v.\"qty_sold(kg)\" * w.\"whsle_px_rmb-kg\"), 2) AS whole_sale_price,\n        ROUND(SUM(v.\"unit_selling_px_rmb/kg\" * v.\"qty_sold(kg)\"), 2) AS selling_price,\n        ROUND(AVG(alr.\"loss_rate_%\"), 2) AS avg_loss_rate_pct\n    FROM BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_TXN_DF\" v\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_WHSLE_DF\" w \n        ON v.\"txn_date\" = w.\"whsle_date\" AND v.\"item_code\" = w.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_CAT\" c \n        ON v.\"item_code\" = c.\"item_code\"\n    LEFT JOIN BANK_SALES_TRADING.BANK_SALES_TRADING.\"VEG_LOSS_RATE_DF\" alr \n        ON alr.\"item_code\" = v.\"item_code\"\n    WHERE v.\"qty_sold(kg)\" > 0 AND TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY') = '2023'\n    GROUP BY TO_CHAR(TO_DATE(v.\"txn_date\", 'YYYY-MM-DD HH24:MI:SS'), 'YYYY'), c.\"category_code\", c.\"category_name\"\n),\nfinal_item AS (\n    SELECT * FROM item_2020\n    UNION\n    SELECT * FROM item_2021\n    UNION\n    SELECT * FROM item_2022\n    UNION\n    SELECT * FROM item_2023\n)\n\nSELECT *,\n    ROUND(((avg_loss_rate_pct * whole_sale_price) / 100.00), 2) AS total_loss,\n    ROUND(((selling_price - whole_sale_price) - (avg_loss_rate_pct * whole_sale_price) / 100.00), 2) AS profit\nFROM final_item;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local299",
        "score": 1,
        "pred_sql": "WITH RECURSIVE customer_date_series AS (\n    -- Anchor part: ensure 'date_series' is of DATE type\n    SELECT \"customer_id\", \n           MIN(\"txn_date\")::DATE AS \"date_series\",  -- Ensure this is a DATE type\n           MAX(\"txn_date\")::DATE AS \"last_date\"     -- Ensure this is a DATE type\n    FROM \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"CUSTOMER_TRANSACTIONS\"\n    GROUP BY \"customer_id\"\n\n    UNION ALL\n\n    -- Recursive part: ensure 'date_series' is of DATE type\n    SELECT \"customer_id\", \n           DATEADD(DAY, 1, \"date_series\") AS \"date_series\",  -- Ensure this adds 1 day to a DATE\n           \"last_date\"\n    FROM customer_date_series\n    WHERE DATEADD(DAY, 1, \"date_series\") <= \"last_date\"\n),\ncustomer_txn AS (\n    SELECT *,\n           CASE WHEN \"txn_type\" = 'deposit' THEN \"txn_amount\"\n                ELSE -1 * \"txn_amount\" END AS \"txn_group\"\n    FROM \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"CUSTOMER_TRANSACTIONS\"\n),\ncustomer_balance AS (\n    SELECT s.\"customer_id\", \n           s.\"date_series\", \n           COALESCE(b.\"txn_group\", 0) AS \"txn_group\",\n           SUM(COALESCE(b.\"txn_group\", 0)) OVER (PARTITION BY s.\"customer_id\" ORDER BY s.\"date_series\") AS \"balance\"\n    FROM customer_date_series s\n    LEFT JOIN customer_txn b \n        ON s.\"customer_id\" = b.\"customer_id\" \n        AND s.\"date_series\" = b.\"txn_date\"\n    ORDER BY s.\"customer_id\", s.\"date_series\"\n),\ncustomer_data AS (\n    SELECT \"customer_id\", \n           \"date_series\",\n           CASE WHEN \"txn_row\" < 30 THEN NULL\n                WHEN \"avg_last_30\" < 0 THEN 0\n                ELSE \"avg_last_30\" END AS \"data_storage\"\n    FROM (\n        SELECT *,\n               AVG(\"balance\") OVER (PARTITION BY \"customer_id\" ORDER BY \"date_series\" \n                                    ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) AS \"avg_last_30\",\n               ROW_NUMBER() OVER (PARTITION BY \"customer_id\" ORDER BY \"date_series\") AS \"txn_row\"\n        FROM customer_balance\n    ) AS tmp\n),\nmonthly_data AS (\n    SELECT \"customer_id\",\n           TO_CHAR(\"date_series\", 'YYYY-MM') AS \"month\",  -- Ensure 'date_series' is a valid DATE or TIMESTAMP\n           MAX(\"data_storage\") AS \"data_allocation\",\n           ROW_NUMBER() OVER (PARTITION BY \"customer_id\" ORDER BY TO_CHAR(\"date_series\", 'YYYY-MM')) AS \"month_row\"\n    FROM customer_data\n    GROUP BY \"customer_id\", TO_CHAR(\"date_series\", 'YYYY-MM')\n)\nSELECT \"month\", \n       SUM(\"data_allocation\") AS \"total_allocation\"\nFROM monthly_data\nWHERE \"month_row\" > 1\nGROUP BY \"month\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local300",
        "score": 1,
        "pred_sql": "WITH RECURSIVE customer_date_series AS (\n    SELECT \"customer_id\", \n           MIN(\"txn_date\")::DATE AS \"date_series\",\n           MAX(\"txn_date\")::DATE AS \"last_date\"\n    FROM \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"CUSTOMER_TRANSACTIONS\"\n    GROUP BY \"customer_id\"\n    UNION ALL\n    SELECT \"customer_id\", \n           DATEADD(DAY, 1, \"date_series\") AS \"date_series\",\n           \"last_date\"\n    FROM customer_date_series\n    WHERE DATEADD(DAY, 1, \"date_series\") <= \"last_date\"\n),\ncustomer_txn AS (\n    SELECT *,\n           CASE WHEN \"txn_type\" = 'deposit' THEN \"txn_amount\"\n                ELSE -1 * \"txn_amount\" END AS \"txn_group\"\n    FROM \"BANK_SALES_TRADING\".\"BANK_SALES_TRADING\".\"CUSTOMER_TRANSACTIONS\"\n),\ncustomer_balance AS (\n    SELECT s.\"customer_id\", \n           s.\"date_series\", \n           COALESCE(b.\"txn_group\", 0) AS \"txn_group\",\n           SUM(COALESCE(b.\"txn_group\", 0)) OVER (PARTITION BY s.\"customer_id\" ORDER BY s.\"date_series\") AS \"balance\"\n    FROM customer_date_series s\n    LEFT JOIN customer_txn b \n        ON s.\"customer_id\" = b.\"customer_id\" \n        AND s.\"date_series\" = b.\"txn_date\"\n    ORDER BY s.\"customer_id\", s.\"date_series\"\n),\ncustomer_data AS (\n    SELECT \"customer_id\", \n           \"date_series\",\n           CASE WHEN \"balance\" < 0 THEN 0\n                ELSE \"balance\" END AS \"data_storage\"\n    FROM customer_balance\n)\nSELECT \"month\", \n       SUM(\"data_allocation\") AS \"total_allocation\"\nFROM (\n    SELECT \"customer_id\",\n           TO_CHAR(\"date_series\", 'YYYY-MM') AS \"month\",\n           MAX(\"data_storage\") AS \"data_allocation\"\n    FROM customer_data\n    GROUP BY \"customer_id\", TO_CHAR(\"date_series\", 'YYYY-MM')\n) AS tmp\nGROUP BY \"month\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local309",
        "score": 1,
        "pred_sql": "WITH year_points AS (\n    SELECT\n        races.\"year\",\n        drivers.\"forename\" || ' ' || drivers.\"surname\" AS \"driver\",\n        constructors.\"name\" AS \"constructor\",\n        SUM(results.\"points\") AS \"points\"\n    FROM F1.F1.RESULTS results\n    LEFT JOIN F1.F1.RACES races ON results.\"race_id\" = races.\"race_id\"\n    LEFT JOIN F1.F1.DRIVERS drivers ON results.\"driver_id\" = drivers.\"driver_id\"\n    LEFT JOIN F1.F1.CONSTRUCTORS constructors ON results.\"constructor_id\" = constructors.\"constructor_id\"\n    GROUP BY races.\"year\", drivers.\"forename\", drivers.\"surname\", constructors.\"name\"\n    \n    UNION\n    \n    SELECT\n        races.\"year\",\n        NULL AS \"driver\",\n        constructors.\"name\" AS \"constructor\",\n        SUM(results.\"points\") AS \"points\"\n    FROM F1.F1.RESULTS results\n    LEFT JOIN F1.F1.RACES races ON results.\"race_id\" = races.\"race_id\"\n    LEFT JOIN F1.F1.DRIVERS drivers ON results.\"driver_id\" = drivers.\"driver_id\"\n    LEFT JOIN F1.F1.CONSTRUCTORS constructors ON results.\"constructor_id\" = constructors.\"constructor_id\"\n    GROUP BY races.\"year\", constructors.\"name\"\n),\nmax_points AS (\n    SELECT\n        \"year\",\n        MAX(CASE WHEN \"driver\" IS NOT NULL THEN \"points\" ELSE NULL END) AS \"max_driver_points\",\n        MAX(CASE WHEN \"constructor\" IS NOT NULL THEN \"points\" ELSE NULL END) AS \"max_constructor_points\"\n    FROM year_points\n    GROUP BY \"year\"\n)\nSELECT\n    max_points.\"year\",\n    drivers_year_points.\"driver\",\n    constructors_year_points.\"constructor\"\nFROM max_points\nLEFT JOIN year_points AS drivers_year_points\n    ON max_points.\"year\" = drivers_year_points.\"year\"\n    AND max_points.\"max_driver_points\" = drivers_year_points.\"points\"\n    AND drivers_year_points.\"driver\" IS NOT NULL\nLEFT JOIN year_points AS constructors_year_points\n    ON max_points.\"year\" = constructors_year_points.\"year\"\n    AND max_points.\"max_constructor_points\" = constructors_year_points.\"points\"\n    AND constructors_year_points.\"constructor\" IS NOT NULL\nORDER BY max_points.\"year\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local311",
        "score": 1,
        "pred_sql": "WITH year_points AS (\n    SELECT \n        races.\"year\",\n        drivers.\"forename\" || ' ' || drivers.\"surname\" AS \"driver\",\n        constructors.\"name\" AS \"constructor\",\n        SUM(results.\"points\") AS \"points\"\n    FROM F1.F1.RESULTS results\n    LEFT JOIN F1.F1.RACES races \n        ON results.\"race_id\" = races.\"race_id\"\n    LEFT JOIN F1.F1.DRIVERS drivers \n        ON results.\"driver_id\" = drivers.\"driver_id\"\n    LEFT JOIN F1.F1.CONSTRUCTORS constructors \n        ON results.\"constructor_id\" = constructors.\"constructor_id\"\n    GROUP BY \n        races.\"year\", \n        drivers.\"forename\", \n        drivers.\"surname\", \n        constructors.\"name\"\n    \n    UNION\n    \n    SELECT \n        races.\"year\",\n        NULL AS \"driver\",\n        constructors.\"name\" AS \"constructor\",\n        SUM(results.\"points\") AS \"points\"\n    FROM F1.F1.RESULTS results\n    LEFT JOIN F1.F1.RACES races \n        ON results.\"race_id\" = races.\"race_id\"\n    LEFT JOIN F1.F1.DRIVERS drivers \n        ON results.\"driver_id\" = drivers.\"driver_id\"\n    LEFT JOIN F1.F1.CONSTRUCTORS constructors \n        ON results.\"constructor_id\" = constructors.\"constructor_id\"\n    GROUP BY \n        races.\"year\", \n        constructors.\"name\"\n),\nmax_points AS (\n    SELECT \n        \"year\",\n        \"constructor\",\n        MAX(CASE WHEN \"driver\" IS NOT NULL THEN \"points\" ELSE NULL END) AS \"max_driver_points\",\n        MAX(CASE WHEN \"constructor\" IS NOT NULL THEN \"points\" ELSE NULL END) AS \"max_constructor_points\"\n    FROM year_points\n    GROUP BY \n        \"year\", \n        \"constructor\"\n)\nSELECT \n    constructors_year_points.\"year\",\n    max_points.\"constructor\",\n    max_points.\"max_driver_points\" + max_points.\"max_constructor_points\" AS \"combined_points\"\nFROM max_points\nLEFT JOIN year_points AS drivers_year_points\n    ON max_points.\"year\" = drivers_year_points.\"year\"\n    AND max_points.\"max_driver_points\" = drivers_year_points.\"points\"\n    AND drivers_year_points.\"driver\" IS NOT NULL\nLEFT JOIN year_points AS constructors_year_points\n    ON max_points.\"year\" = constructors_year_points.\"year\"\n    AND max_points.\"max_constructor_points\" = constructors_year_points.\"points\"\n    AND constructors_year_points.\"constructor\" IS NOT NULL\nORDER BY \n    \"combined_points\" DESC\nLIMIT 3;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local329",
        "score": 1,
        "pred_sql": "WITH mst_fallout_step AS (\n  -- Define the stages and paths\n  SELECT \n      1 AS \"step\", '/regist/input' AS \"path\"\n  UNION ALL\n  SELECT \n      2 AS \"step\", '/regist/confirm' AS \"path\"\n),\nform_log_with_fallout_step AS (\n  SELECT\n      l.\"session\",\n      m.\"step\",\n      m.\"path\",\n      MAX(l.\"stamp\") AS \"max_stamp\",\n      MIN(l.\"stamp\") AS \"min_stamp\"\n  FROM\n      mst_fallout_step AS m\n      JOIN LOG.LOG.FORM_LOG AS l\n      ON m.\"path\" = l.\"path\"\n  WHERE \n      l.\"status\" = ''\n  GROUP BY \n      l.\"session\", m.\"step\", m.\"path\"\n),\nform_log_with_mod_fallout_step AS (\n  SELECT\n      \"session\",\n      \"step\",\n      \"path\",\n      \"max_stamp\",\n      (\n          SELECT MIN(\"min_stamp\")\n          FROM \n              form_log_with_fallout_step AS prev\n          WHERE \n              prev.\"session\" = curr.\"session\" \n              AND prev.\"step\" = curr.\"step\" - 1\n      ) AS \"lag_min_stamp\",\n      (\n          SELECT \n              MIN(\"step\") \n          FROM \n              form_log_with_fallout_step AS min_step\n          WHERE \n              min_step.\"session\" = curr.\"session\"\n      ) AS \"min_step\",\n      (\n          SELECT \n              COUNT(*)\n          FROM \n              form_log_with_fallout_step AS count_step\n          WHERE \n              count_step.\"session\" = curr.\"session\" \n              AND count_step.\"step\" <= curr.\"step\"\n      ) AS \"cum_count\"\n  FROM \n      form_log_with_fallout_step AS curr\n),\nfallout_log AS (\n  SELECT\n    \"session\",\n    \"step\",\n    \"path\",\n    \"max_stamp\"\n  FROM \n    form_log_with_mod_fallout_step\n  WHERE \n    \"min_step\" = 1\n    AND \"step\" = \"cum_count\"\n    AND (\"lag_min_stamp\" IS NULL OR \"max_stamp\" >= \"lag_min_stamp\")\n),\ninput_to_confirm_counts AS (\n  SELECT\n    COUNT(DISTINCT input.\"session\") AS \"count\"\n  FROM \n    fallout_log AS input\n  JOIN \n    fallout_log AS confirm\n  ON \n    input.\"session\" = confirm.\"session\"\n  WHERE \n    input.\"path\" = '/regist/input'\n    AND confirm.\"path\" = '/regist/confirm'\n    AND input.\"max_stamp\" < confirm.\"max_stamp\"\n)\nSELECT\n  \"count\"\nFROM \n  input_to_confirm_counts;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local336",
        "score": 1,
        "pred_sql": "SELECT\n  overtake_type,\n  COUNT(*) AS overtake_count\nFROM (\n  SELECT DISTINCT\n    lap_positions.\"race_id\",\n    lap_positions.\"driver_id\" AS overtaking_driver_id,\n    lap_positions.\"lap\",\n    cars_behind_this_lap.\"driver_id\" AS overtaken_driver_id,\n    CASE\n      WHEN retirements.\"driver_id\" IS NOT NULL THEN 'R'\n      WHEN pit_stops.\"lap\" = lap_positions.\"lap\" THEN 'P'\n      WHEN pit_stops.\"milliseconds\" > overtaking_lap_times.\"running_milliseconds\" - overtaken_lap_times.\"running_milliseconds\" THEN 'P'\n      WHEN lap_positions.\"lap\" = 1 AND (previous_lap.\"position\" - cars_behind_this_lap_results.\"grid\") <= 2 THEN 'S'\n      ELSE 'T'\n    END AS overtake_type\n  FROM F1.F1.LAP_POSITIONS lap_positions\n    INNER JOIN F1.F1.RACES_EXT AS races\n      ON races.\"race_id\" = lap_positions.\"race_id\"\n      AND races.\"is_pit_data_available\" = 1\n    INNER JOIN F1.F1.LAP_POSITIONS AS previous_lap\n      ON previous_lap.\"race_id\" = lap_positions.\"race_id\"\n      AND previous_lap.\"driver_id\" = lap_positions.\"driver_id\"\n      AND previous_lap.\"lap\" = lap_positions.\"lap\" - 1\n    INNER JOIN F1.F1.LAP_POSITIONS AS cars_behind_this_lap\n      ON cars_behind_this_lap.\"race_id\" = lap_positions.\"race_id\"\n      AND cars_behind_this_lap.\"lap\" = lap_positions.\"lap\"\n      AND cars_behind_this_lap.\"position\" > lap_positions.\"position\"\n    LEFT JOIN F1.F1.RESULTS AS cars_behind_this_lap_results\n      ON cars_behind_this_lap_results.\"race_id\" = lap_positions.\"race_id\"\n      AND cars_behind_this_lap_results.\"driver_id\" = cars_behind_this_lap.\"driver_id\"\n    LEFT JOIN F1.F1.LAP_POSITIONS AS cars_behind_last_lap\n      ON cars_behind_last_lap.\"race_id\" = lap_positions.\"race_id\"\n      AND cars_behind_last_lap.\"lap\" = lap_positions.\"lap\" - 1\n      AND cars_behind_last_lap.\"driver_id\" = cars_behind_this_lap.\"driver_id\"\n      AND cars_behind_last_lap.\"position\" > previous_lap.\"position\"\n    LEFT JOIN F1.F1.RETIREMENTS AS retirements\n      ON retirements.\"race_id\" = lap_positions.\"race_id\"\n      AND retirements.\"lap\" = lap_positions.\"lap\"\n      AND retirements.\"driver_id\" = cars_behind_this_lap.\"driver_id\"\n    LEFT JOIN F1.F1.PIT_STOPS AS pit_stops\n      ON pit_stops.\"race_id\" = lap_positions.\"race_id\"\n      AND pit_stops.\"lap\" BETWEEN lap_positions.\"lap\" - 1 AND lap_positions.\"lap\"\n      AND pit_stops.\"driver_id\" = cars_behind_this_lap.\"driver_id\"\n    LEFT JOIN F1.F1.LAP_TIMES_EXT AS overtaking_lap_times\n      ON overtaking_lap_times.\"race_id\" = lap_positions.\"race_id\"\n      AND overtaking_lap_times.\"driver_id\" = lap_positions.\"driver_id\"\n      AND overtaking_lap_times.\"lap\" = pit_stops.\"lap\" - 1\n    LEFT JOIN F1.F1.LAP_TIMES_EXT AS overtaken_lap_times\n      ON overtaken_lap_times.\"race_id\" = lap_positions.\"race_id\"\n      AND overtaken_lap_times.\"driver_id\" = pit_stops.\"driver_id\"\n      AND overtaken_lap_times.\"lap\" = pit_stops.\"lap\" - 1\n  WHERE\n    cars_behind_last_lap.\"driver_id\" IS NULL\n    AND lap_positions.\"lap\" <= 5 /* Filter for the first five laps */\n) AS overtakes\nGROUP BY overtake_type;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local354",
        "score": 1,
        "pred_sql": "WITH drives_prelim AS (\n  SELECT DISTINCT\n    races.\"year\",\n    results.\"driver_id\",\n    races.\"round\",\n    results.\"constructor_id\",\n    COALESCE(\n      CASE \n        WHEN results.\"constructor_id\" = LAG(results.\"constructor_id\") OVER (\n          PARTITION BY races.\"year\", results.\"driver_id\"\n          ORDER BY races.\"round\" ASC\n        ) THEN 0 \n        ELSE 1 \n      END, 1\n    ) AS \"is_first_race\",\n    COALESCE(\n      CASE \n        WHEN results.\"constructor_id\" = LEAD(results.\"constructor_id\") OVER (\n          PARTITION BY races.\"year\", results.\"driver_id\"\n          ORDER BY races.\"round\" ASC\n        ) THEN 0 \n        ELSE 1 \n      END, 1\n    ) AS \"is_last_race\"\n  FROM \n      F1.F1.RESULTS results\n  INNER JOIN F1.F1.RACES races ON races.\"race_id\" = results.\"race_id\"\n),\nfirst_last_races AS (\n  SELECT\n    \"year\",\n    \"driver_id\",\n    MIN(\"round\") AS \"first_round\",\n    MAX(\"round\") AS \"last_round\"\n  FROM \n      drives_prelim\n  GROUP BY \n      \"year\", \n      \"driver_id\"\n)\nSELECT DISTINCT\n  dp.\"driver_id\"\nFROM \n    drives_prelim dp\nINNER JOIN first_last_races flr\n  ON dp.\"year\" = flr.\"year\"\n  AND dp.\"driver_id\" = flr.\"driver_id\"\n  AND (dp.\"round\" = flr.\"first_round\" OR dp.\"round\" = flr.\"last_round\")\nWHERE \n    dp.\"is_first_race\" = 0\n  AND dp.\"is_last_race\" = 0\n  AND dp.\"year\" BETWEEN 1950 AND 1959\nGROUP BY \n    dp.\"driver_id\"\nHAVING \n    COUNT(DISTINCT dp.\"round\") > 1;\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local355",
        "score": 1,
        "pred_sql": "WITH hiatus_prelim AS (\n  SELECT DISTINCT\n    races.\"year\",\n    driver_standings.\"driver_id\",\n    races.\"round\",\n    previous_results.\"constructor_id\" AS \"previous_constructor_id\",\n    next_results.\"constructor_id\" AS \"next_constructor_id\",\n    CASE\n      WHEN previous_results.\"constructor_id\" IS NOT NULL THEN 1\n      ELSE 0\n    END AS \"is_first_race\",\n    CASE\n      WHEN next_results.\"constructor_id\" IS NOT NULL THEN 1\n      ELSE 0\n    END AS \"is_last_race\"\n  FROM F1.F1.DRIVER_STANDINGS_EXT AS driver_standings\n  INNER JOIN F1.F1.RACES_EXT AS races ON races.\"race_id\" = driver_standings.\"race_id\"\n  LEFT JOIN F1.F1.RESULTS AS results\n    ON results.\"race_id\" = driver_standings.\"race_id\"\n    AND results.\"driver_id\" = driver_standings.\"driver_id\"\n  LEFT JOIN F1.F1.RACES_EXT AS previous_race\n    ON previous_race.\"year\" = races.\"year\"\n    AND previous_race.\"round\" = races.\"round\" - 1\n  LEFT JOIN F1.F1.RESULTS AS previous_results\n    ON previous_results.\"race_id\" = previous_race.\"race_id\"\n    AND previous_results.\"driver_id\" = driver_standings.\"driver_id\"\n  LEFT JOIN F1.F1.RACES_EXT AS next_race\n    ON next_race.\"year\" = races.\"year\"\n    AND next_race.\"round\" = races.\"round\" + 1\n  LEFT JOIN F1.F1.RESULTS AS next_results\n    ON next_results.\"race_id\" = next_race.\"race_id\"\n    AND next_results.\"driver_id\" = driver_standings.\"driver_id\"\n  WHERE results.\"driver_id\" IS NULL\n),\nfirst_race AS (\n  SELECT\n    \"year\",\n    \"driver_id\",\n    \"round\" AS \"first_round\",\n    ROW_NUMBER() OVER (PARTITION BY \"year\", \"driver_id\" ORDER BY \"round\" ASC) AS \"drive_id\",\n    \"previous_constructor_id\"\n  FROM hiatus_prelim\n  WHERE \"is_first_race\" = 1\n),\nlast_race AS (\n  SELECT\n    \"year\",\n    \"driver_id\",\n    \"round\" AS \"last_round\",\n    ROW_NUMBER() OVER (PARTITION BY \"year\", \"driver_id\" ORDER BY \"round\" ASC) AS \"drive_id\",\n    \"next_constructor_id\"\n  FROM hiatus_prelim\n  WHERE \"is_last_race\" = 1\n),\nmissed_races AS (\n  SELECT\n    \"driver_id\",\n    \"year\",\n    COUNT(*) AS \"missed_count\"  -- Count all missed rounds\n  FROM hiatus_prelim\n  GROUP BY \"driver_id\", \"year\"\n  HAVING COUNT(*) < 3  -- Less than 3 missed rounds\n)\nSELECT\n  AVG(first_race.\"first_round\") AS \"avg_first_round\",\n  AVG(last_race.\"last_round\") AS \"avg_last_round\"\nFROM F1.F1.DRIVER_STANDINGS_EXT AS driver_standings\nINNER JOIN F1.F1.RACES_EXT AS races ON races.\"race_id\" = driver_standings.\"race_id\"\nLEFT JOIN F1.F1.RESULTS AS results\n  ON results.\"race_id\" = driver_standings.\"race_id\"\n  AND results.\"driver_id\" = driver_standings.\"driver_id\"\nINNER JOIN first_race\n  ON first_race.\"year\" = races.\"year\"\n  AND first_race.\"driver_id\" = driver_standings.\"driver_id\"\nINNER JOIN last_race\n  ON last_race.\"year\" = races.\"year\"\n  AND last_race.\"driver_id\" = driver_standings.\"driver_id\"\n  AND last_race.\"drive_id\" = first_race.\"drive_id\"\nINNER JOIN missed_races\n  ON missed_races.\"year\" = races.\"year\"\n  AND missed_races.\"driver_id\" = driver_standings.\"driver_id\"\nWHERE results.\"driver_id\" IS NULL\n  AND first_race.\"previous_constructor_id\" != last_race.\"next_constructor_id\";\n",
        "error_info": null
    },
    {
        "instance_id": "sf_local360",
        "score": 1,
        "pred_sql": "WITH activity_log_with_session_click_conversion_flag AS (\n  SELECT\n    \"session\",\n    \"stamp\",\n    \"path\",\n    \"search_type\",\n    CASE\n      WHEN LAG(\"path\") OVER (PARTITION BY \"session\" ORDER BY \"stamp\" DESC) = '/detail'\n        THEN 1\n      ELSE 0\n    END AS \"has_session_click\",\n    SIGN(\n      SUM(CASE WHEN \"path\" = '/complete' THEN 1 ELSE 0 END)\n      OVER (PARTITION BY \"session\" ORDER BY \"stamp\" DESC\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n    ) AS \"has_session_conversion\"\n  FROM\n    LOG.LOG.ACTIVITY_LOG\n),\n\ncounts AS (\n  SELECT\n    \"session\",\n    \"path\",\n    \"search_type\",\n    COUNT(*) AS \"count_zeros\"\n  FROM\n    activity_log_with_session_click_conversion_flag\n  WHERE\n    \"has_session_click\" = 0\n    AND \"has_session_conversion\" = 0\n    AND \"search_type\" IS NOT NULL\n    AND TRIM(\"search_type\") <> ''\n  GROUP BY\n    \"session\",\n    \"path\",\n    \"search_type\"\n),\n\nmin_count AS (\n  SELECT\n    MIN(\"count_zeros\") AS \"min_zeros\"\n  FROM\n    counts\n)\n\nSELECT\n  c.\"session\",\n  c.\"path\",\n  c.\"search_type\"\nFROM\n  counts c\nJOIN\n  min_count mc ON c.\"count_zeros\" = mc.\"min_zeros\"\nORDER BY\n  c.\"count_zeros\";\n",
        "error_info": null
    }
]